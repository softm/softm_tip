<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Chapter 14. High Availability and Scalability</title><link rel="stylesheet" href="mysql-html.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.69.1"><link rel="start" href="index.html" title="MySQL 5.0 Reference Manual"><link rel="up" href="index.html" title="MySQL 5.0 Reference Manual"><link rel="prev" href="storage-engines.html" title="Chapter 13. Storage Engines"><link rel="next" href="mem-introduction.html" title="Chapter 15. MySQL Enterprise Monitor"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Chapter 14. High Availability and Scalability</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="storage-engines.html">Prev</a> </td><th width="60%" align="center"> </th><td width="20%" align="right"> <a accesskey="n" href="mem-introduction.html">Next</a></td></tr></table><hr></div><div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="ha-overview"></a>Chapter 14. High Availability and Scalability</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="ha-overview.html#ha-drbd">14.1. Using MySQL with DRBD</a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#ha-drbd-install">14.1.1. Configuring the DRBD Environment</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-mysql">14.1.2. Configuring MySQL for DRBD</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-performance">14.1.3. Optimizing Performance and Reliability</a></span></dt></dl></dd><dt><span class="section"><a href="ha-overview.html#ha-heartbeat">14.2. Using Linux HA Heartbeat</a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#ha-heartbeat-config">14.2.1. Heartbeat Configuration</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-heartbeat-drbd">14.2.2. Using Heartbeat with MySQL and DRBD</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-heartbeat-drbd-dopd">14.2.3. Using Heartbeat with DRBD and <span><strong class="command">dopd</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-heartbeat-errors">14.2.4. Dealing with System Level Errors</a></span></dt></dl></dd><dt><span class="section"><a href="ha-overview.html#ha-vm">14.3. MySQL and Virtualization</a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#ha-vm-commonissues">14.3.1. Common Issues with Virtualization</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-aws">14.3.2. Using MySQL within an Amazon EC2 Instance</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-resources">14.3.3. Virtualization Resources</a></span></dt></dl></dd><dt><span class="section"><a href="ha-overview.html#ha-zfs-replication">14.4. Using ZFS Replication</a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#ha-zfs-config">14.4.1. Using ZFS for Filesystem Replication</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-zfs-mysql">14.4.2. Configurating MySQL for ZFS Replication</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-zfs-mysql-recovery">14.4.3. Handling MySQL Recovery with ZFS</a></span></dt></dl></dd><dt><span class="section"><a href="ha-overview.html#ha-memcached">14.5. Using MySQL with <span><strong class="command">memcached</strong></span></a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#ha-memcached-install">14.5.1. Installing <span><strong class="command">memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using">14.5.2. Using <span><strong class="command">memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces">14.5.3. <span><strong class="command">memcached</strong></span> Interfaces</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats">14.5.4. Getting <span><strong class="command">memcached</strong></span> Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-faq">14.5.5. <span><strong class="command">memcached</strong></span> FAQ</a></span></dt></dl></dd><dt><span class="section"><a href="ha-overview.html#mysql-proxy">14.6. MySQL Proxy</a></span></dt><dd><dl><dt><span class="section"><a href="ha-overview.html#mysql-proxy-platforms">14.6.1. MySQL Proxy Supported Platforms</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-install">14.6.2. Installing MySQL Proxy</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-cmdline">14.6.3. MySQL Proxy Command-Line Options</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting">14.6.4. MySQL Proxy Scripting</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-using">14.6.5. Using MySQL Proxy</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-faq">14.6.6. MySQL Proxy FAQ</a></span></dt></dl></dd></dl></div><p>
    When using MySQL you may need to ensure the availability or
    scalability of your MySQL installation. Availability refers to the
    ability to cope with, and if necessary recover from, failures on the
    host, including failures of MySQL, the operating system, or the
    hardware. Scalability refers to the ability to spread the load of
    your application queries across multiple MySQL servers. As your
    application and usage increases, you may need to spread the queries
    for the application across multiple servers to improve response
    times.
  </p><p>
    There are a number of solutions available for solving issues of
    availability and scalability. The two primary solutions supported by
    MySQL are MySQL Replication and MySQL Cluster. Further options are
    available using third-party solutions such as DRBD (Distributed
    Replicated Block Device) and Heartbeat, and more complex scenarios
    can be solved through a combination of these technologies. These
    tools work in different ways:
  </p><div class="itemizedlist"><ul type="disc"><li><p>
        <span class="emphasis"><em>MySQL Replication</em></span> enables statements and
        data from one MySQL server instance to be replicated to another
        MySQL server instance. Without using more complex setups, data
        can only be replicated from a single master server to any number
        of slaves. The replication is asynchronous, so the
        synchronization does not take place in real time, and there is
        no guarantee that data from the master will have been replicated
        to the slaves.
      </p><div class="itemizedlist"><ul type="circle"><li><p>
            <span class="bold"><strong>Advantages</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                MySQL Replication is available on all platforms
                supported by MySQL, and since it isn't operating
                system-specific it can operate across different
                platforms.
              </p></li><li><p>
                Replication is asynchronous and can be stopped and
                restarted at any time, making it suitable for
                replicating over slower links, partial links and even
                across geographical boundaries.
              </p></li><li><p>
                Data can be replicated from one master to any number of
                slaves, making replication suitable in environments with
                heavy reads, but light writes (for example, many web
                applications), by spreading the load across multiple
                slaves.
              </p></li></ul></div></li><li><p>
            <span class="bold"><strong>Disadvantages</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Data can only be written to the master. In advanced
                configurations, though, you can set up a multiple-master
                configuration where the data is replicated around a ring
                configuration.
              </p></li><li><p>
                There is no guarantee that data on master and slaves
                will be consistent at a given point in time. Because
                replication is asynchronous there may be a small delay
                between data being written to the master and it being
                available on the slaves. This can cause problems in
                applications where a write to the master must be
                available for a read on the slaves (for example a web
                application).
              </p></li></ul></div></li><li><p>
            <span class="bold"><strong>Recommended uses</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Scale-out solutions that require a large number of reads
                but fewer writes (for example, web serving).
              </p></li><li><p>
                Logging/data analysis of live data. By replicating live
                data to a slave you can perform queries on the slave
                without affecting the operation of the master.
              </p></li><li><p>
                Online backup (availability), where you need an active
                copy of the data available. You need to combine this
                with other tools, such as custom scripts or Heartbeat.
                However, because of the asynchronous architecture, the
                data may be incomplete.
              </p></li><li><p>
                Offline backup. You can use replication to keep a copy
                of the data. By replicating the data to a slave, you
                take the slave down and get a reliable snapshot of the
                data (without MySQL running), then restart MySQL and
                replication to catch up. The master (and any other
                slaves) can be kept running during this period.
              </p></li></ul></div></li></ul></div><p>
        For information on setting up and configuring replication, see
        <a href="replication.html" title="Chapter 16. Replication">Chapter 16, <i>Replication</i></a>.
      </p></li><li><p>
        <span class="emphasis"><em>MySQL Cluster</em></span> is a synchronous solution
        that enables multiple MySQL instances to share database
        information. Unlike replication, data in a cluster can be read
        from or written to any node within the cluster, and information
        will be distributed to the other nodes.
      </p><div class="itemizedlist"><ul type="circle"><li><p>
            <span class="bold"><strong>Advantages</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Offers multiple read and write nodes for data storage.
              </p></li><li><p>
                Provides automatic failover between nodes. Only
                transaction information for the active node being used
                is lost in the event of a failure.
              </p></li><li><p>
                Data on nodes is instantaneously distributed to the
                other data nodes.
              </p></li></ul></div></li><li><p>
            <span class="bold"><strong>Disadvantages</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Available on a limited range of platforms.
              </p></li><li><p>
                Nodes within a cluster should be connected via a LAN;
                geographically separate nodes are not supported.
                However, you can replicate from one cluster to another
                using MySQL Replication, although the replication in
                this case is still asynchronous.
              </p></li></ul></div></li><li><p>
            <span class="bold"><strong>Recommended uses</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Applications that need very high availability, such as
                telecoms and banking.
              </p></li><li><p>
                Applications that require an equal or higher number of
                writes compared to reads.
              </p></li></ul></div></li></ul></div><p>
        For information on MySQL Cluster, see
        <a href="mysql-cluster.html" title="Chapter 17. MySQL Cluster">Chapter 17, <i>MySQL Cluster</i></a>.
      </p></li><li><p>
        <span class="emphasis"><em>DRBD (Distributed Replicated Block Device)</em></span>
        is a solution from Linbit supported only on Linux. DRBD creates
        a virtual block device (which is associated with an underlying
        physical block device) that can be replicated from the primary
        server to a secondary server. You create a file system on the
        virtual block device, and this information is then replicated,
        at the block level, to the secondary server.
      </p><p>
        Because the block device, not the data you are storing on it, is
        being replicated the validity of the information is more
        reliable than with data-only replication solutions. DRBD can
        also ensure data integrity by only returning from a write
        operation on the primary server when the data has been written
        to the underlying physical block device on both the primary and
        secondary servers.
      </p><div class="itemizedlist"><ul type="circle"><li><p>
            <span class="bold"><strong>Advantages</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Provides high availability and data integrity across two
                servers in the event of hardware or system failure.
              </p></li><li><p>
                Can ensure data integrity by enforcing write consistency
                on the primary and secondary nodes.
              </p></li></ul></div></li><li><p>
            <span class="bold"><strong>Disadvantages</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Only provides a method for duplicating data across the
                nodes. Secondary nodes cannot use the DRBD device while
                data is being replicated, and so the MySQL on the
                secondary node cannot be simultaneously active.
              </p></li><li><p>
                Can not be used to scale performance, since you can not
                redirect reads to the secondary node.
              </p></li></ul></div></li><li><p>
            <span class="bold"><strong>Recommended uses</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                High availability situations where concurrent access to
                the data is not required, but instant access to the
                active data in the event of a system or hardware failure
                is required.
              </p></li></ul></div></li></ul></div><p>
        For information on configuring DRBD and configuring MySQL for
        use with a DRBD device, see <a href="ha-overview.html#ha-drbd" title="14.1. Using MySQL with DRBD">Section 14.1, “Using MySQL with DRBD”</a>.
      </p></li><li><p>
        <span class="emphasis"><em><span><strong class="command">memcached</strong></span></em></span> is a simple,
        yet highly scalable key-based cache that stores data and objects
        wherever dedicated or spare RAM is available for very quick
        access by applications. You use <span><strong class="command">memcached</strong></span> in
        combination with your application and MySQL to reduce the number
        of reads from the database.
      </p><p>
        When writing your application, you first try to load the data
        from the <span><strong class="command">memcached</strong></span> cache, if the data you are
        looking for cannot be found, you then load the data from the
        MySQL database as normal, and populate the cache with the
        information that you loaded. Because
        <span><strong class="command">memcached</strong></span> can be used to store entire objects
        that might normally consist of multiple table lookups and
        aggregations, you can significantly increase the speed of your
        application because the requirement to load data directly from
        the database is reduced or even eliminated. Because the cache is
        entirely in RAM, the response time is very fast, and the
        information can be distributed among many servers to make the
        best use of any spare RAM capacity.
      </p><div class="itemizedlist"><ul type="circle"><li><p>
            <span class="bold"><strong>Advantages</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Very fast, RAM based, cache.
              </p></li><li><p>
                Reduces load on the MySQL server, allowing MySQL to
                concentrate on persistent storage and data writes.
              </p></li><li><p>
                Highly distributable and scalable, allowing multiple
                servers to be part of the cache group.
              </p></li><li><p>
                Highly portable - the <span><strong class="command">memcached</strong></span>
                interface is supported by many languages and systems,
                including Perl, Python, PHP, Ruby, Java and the MySQL
                server.
              </p></li></ul></div></li><li><p>
            <span class="bold"><strong>Disadvantages</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                Data is not persistent - you should only use the cache
                to store information that can otherwise be loaded from a
                MySQL database.
              </p></li><li><p>
                Fault tolerance is implied, rather than explicit. If a
                <span><strong class="command">memcached</strong></span> node fails then your
                application must be capable of loading the data from
                MySQL and updating the cache.
              </p></li></ul></div></li><li><p>
            <span class="bold"><strong>Recommended uses</strong></span>
          </p><div class="itemizedlist"><ul type="square"><li><p>
                High scalability situations where you have a very high
                number of reads, particularly of complex data objects
                that can easily be cached in the final, usable, form
                directly within the cache.
              </p></li></ul></div></li></ul></div><p>
        For information on installing, configuring and using
        <span><strong class="command">memcached</strong></span>, including using the many APIs
        available for communicating with <span><strong class="command">memcached</strong></span>,
        see <a href="ha-overview.html#ha-memcached" title="14.5. Using MySQL with memcached">Section 14.5, “Using MySQL with <span><strong class="command">memcached</strong></span>”</a>.
      </p></li><li><p>
        <span class="emphasis"><em>Heartbeat</em></span> is a software solution for Linux.
        It is not a data replication or synchronization solution, but a
        solution for monitoring servers and switching active MySQL
        servers automatically in the event of failure. Heartbeat needs
        to be combined with MySQL Replication or DRBD to provide
        automatic failover.
      </p><p>
        For more information on configuring Heartbeat for use with MySQL
        and DRBD, see <a href="ha-overview.html#ha-heartbeat" title="14.2. Using Linux HA Heartbeat">Section 14.2, “Using Linux HA Heartbeat”</a>.
      </p></li></ul></div><p>
    The information and suitability of the various technologies and
    different scenarios is summarized in the following table.
  </p><div class="informaltable"><a name="ha-availability-comparison"></a><table border="1"><colgroup><col><col><col><col><col><col></colgroup><thead><tr><th>Requirements</th><th>MySQL Replication</th><th>MySQL Replication + Heartbeat</th><th>MySQL Heartbeat + DRBD</th><th>MySQL Cluster</th><th>MySQL + <span><strong class="command">memcached</strong></span></th></tr></thead><tbody><tr><td><span class="bold"><strong>Availability</strong></span></td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td></tr><tr><td>Automated IP failover</td><td>No</td><td>Yes</td><td>Yes</td><td>No</td><td>No</td></tr><tr><td>Automated database failover</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td><td>No</td></tr><tr><td>Typical failover time</td><td>User/script-dependent</td><td>Varies</td><td>&lt; 30 seconds</td><td>&lt; 3 seconds</td><td>App dependent</td></tr><tr><td>Automatic resynchronization of data</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td><td>No</td></tr><tr><td>Geographic redundancy support</td><td>Yes</td><td>Yes</td><td>Yes, when combined with MySQL Replication</td><td>Yes, when combined with MySQL Replication</td><td>No</td></tr><tr><td><span class="bold"><strong>Scalability</strong></span></td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td><td class="auto-generated"> </td></tr><tr><td>Built-in load balancing</td><td>No</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td></tr><tr><td>Supports Read-intensive applications</td><td>Yes</td><td>Yes</td><td>Yes, when combined with MySQL Replication</td><td>Yes</td><td>Yes</td></tr><tr><td>Supports Write-intensive applications</td><td>No</td><td>No</td><td>Yes</td><td>Yes</td><td>No</td></tr><tr><td>Maximum number of nodes per group</td><td>One master, multiple slaves</td><td>One master, multiple slaves</td><td>One active (primary), one passive (secondary) node</td><td>255</td><td>Unlimited</td></tr><tr><td>Maximum number of slaves</td><td>Unlimited (reads only)</td><td>Unlimited (reads only)</td><td>One (failover only)</td><td>Unlimited (reads only)</td><td>Unlimited</td></tr></tbody></table></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ha-drbd"></a>14.1. Using MySQL with DRBD</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-drbd-install">14.1.1. Configuring the DRBD Environment</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-mysql">14.1.2. Configuring MySQL for DRBD</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-performance">14.1.3. Optimizing Performance and Reliability</a></span></dt></dl></div><p>
    The Distributed Replicated Block Device (DRBD) is a Linux Kernel
    module that constitutes a distributed storage system. You can use
    DRBD to share block devices between Linux servers and, in turn,
    share file systems and data.
  </p><p>
    DRBD implements a block device which can be used for storage and
    which is replicated from a primary server to one or more secondary
    servers. The distributed block device is handled by the DRBD
    service. Writes to the DRBD block device are distributed among the
    servers. Each DRBD service writes the information from the DRBD
    block device to a local physical block device (hard disk).
  </p><p>
    On the primary data writes are written both to the underlying
    physical block device and distributed to the secondary DRBD
    services. On the secondary, the writes received through DRBD and
    written to the local physical block device. On both the primary and
    the secondary, reads from the DRBD block device are handled by the
    underlying physical block device. The information is shared between
    the primary DRBD server and the secondary DRBD server synchronously
    and at a block level, and this means that DRBD can be used in
    high-availability solutions where you need failover support.
  </p><div class="figure"><a name="ha-drbd-overview"></a><p class="title"><b>Figure 14.1. DRBD Architecture Overview</b></p><div class="mediaobject"><img src="images/drbd-main.png" width="528" height="251" alt="DRBD Architecture Overview"></div></div><p>
    When used with MySQL, DRBD can be used to ensure availability in the
    event of a failure. MySQL is configured to store information on the
    DRBD block device, with one server acting as the primary and a
    second machine available to operate as an immediate replacement in
    the event of a failure.
  </p><p>
    For automatic failover support you can combine DRBD with the Linux
    Heartbeat project, which will manage the interfaces on the two
    servers and automatically configure the secondary (passive) server
    to replace the primary (active) server in the event of a failure.
    You can also combine DRBD with MySQL Replication to provide both
    failover and scalability within your MySQL environment.
  </p><p>
    For information on how to configure DRBD and MySQL, including
    Heartbeat support, see <a href="ha-overview.html#ha-drbd-install" title="14.1.1. Configuring the DRBD Environment">Section 14.1.1, “Configuring the DRBD Environment”</a>.
  </p><p>
    An FAQ for using DRBD and MySQL is available. See
    <a href="faqs.html#faqs-mysql-drbd-heartbeat" title="A.14. MySQL 5.0 FAQ — MySQL, DRBD, and Heartbeat">Section A.14, “MySQL 5.0 FAQ — MySQL, DRBD, and Heartbeat”</a>.
  </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
      Because DRBD is a Linux Kernel module it is currently not
      supported on platforms other than Linux.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-drbd-install"></a>14.1.1. Configuring the DRBD Environment</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-os">14.1.1.1. Setting Up Your Operating System for DRBD</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-drbd">14.1.1.2. Installing and Configuring DRBD</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-drbd-primary">14.1.1.3. Setting Up a DRBD Primary Node</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-drbd-secondary">14.1.1.4. Setting Up a DRBD Secondary Node</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-drbd-using">14.1.1.5. Monitoring DRBD Device</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-drbd-management">14.1.1.6. Managing your DRBD Installation</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-install-drbd-othercfg">14.1.1.7. Additional DRBD Configuration Options</a></span></dt></dl></div><p>
      To set up DRBD, MySQL and Heartbeat you need to follow a number of
      steps that affect the operating system, DRBD and your MySQL
      installation.
    </p><p>
      Before starting the installation process, you should be aware of
      the following information, terms and requirements on using DRBD:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          DRBD is a solution for enabling high-availability, and
          therefore you need to ensure that the two machines within your
          DRBD setup are as identically configured as possible so that
          the secondary machine can act as a direct replacement for the
          primary machine in the event of system failure.
        </p></li><li><p>
          DRBD works through two (or more) servers, each called a
          <em class="firstterm">node</em>
        </p></li><li><p>
          The node that contains the primary data, has read/write access
          to the data, and in an HA environment is the currently active
          node is called the <em class="firstterm">primary</em>.
        </p></li><li><p>
          The server to which the data is replicated is referred as
          <em class="firstterm">secondary</em>.
        </p></li><li><p>
          A collection of nodes that are sharing information are
          referred to as a <em class="firstterm">DRBD cluster</em>.
        </p></li><li><p>
          For DRBD to operate you must have a block device on which the
          information can be stored on <span class="emphasis"><em>each</em></span> DRBD
          node. The <em class="firstterm">lower level</em> block device can
          be a physical disk partition, a partition from a volume group
          or RAID device or any other block device.
        </p><p>
          Typically you use a spare partition on which the physical data
          will be stored . On the primary node, this disk will hold the
          raw data that you want replicated. On the secondary nodes, the
          disk will hold the data replicated to the secondary server by
          the DRBD service. Ideally, the size of the partition on the
          two DRBD servers should be identical, but this is not
          necessary as long as there is enough space to hold the data
          that you want distributed between the two servers.
        </p></li><li><p>
          For the distribution of data to work, DRBD is used to create a
          logical block device that uses the lower level block device
          for the actual storage of information. To store information on
          the distributed device, a file system is created on the DRBD
          logical block device.
        </p></li><li><p>
          When used with MySQL, once the file system has been created,
          you move the MySQL data directory (including InnoDB data files
          and binary logs) to the new file system.
        </p></li><li><p>
          When you set up the secondary DRBD server, you set up the
          physical block device and the DRBD logical block device that
          will store the data. The block device data is then copied from
          the primary to the secondary server.
        </p></li></ul></div><p>
      The overview for the installation and configuration sequence is as
      follows:
    </p><div class="orderedlist"><ol type="1"><li><p>
          First you need to set up your operating system and
          environment. This includes setting the correct host name,
          updating the system and preparing the available packages and
          software required by DRBD, and configuring a physical block
          device to be used with the DRBD block device. See
          <a href="ha-overview.html#ha-drbd-install-os" title="14.1.1.1. Setting Up Your Operating System for DRBD">Section 14.1.1.1, “Setting Up Your Operating System for DRBD”</a>.
        </p></li><li><p>
          Installing DRBD requires installing or compiling the DRBD
          source code and then configuring the DRBD service to set up
          the block devices that will be shared. See
          <a href="ha-overview.html#ha-drbd-install-drbd" title="14.1.1.2. Installing and Configuring DRBD">Section 14.1.1.2, “Installing and Configuring DRBD”</a>.
        </p></li><li><p>
          Once DRBD has been configured, you must alter the
          configuration and storage location of the MySQL data. See
          <a href="ha-overview.html#ha-drbd-install-mysql" title="14.1.2. Configuring MySQL for DRBD">Section 14.1.2, “Configuring MySQL for DRBD”</a>.
        </p></li></ol></div><p>
      You may optionally want to configure high availability using the
      Linux Heartbeat service. See <a href="ha-overview.html#ha-heartbeat" title="14.2. Using Linux HA Heartbeat">Section 14.2, “Using Linux HA Heartbeat”</a>, for
      more information.
    </p><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-install-os"></a>14.1.1.1. Setting Up Your Operating System for DRBD</h4></div></div></div><p>
        To set your Linux environment for using DRBD there are a number
        of system configuration steps that you must follow.
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            Make sure that the primary and secondary DRBD servers have
            the correct host name, and that the host names are unique.
            You can verify this by using the <span><strong class="command">uname</strong></span>
            command:
          </p><pre class="programlisting">shell&gt; uname -n
drbd-one
</pre><p>
            If the host name is not set correctly, edit the appropriate
            file (usually <code class="filename">/etc/sysconfig/network</code>,
            <code class="filename">/etc/hostname</code>, or
            <code class="filename">/etc/conf.d/hostname</code>) and set the name
            correctly.
          </p></li><li><p>
            Each DRBD node must have a unique IP address. Make sure that
            the IP address information is set correctly within the
            network configuration and that the host name and IP address
            has been set correctly within the
            <code class="filename">/etc/hosts</code> file.
          </p></li><li><p>
            Although you can rely on the DNS or NIS system for host
            resolving, in the event of a major network failure these
            services may not be available. If possible, add the IP
            address and host name of each DRBD node into the /etc/hosts
            file for each machine. This will ensure that the node
            information can always be determined even if the DNS/NIS
            servers are unavailable.
          </p></li><li><p>
            As a general rule, the faster your network connection the
            better. Because the block device data is exchanged over the
            network, everything that will be written to the local disk
            on the DRBD primary will also be written to the network for
            distribution to the DRBD secondary.
          </p><p>
            For tips on configuring a faster network connection see
            <a href="ha-overview.html#ha-drbd-performance" title="14.1.3. Optimizing Performance and Reliability">Section 14.1.3, “Optimizing Performance and Reliability”</a>.
          </p></li><li><p>
            You must have a spare disk or disk partition that you can
            use as the physical storage location for the DRBD data that
            will be replicated. You do not have to have a complete disk
            available, a partition on an existing disk is acceptable.
          </p><p>
            If the disk is unpartitioned, partition the disk using
            <span><strong class="command">fdisk</strong></span>, <span><strong class="command">cfdisk</strong></span> or other
            partitioning solution. Do not create a file system on the
            new partition.
          </p><p>
            Remember that you must have a physical disk available for
            the storage of the replicated information on each DRBD node.
            Ideally the partitions that will be used on each node should
            be of an identical size, although this is not strictly
            necessary. Do, however, ensure that the physical partition
            on the DRBD secondary is at least as big as the partitions
            on the DRBD primary node.
          </p></li><li><p>
            If possible, upgrade your system to the latest available
            Linux kernel for your distribution. Once the kernel has been
            installed, you must reboot to make the kernel active. To use
            DRBD you will also need to install the relevant kernel
            development and header files that are required for building
            kernel modules. Platform specification information for this
            is available later in this section.
          </p></li></ul></div><p>
        Before you compile or install DRBD, you must make sure the
        following tools and files are in place:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            Kernel header files
          </p></li><li><p>
            Kernel source files
          </p></li><li><p>
            GCC Compiler
          </p></li><li><p>
            <code class="literal">glib 2</code>
          </p></li><li><p>
            <span><strong class="command">flex</strong></span>
          </p></li></ul></div><p>
        Here are some operating system specific tips for setting up your
        installation:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <span class="bold"><strong>Tips for Red Hat (including CentOS and
            Fedora)</strong></span>:
          </p><p>
            Use <span><strong class="command">up2date</strong></span> or <span><strong class="command">yum</strong></span> to
            update and install the latest kernel and kernel header
            files:
          </p><pre class="programlisting">root-shell&gt; up2date kernel-smp-devel kernel-smp</pre><p>
            Reboot. If you are going to build DRBD from source, then
            update your system with the required development packages:
          </p><pre class="programlisting">root-shell&gt; up2date glib-devel openssl-devel libgcrypt-devel glib2-devel \
pkgconfig ncurses-devel rpm-build rpm-devel redhat-rpm-config gcc \
gcc-c++ bison flex gnutls-devel lm_sensors-devel net-snmp-devel \
python-devel bzip2-devel libselinux-devel perl-DBI</pre><p>
            If you are going to use the pre-built DRBD RPMs:
          </p><pre class="programlisting">root-shell&gt; up2date gnutls lm_sensors net-snmp ncurses libgcrypt glib2 openssl glib</pre></li><li><p>
            <span class="bold"><strong>Tips for Debian, Ubuntu,
            Kubuntu</strong></span>:
          </p><p>
            Use <span><strong class="command">apt-get</strong></span> to install the kernel
            packages
          </p><pre class="programlisting">root-shell&gt; apt-get install linux-headers linux-image-server</pre><p>
            If you are going to use the pre-built Debian packages for
            DRBD then you should not need any additional packages.
          </p><p>
            If you want to build DRBD from source, you will need to use
            the following command to install the required components:
          </p><pre class="programlisting">root-shell&gt; apt-get install devscripts flex bison build-essential \
dpkg-dev kernel-package debconf-utils dpatch debhelper \
libnet1-dev e2fslibs-dev libglib2.0-dev automake1.9 \
libgnutls-dev libtool libltdl3 libltdl3-dev</pre></li><li><p>
            <span class="bold"><strong>Tips for Gentoo</strong></span>:
          </p><p>
            Gentoo is a source based Linux distribution and therefore
            many of the source files and components that you will need
            are either already installed or will be installed
            automatically by <span><strong class="command">emerge</strong></span>.
          </p><p>
            To install DRBD 0.8.x, you must unmask the
            <code class="literal">sys-cluster/drbd</code> build by adding the
            following line to
            <code class="filename">/etc/portage/package.keywords</code>:
          </p><pre class="programlisting">sys-cluster/drbd ~x86
sys-cluster/drbd-kernel ~x86</pre><p>
            If your kernel does not already have the userspace to
            kernelspace linker enabled, then you will need to rebuild
            the kernel with this option. The best way to do this is to
            use <span><strong class="command">genkernel</strong></span> with the
            <code class="option">--menuconfig</code> option to select the option
            and then rebuild the kernel. For example, at the command
            line as <code class="literal">root</code>:
          </p><pre class="programlisting">root-shell&gt; genkernel --menuconfig all</pre><p>
            Then through the menu options, select <span class="guimenu">Device
            Drivers</span>, <span class="guimenu">Connector - unified userspace
            &lt;-&gt; kernelspace linker</span> and finally press 'y'
            or 'space' to select the <span class="guimenu">Connector - unified
            userspace &lt;-&gt; kernelspace linker</span> option.
            Then exit the menu configuration. The kernel will be rebuilt
            and installed. If this is a new kernel, make sure you update
            your bootloader accordingly. Now reboot to enable the new
            kernel.
          </p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-install-drbd"></a>14.1.1.2. Installing and Configuring DRBD</h4></div></div></div><p>
        To install DRBD you can choose either the pre-built binary
        installation packages or you can use the source packages and
        build from source. If you want to build from source you must
        have installed the source and development packages.
      </p><p>
        If you are installing using a binary distribution then you must
        ensure that the kernel version number of the binary package
        matches your currently active kernel. You can use
        <span><strong class="command">uname</strong></span> to find out this information:
      </p><pre class="programlisting">shell&gt; uname -r
2.6.20-gentoo-r6</pre><p>
        Once DRBD has been built and installed, you need to edit the
        <code class="filename">/etc/drbd.conf</code> file and then run a number
        of commands to build the block device and set up the
        replication.
      </p><p>
        Although the steps below are split into those for the primary
        node and the secondary node, it should be noted that the
        configuration files for all nodes should be identical, and many
        of the same steps have to be repeated on each node to enable the
        DRBD block device.
      </p><p>
        Building from source:
      </p><p>
        To download and install from the source code:
      </p><div class="orderedlist"><ol type="1"><li><p>
            Download the source code.
          </p></li><li><p>
            Unpack the package:
          </p><pre class="programlisting">shell&gt; tar zxf <strong class="userinput"><code>drbd-8.3.0.tar.gz</code></strong></pre></li><li><p>
            Change to the extracted directory, and then run
            <span><strong class="command">make</strong></span> to build the DRBD driver:
          </p><pre class="programlisting">shell&gt; cd drbd-8.3.0
shell&gt; make</pre></li><li><p>
            Install the kernel driver and commands:
          </p><pre class="programlisting">shell&gt; make install</pre></li></ol></div><p>
        Binary Installation:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <span class="bold"><strong> SUSE Linux Enterprise Server
            (SLES)</strong></span>
          </p><p>
            For SUSE, use <span><strong class="command">yast</strong></span>:
          </p><pre class="programlisting">shell&gt; yast -i drbd</pre><p>
            Alternatively:
          </p><pre class="programlisting">shell&gt; rug install drbd
</pre></li><li><p>
            <span class="bold"><strong>Debian</strong></span>
          </p><p>
            Use <span><strong class="command">apt-get</strong></span> to install the modules. You
            do not need to install any other components.
          </p><pre class="programlisting">shell&gt; apt-get install drbd8-utils drbd8-module
</pre></li><li><p>
            <span class="bold"><strong>Debian 3.1 and 4.0</strong></span>
          </p><p>
            You must install the <code class="literal">module-assistant</code> to
            build the DRBD kernel module, in addition to the DRBD
            components.
          </p><pre class="programlisting">shell&gt; apt-get install drbd0.7-utils drbd0.7-module-source \
  build-essential module-assistant
shell&gt; module-assistant auto-install drbd0.7
</pre></li><li><p>
            <span class="bold"><strong>CentOS</strong></span>
          </p><p>
            DRBD can be installed using yum:
          </p><pre class="programlisting">shell&gt; yum install drbd kmod-drbd</pre></li><li><p>
            <span class="bold"><strong>Ubuntu</strong></span>
          </p><p>
            You must enable the universe component for your preferred
            Ubuntu mirror in <code class="filename">/etc/apt/sources.list</code>,
            and then issue these commands:
          </p><pre class="programlisting">shell&gt; apt-get update
shell&gt; apt-get install drbd8-utils drbd8-module-source \
  build-essential module-assistant
shell&gt; module-assistant auto-install drbd8
</pre></li><li><p>
            <span class="bold"><strong>Gentoo</strong></span>
          </p><p>
            You can now <span><strong class="command">emerge</strong></span> DRBD 0.8.x into your
            Gentoo installation:
          </p><pre class="programlisting">root-shell&gt; emerge drbd</pre><p>
            Once <code class="literal">drbd</code> has been downloaded and
            installed, you need to decompress and copy the default
            configuration file from
            <code class="filename">/usr/share/doc/drbd-8.0.7/drbd.conf.bz2</code>
            into <code class="filename">/etc/drbd.conf</code>.
          </p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-install-drbd-primary"></a>14.1.1.3. Setting Up a DRBD Primary Node</h4></div></div></div><p>
        To set up a DRBD primary node you need to configure the DRBD
        service, create the first DRBD block device and then create a
        file system on the device so that you can store files and data.
      </p><p>
        The DRBD configuration file <code class="filename">/etc/drbd.conf</code>
        defines a number of parameters for your DRBD configuration,
        including the frequency of updates and block sizes, security
        information and the definition of the DRBD devices that you want
        to create.
      </p><p>
        The key elements to configure are the <code class="literal">on</code>
        sections which specify the configuration of each node.
      </p><p>
        To follow the configuration, the sequence below shows only the
        changes from the default <code class="filename">drbd.conf</code> file.
        Configurations within the file can be both global or tied to
        specific resource.
      </p><div class="orderedlist"><ol type="1"><li><p>
            Set the synchronization rate between the two nodes. This is
            the rate at which devices are synchronized in the background
            after a disk failure, device replacement or during the
            initial setup. You should keep this in check compared to the
            speed of your network connection. Gigabit Ethernet can
            support up to 125 MB/second, 100Mbps Ethernet slightly less
            than a tenth of that (12MBps). If you are using a shared
            network connection, rather than a dedicated, then you should
            gauge accordingly.
          </p><p>
            To set the synchronization rate, edit the
            <code class="literal">rate</code> setting within the
            <code class="literal">syncer</code> block:
          </p><pre class="programlisting">syncer {
    rate 10M;
}</pre><p>
            You may additionally want to set the
            <code class="literal">al-extents</code> parameter. The default for
            this parameter is 257.
          </p><p>
            For more detailed information on synchronization, the
            effects of the synchronization rate and the effects on
            network performance, see
            <a href="ha-overview.html#ha-drbd-performance-syncrate" title="14.1.3.2. Optimizing the Synchronization Rate">Section 14.1.3.2, “Optimizing the Synchronization Rate”</a>.
          </p></li><li><p>
            Set up some basic authentication. DRBD supports a simple
            password hash exchange mechanism. This helps to ensure that
            only those hosts with the same shared secret are able to
            join the DRBD node group.
          </p><pre class="programlisting">cram-hmac-alg “sha1”;
shared-secret "<em class="replaceable"><code>shared-string</code></em>";</pre></li><li><p>
            Now you must configure the host information. Remember that
            you must have the node information for the primary and
            secondary nodes in the <code class="filename">drbd.conf</code> file
            on each host. You need to configure the following
            information for each node:
          </p><div class="itemizedlist"><ul type="disc"><li><p>
                <code class="literal">device</code> — the path of the
                logical block device that will be created by DRBD.
              </p></li><li><p>
                <code class="literal">disk</code> — the block device that
                will be used to store the data.
              </p></li><li><p>
                <code class="literal">address</code> — the IP address and
                port number of the host that will hold this DRBD device.
              </p></li><li><p>
                <code class="literal">meta-disk</code> — the location where
                the metadata about the DRBD device will be stored. You
                can set this to <code class="literal">internal</code> and DRBD
                will use the physical block device to store the
                information, by recording the metadata within the last
                sections of the disk. The exact size will depend on the
                size of the logical block device you have created, but
                it may involve up to 128MB.
              </p></li></ul></div><p>
            A sample configuration for our primary server might look
            like this:
          </p><pre class="programlisting">on drbd-one {
device /dev/drbd0;
disk /dev/hdd1;
address 192.168.0.240:8888;
meta-disk internal;
}</pre><p>
            The <code class="literal">on</code> configuration block should be
            repeated for the secondary node (and any further) nodes:
          </p><pre class="programlisting">on drbd-two {
device /dev/drbd0;
disk /dev/hdd1;
address 192.168.0.241:8888;
meta-disk internal;
}</pre><p>
            The IP address of each <code class="literal">on</code> block must
            match the IP address of the corresponding host. Do not set
            this value to the IP address of the corresponding primary or
            secondary in each case.
          </p></li><li><p>
            Before starting the primary node, you should create the
            metadata for the devices:
          </p><pre class="programlisting">root-shell&gt; drbdadm create-md all</pre></li><li><p>
            You are now ready to start DRBD:
          </p><pre class="programlisting">root-shell&gt; /etc/init.d/drbd start</pre><p>
            DRBD should now start and initialize, creating the DRBD
            devices that you have configured.
          </p></li><li><p>
            DRBD creates a standard block device - to make it usable,
            you must create a file system on the block device just as
            you would with any standard disk partition. Before you can
            create the file system, you must mark the new device as the
            primary device (that is, where the data will be written and
            stored), and initialize the device. Because this is a
            destructive operation, you must specify the command line
            option to overwrite the raw data:
          </p><pre class="programlisting">root-shell&gt; drbdadm -- --overwrite-data-of-peer primary all</pre><p>
            If you are using a version of DRBD 0.7.x or earlier, then
            you need to use a different command-line option:
          </p><pre class="programlisting">root-shell&gt; drbdadm -- --do-what-I-say primary all</pre><p>
            Now create a file system using your chosen file system type:
          </p><pre class="programlisting">root-shell&gt; mkfs.ext3 /dev/drbd0</pre></li><li><p>
            You can now mount the file system and if necessary copy
            files to the mount point:
          </p><pre class="programlisting">root-shell&gt; mkdir /mnt/drbd
root-shell&gt; mount /dev/drbd0 /mnt/drbd
root-shell&gt; echo "DRBD Device" &gt;/mnt/drbd/samplefile</pre></li></ol></div><p>
        Your primary node is now ready to use. You should now configure
        your secondary node or nodes.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-install-drbd-secondary"></a>14.1.1.4. Setting Up a DRBD Secondary Node</h4></div></div></div><p>
        The configuration process for setting up a secondary node is the
        same as for the primary node, except that you do not have to
        create the file system on the secondary node device, as this
        information will automatically be transferred from the primary
        node.
      </p><p>
        To set up a secondary node:
      </p><div class="orderedlist"><ol type="1"><li><p>
            Copy the <code class="filename">/etc/drbd.conf</code> file from your
            primary node to your secondary node. It should already
            contain all the information and configuration that you need,
            since you had to specify the secondary node IP address and
            other information for the primary node configuration.
          </p></li><li><p>
            Create the DRBD metadata on the underlying disk device:
          </p><pre class="programlisting">root-shell&gt; drbdadm create-md all</pre></li><li><p>
            Start DRBD:
          </p><pre class="programlisting">root-shell&gt; /etc/init.d/drbd start</pre></li></ol></div><p>
        Once DRBD has started, it will start the copy the data from the
        primary node to the secondary node. Even with an empty file
        system this will take some time, since DRBD is copying the block
        information from a block device, not simply copying the file
        system data.
      </p><p>
        You can monitor the progress of the copy between the primary and
        secondary nodes by viewing the output of
        <code class="filename">/proc/drbd</code>:
      </p><pre class="programlisting">root-shell&gt; cat /proc/drbd
version: 8.0.4 (api:86/proto:86)
SVN Revision: 2947 build by root@drbd-one, 2007-07-30 16:43:05
 0: cs:SyncSource st:Primary/Secondary ds:UpToDate/Inconsistent C r---
    ns:252284 nr:0 dw:0 dr:257280 al:0 bm:15 lo:0 pe:7 ua:157 ap:0
        [==&gt;.................] sync'ed: 12.3% (1845088/2097152)K
        finish: 0:06:06 speed: 4,972 (4,580) K/sec
        resync: used:1/31 hits:15901 misses:16 starving:0 dirty:0 changed:16
        act_log: used:0/257 hits:0 misses:0 starving:0 dirty:0 changed:0</pre><p>
        You can monitor the synchronization process by using the
        <span><strong class="command">watch</strong></span> command to run the command at specific
        intervals:
      </p><pre class="programlisting">root-shell&gt; watch -n 10 'cat /proc/drbd'</pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-install-drbd-using"></a>14.1.1.5. Monitoring DRBD Device</h4></div></div></div><p>
        Once the primary and secondary machines are configured and
        synchronized, you can get the status information about your DRBD
        device by viewing the output from
        <code class="filename">/proc/drbd</code>:
      </p><pre class="programlisting">root-shell&gt; cat /proc/drbd
version: 8.0.4 (api:86/proto:86)
SVN Revision: 2947 build by root@drbd-one, 2007-07-30 16:43:05
 0: cs:Connected st:Primary/Secondary ds:UpToDate/UpToDate C r---
    ns:2175704 nr:0 dw:99192 dr:2076641 al:33 bm:128 lo:0 pe:0 ua:0 ap:0
        resync: used:0/31 hits:134841 misses:135 starving:0 dirty:0 changed:135
        act_log: used:0/257 hits:24765 misses:33 starving:0 dirty:0 changed:33</pre><p>
        The first line provides the version/revision and build
        information.
      </p><p>
        The second line starts the detailed status information for an
        individual resource. The individual field headings are as
        follows:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            cs — connection state
          </p></li><li><p>
            st — node state (local/remote)
          </p></li><li><p>
            ld — local data consistency
          </p></li><li><p>
            ds — data consistency
          </p></li><li><p>
            ns — network send
          </p></li><li><p>
            nr — network receive
          </p></li><li><p>
            dw — disk write
          </p></li><li><p>
            dr — disk read
          </p></li><li><p>
            pe — pending (waiting for ack)
          </p></li><li><p>
            ua — unack'd (still need to send ack)
          </p></li><li><p>
            al — access log write count
          </p></li></ul></div><p>
        In the previous example, the information shown indicates that
        the nodes are connected, the local node is the primary (because
        it is listed first), and the local and remote data is up to date
        with each other. The remainder of the information is statistical
        data about the device, and the data exchanged that kept the
        information up to date.
      </p><p>
        You can also get the status information for DRBD by using the
        startup script with the <code class="literal">status</code> option:
      </p><pre class="programlisting">root-shell&gt; /etc/init.d/drbd status
 * status:  started
 * drbd driver loaded OK; device status: ...                                                                                      [ ok ]
version: 8.3.0 (api:88/proto:86-89)
GIT-hash: 9ba8b93e24d842f0dd3fb1f9b90e8348ddb95829 build by root@gentoo1.vmbear, 2009-03-14 23:00:06
 0: cs:Connected ro:Secondary/Secondary ds:UpToDate/UpToDate C r---
    ns:0 nr:0 dw:0 dr:8385604 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:b oos:0
</pre><p>
        The information and statistics are the same.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-install-drbd-management"></a>14.1.1.6. Managing your DRBD Installation</h4></div></div></div><p>
        For administration, the main command is
        <span><strong class="command">drbdadm</strong></span>. There are a number of commands
        supported by this tool the control the connectivity and status
        of the DRBD devices.
      </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          For convenience, a bash completion script is available. This
          will provide tab completion for options to
          <span><strong class="command">drbdadm</strong></span>. The file
          <code class="filename">drbdadm.bash_completion</code> can be found
          within the standard DRBD source package within the
          <code class="filename">scripts</code> directory. To enable, copy the
          file to <code class="filename">/etc/bash_completion.d/drbdadm</code>.
          You can load it manually by using:
        </p><pre class="programlisting">shell&gt; source /etc/bash_completion.d/drbdadm</pre></div><p>
        The most common commands are those to set the primary/secondary
        status of the local device. You can manually set this
        information for a number of reasons, including when you want to
        check the physical status of the secondary device (since you
        cannot mount a DRBD device in primary mode), or when you are
        temporarily moving the responsibility of keeping the data in
        check to a different machine (for example, during an upgrade or
        physical move of the normal primary node). You can set state of
        all local device to be the primary using this command:
      </p><pre class="programlisting">root-shell&gt; drbdadm primary all</pre><p>
        Or switch the local device to be the secondary using:
      </p><pre class="programlisting">root-shell&gt; drbdadm secondary all</pre><p>
        To change only a single DRBD resource, specify the resource name
        instead of <code class="literal">all</code>.
      </p><p>
        You can temporarily disconnect the DRBD nodes:
      </p><pre class="programlisting">root-shell&gt; drbdadm disconnect all</pre><p>
        Reconnect them using <code class="literal">connect</code>:
      </p><pre class="programlisting">root-shell&gt; drbdadm connect all</pre><p>
        For other commands and help with <span><strong class="command">drbdadm</strong></span> see
        the DRBD documentation.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-install-drbd-othercfg"></a>14.1.1.7. Additional DRBD Configuration Options</h4></div></div></div><p>
        Additional options you may want to configure:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <code class="literal">protocol</code> — specifies the level of
            consistency to be used when information is written to the
            block device. The option is similar in principle to the
            <a href="storage-engines.html#sysvar_innodb_flush_log_at_trx_commit"><code class="literal">innodb_flush_log_at_trx_commit</code></a>
            option within MySQL. Three levels are supported:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">A</code> — data is considered written
                when the information reaches the TCP send buffer and the
                local physical disk. There is no guarantee that the data
                has been written to the remote server or the remote
                physical disk.
              </p></li><li><p>
                <code class="literal">B</code> — data is considered written
                when the data has reached the local disk and the remote
                node's network buffer. The data has reached the remote
                server, but there is no guarantee it has reached the
                remote server's physical disk.
              </p></li><li><p>
                <code class="literal">C</code> — data is considered written
                when the data has reached the local disk and the remote
                node's physical disk.
              </p></li></ul></div><p>
            The preferred and recommended protocol is C, as it is the
            only protocol which ensures the consistency of the local and
            remote physical storage.
          </p></li><li><p>
            <code class="literal">size</code> — if you do not want to use
            the entire partition space with your DRBD block device then
            you can specify the size of the DRBD device to be created.
            The size specification can include a quantifier. For
            example, to set the maximum size of the DRBD partition to
            1GB you would use:
          </p><pre class="programlisting">size 1G;</pre></li></ul></div><p>
        With the configuration file suitably configured and ready to
        use, you now need to populate the lower-level device with the
        metadata information, and then start the DRBD service.
      </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-drbd-install-mysql"></a>14.1.2. Configuring MySQL for DRBD</h3></div></div></div><p>
      Once you have configured DRBD and have an active DRBD device and
      file system, you can configure MySQL to use the chosen device to
      store the MySQL data.
    </p><p>
      When performing a new installation of MySQL, you can either select
      to install MySQL entirely onto the DRBD device, or just configure
      the data directory to be located on the new file system.
    </p><p>
      In either case, the files and installation must take place on the
      primary node, because that is the only DRBD node on which you can
      mount the DRBD device file system as read/write.
    </p><p>
      You should store the following files and information on your DRBD
      device:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          MySQL data files, including the binary log, and InnoDB data
          files.
        </p></li><li><p>
          MySQL configuration file (<code class="filename">my.cnf</code>).
        </p></li></ul></div><p>
      To set up MySQL to use your new DRBD device and file system:
    </p><div class="orderedlist"><ol type="1"><li><p>
          If you are migrating an existing MySQL installation, stop
          MySQL:
        </p><pre class="programlisting">shell&gt; mysqladmin shutdown</pre></li><li><p>
          Copy the <code class="filename">my.cnf</code> onto the DRBD device. If
          you are not already using a configuration file, copy one of
          the sample configuration files from the MySQL distribution.
        </p><pre class="programlisting">root-shell&gt; mkdir /mnt/drbd/mysql
root-shell&gt; cp /etc/my.cnf /mnt/drbd/mysql</pre></li><li><p>
          Copy your MySQL data directory to the DRBD device and mounted
          file system.
        </p><pre class="programlisting">root-shell&gt; cp -R /var/lib/mysql /drbd/mysql/data</pre></li><li><p>
          Edit the configuration file to reflect the change of directory
          by setting the value of the
          <a href="server-administration.html#sysvar_datadir"><code class="literal">datadir</code></a> option. If you have
          not already enabled the binary log, also set the value of the
          <code class="literal">log-bin</code> option.
        </p><pre class="programlisting">datadir = /drbd/mysql/data
  log-bin = mysql-bin</pre></li><li><p>
          Create a symbolic link from <code class="filename">/etc/my.cnf</code>
          to the new configuration file on the DRBD device file system.
        </p><pre class="programlisting">root-shell&gt; ln -s /drbd/mysql/my.cnf /etc/my.cnf</pre></li><li><p>
          Now start MySQL and check that the data that you copied to the
          DRBD device file system is present.
        </p><pre class="programlisting">root-shell&gt; /etc/init.d/mysql start</pre></li></ol></div><p>
      Your MySQL data should now be located on the file system running
      on your DRBD device. The data will be physically stored on the
      underlying device that you configured for the DRBD device.
      Meanwhile, the content of your MySQL databases will be copied to
      the secondary DRBD node.
    </p><p>
      Note that you cannot access the information on your secondary
      node, as a DRBD device working in secondary mode is not available
      for use.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-drbd-performance"></a>14.1.3. Optimizing Performance and Reliability</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-drbd-performance-bonded">14.1.3.1. Using Bonded Ethernet Network Interfaces</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-drbd-performance-syncrate">14.1.3.2. Optimizing the Synchronization Rate</a></span></dt></dl></div><p>
      Because of the nature of the DRBD system, the critical
      requirements are for a very fast exchange of the information
      between the two hosts. To ensure that your DRBD setup is available
      to switch over in the event of a failure as quickly as possible,
      you must transfer the information between the two hosts using the
      fastest method available.
    </p><p>
      Typically, a dedicated network circuit should be used for
      exchanging DRBD data between the two hosts. You should then use a
      separate, additional, network interface for your standard network
      connection. For an example of this layout, see
      <a href="ha-overview.html#ha-drbd-performance-sepinterface" title="Figure 14.2. DRBD Architecture Using Separate Network Interfaces">Figure 14.2, “DRBD Architecture Using Separate Network Interfaces”</a>.
    </p><div class="figure"><a name="ha-drbd-performance-sepinterface"></a><p class="title"><b>Figure 14.2. DRBD Architecture Using Separate Network Interfaces</b></p><div class="mediaobject"><img src="images/drbd-sepinterface.png" width="515" height="255" alt="DRBD Architecture Using Separate Network
          Interfaces"></div></div><p>
      The dedicated DRBD network interfaces should be configured to use
      a nonrouted TCP/IP network configuration. For example, you might
      want to set the primary to use 192.168.0.1 and the secondary
      192.168.0.2. These networks and IP addresses should not be part of
      normal network subnet.
    </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
        The preferred setup, whenever possible, is to use a direct cable
        connection (using a crossover cable with Ethernet, for example)
        between the two machines. This eliminates the risk of loss of
        connectivity due to switch failures.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-performance-bonded"></a>14.1.3.1. Using Bonded Ethernet Network Interfaces</h4></div></div></div><p>
        For a set-up where there is a high-throughput of information
        being written, you may want to use bonded network interfaces.
        This is where you combine the connectivity of more than one
        network port, increasing the throughput linearly according to
        the number of bonded connections.
      </p><p>
        Bonding also provides an additional benefit in that with
        multiple network interfaces effectively supporting the same
        communications channel, a fault within a single network
        interface in a bonded group does not stop communication. For
        example, imagine you have a bonded setup with four network
        interfaces providing a single interface channel between two DRBD
        servers. If one network interface fails, communication can
        continue on the other three without interruption, although it
        will be at a lower speed
      </p><p>
        To enable bonded connections you must enable bonding within the
        kernel. You then need to configure the module to specify the
        bonded devices and then configure each new bonded device just as
        you would a standard network device:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            To configure the bonded devices, you need to edit the
            <code class="filename">/etc/modprobe.conf</code> file (RedHat) or add
            a file to the <code class="filename">/etc/modprobe.d</code>
            directory.. In each case you will define the parameters for
            the kernel module. First, you need to specify each bonding
            device:
          </p><pre class="programlisting">alias bond0 bonding</pre><p>
            You can then configure additional parameters for the kernel
            module. Typical parameters are the <code class="literal">mode</code>
            option and the <code class="literal">miimon</code> option.
          </p><p>
            The <code class="literal">mode</code> option specifies how the network
            interfaces are used. The default setting is 0, which means
            that each network interface is used in a round-robin fashion
            (this supports aggregation and fault tolerance). Using
            setting 1 sets the bonding mode to active-backup. This means
            that only one network interface is used as a time, but that
            the link will automatically failover to a new interface if
            the primary interface fails. This settings only supports
            fault-tolerance.
          </p><p>
            The <code class="literal">miimon</code> option enables the MII link
            monitoring. A positive value greater than zero indicates the
            monitoring frequency in milliseconds for checking each slave
            network interface that is configured as part of the bonded
            interface. A typical value is 100.
          </p><p>
            You set th options within the module parameter file, and you
            must set the options for each bonded device individually:
          </p><pre class="programlisting">options bond0 miimon=100 mode=1</pre></li><li><p>
            Reboot your server to enable the bonded devices.
          </p></li><li><p>
            Configure the network device parameters. There are two parts
            to this, you need to setup the bonded device configuration,
            and then configure the original network interfaces as
            'slaves' of the new bonded interface.
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                For RedHat Linux:
              </p><p>
                Edit the configuration file for the bonded device. For
                device <code class="literal">bond0</code> this would be
                <code class="filename">/etc/sysconfig/network-scripts/ifcfg-bond0</code>:
              </p><pre class="programlisting">DEVICE=bond0
BOOTPROTO=none
ONBOOT=yes
GATEWAY=192.168.0.254
NETWORK=192.168.0.0
NETMASK=255.255.255.0
IPADDR=192.168.0.1
USERCTL=no</pre><p>
                Then for each network interface that you want to be part
                of the bonded device, configure the interface as a slave
                to the 'master' bond. For example, the configuration of
                <code class="literal">eth0</code> in
                <code class="filename">/etc/sysconfig/network-scripts/ifcfg-eth0</code>
                might look like this::
              </p><pre class="programlisting">DEVICE=eth0
BOOTPROTO=none
HWADDR=00:11:22:33:44:55
ONBOOT=yes
TYPE=Ethernet
MASTER=bond0
SLAVE=yes</pre></li><li><p>
                For Debian Linux:
              </p><p>
                Edit the <code class="filename">/etc/iftab</code> file and
                configure the logical name and MAC address for each
                devices. For example:
              </p><pre class="programlisting">eth0 mac 00:11:22:33:44:55</pre><p>
                Now you need to set the configuration of the devices in
                <code class="filename">/etc/network/interfaces</code>:
              </p><pre class="programlisting">auto bond0
    iface bond0 inet static
    address 192.168.0.1
    netmask 255.255.255.0
    network 192.168.0.0
    gateway 192.168.0.254
    up /sbin/ifenslave bond0 eth0
    up /sbin/ifenslave bond0 eth1</pre></li><li><p>
                For Gentoo:
              </p><p>
                Use <span><strong class="command">emerge</strong></span> to add the
                <code class="literal">net-misc/ifenslave</code> package to your
                system.
              </p><p>
                Edit the <code class="filename">/etc/conf.d/net</code> file and
                specify the network interface slaves in a bond, the
                dependencies and then the configuration for the bond
                itself. A sample configuration might look like this:
              </p><pre class="programlisting">slaves_bond0="eth0 eth1 eth2"

config_bond0=( "192.168.0.1 netmask 255.255.255.0"  )

depend_bond0() {
need net.eth0 net.eth1 net.eth2
}
            </pre><p>
                Then make sure that you add the new network interface to
                list of interfaces configured during boot:
              </p><pre class="programlisting">root-shell&gt; rc-update add default net.bond0</pre></li></ul></div></li></ul></div><p>
        Once the bonded devices are configured you should reboot your
        systems.
      </p><p>
        You can monitor the status of a bonded connection using the
        <code class="filename">/proc</code> file system:
      </p><pre class="programlisting">root-shell&gt; cat /proc/net/bonding/bond0
Bonding Mode: fault-tolerance (active-backup)
Primary Slave: None
Currently Active Slave: eth1
MII Status: up
MII Polling Interval (ms): 100
Up Delay (ms): 200
Down Delay (ms): 200
Slave Interface: eth1
MII Status: up
Link Failure Count: 0
Permanent HW addr: 00:11:22:33:44:55
Slave Interface: eth2
MII Status: up
Link Failure Count: 0
Permanent HW addr: 00:11:22:33:44:56</pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-drbd-performance-syncrate"></a>14.1.3.2. Optimizing the Synchronization Rate</h4></div></div></div><p>
        The <code class="literal">syncer rate</code> configuration parameter
        should be configured with care as the synchronization rate can
        have a significant effect on the performance of the DRBD setup
        in the event of a node or disk failure where the information is
        being synchronized from the Primary to the Secondary node.
      </p><p>
        In DRBD, there are two distinct ways of data being transferred
        between peer nodes:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <span class="emphasis"><em>Replication</em></span> refers to the transfer of
            modified blocks being transferred from the primary to the
            secondary node. This happens automatically when the block is
            modified on the primary node, and the replication process
            uses whatever bandwidth is available over the replication
            link. The replication process cannot be throttled, because
            you want to transfer of the block information to happen as
            quickly as possible during normal operation.
          </p></li><li><p>
            <span class="emphasis"><em>Synchronization</em></span> refers to the process
            of bringing peers back in sync after some sort of outage,
            due to manual intervention, node failure, disk swap, or the
            initial setup. Synchronization is limited to the
            <code class="literal">syncer rate</code> configured for the DRBD
            device.
          </p></li></ul></div><p>
        Both replication and synchronization can take place at the same
        time. For example, the block devices can be being synchronized
        while they are actively being used by the primary node. Any I/O
        that updates on the primary node will automatically trigger
        replication of the modified block. In the event of a failure
        within an HA environment, it is highly likely that
        synchronization and replication will take place at the same
        time.
      </p><p>
        Unfortunately, if the synchronization rate is set too high, then
        the synchronization process will use up all the available
        network bandwidth between the primary and secondary nodes. In
        turn, the bandwidth available for replication of changed blocks
        is zero, which means replication will stall and I/O will block,
        and ultimately the application will fail or degrade.
      </p><p>
        To avoid enabling the <code class="literal">syncer rate</code> to consume
        the available network bandwidth and prevent the replication of
        changed blocks you should set the <code class="literal">syncer rate</code>
        to less than the maximum network bandwidth.
      </p><p>
        You should avoid setting the sync rate to more than 30% of the
        maximum bandwidth available to your device and network
        bandwidth. For example, if your network bandwidth is based on
        Gigabit ethernet, you should achieve 110MB/s. Assuming your disk
        interface is capable of handling data at 110MB/s or more, then
        the sync rate should be configered as <code class="literal">33M</code>
        (33MB/s). If your disk system works at a rate lower than your
        network interface, use 30% of your disk interface speed.
      </p><p>
        Depending on the application, you may wish to limit the
        synchronization rate. For example, on a busy server you may wish
        to configure a significantly slower synchronization rate to
        ensure the replication rate is not affected.
      </p><p>
        The <code class="literal">al-extents</code> parameter controls the number
        of 4MB blocks of the underlying disk that can be written to at
        the same time. Increasing this parameter lowers the frequency of
        the meta data transactions required to log the changes to the
        DRBD device, which in turn lowers the number of interruptions in
        your I/O stream when synchronizing changes. This can lower the
        latency of changes to the DRBD device. However, if a crash
        occurs on your primary, then all of the blocks in the activity
        log (that is, the number of <code class="literal">al-extents</code>
        blocks) will need to be completely resynchronized before
        replication can continue.
      </p></div></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ha-heartbeat"></a>14.2. Using Linux HA Heartbeat</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-heartbeat-config">14.2.1. Heartbeat Configuration</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-heartbeat-drbd">14.2.2. Using Heartbeat with MySQL and DRBD</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-heartbeat-drbd-dopd">14.2.3. Using Heartbeat with DRBD and <span><strong class="command">dopd</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-heartbeat-errors">14.2.4. Dealing with System Level Errors</a></span></dt></dl></div><p>
    The Heartbeat program provides a basis for verifying the
    availability of resources on one or more systems within a cluster.
    In this context a resource includes MySQL, the file systems on which
    the MySQL data is being stored and, if you are using DRBD, the DRBD
    device being used for the file system. Heartbeat also manages a
    virtual IP address, and the virtual IP address should be used for
    all communication to the MySQL instance.
  </p><p>
    A cluster within the context of Heartbeat is defined as two
    computers notionally providing the same service. By definition, each
    computer in the cluster is physically capable of providing the same
    services as all the others in the cluster. However, because the
    cluster is designed for high-availability, only one of the servers
    is actively providing the service at any one time. Each additional
    server within the cluster is a “<span class="quote">hot-spare</span>” that can be
    brought into service in the event of a failure of the master, its
    next connectivity or the connectivity of the network in general.
  </p><p>
    The basics of Heartbeat are very simple. Within the Heartbeat
    cluster (see <a href="ha-overview.html#ha-heartbeat-overview" title="Figure 14.3. Heartbeat Architecture">Figure 14.3, “Heartbeat Architecture”</a>, each machine
    sends a 'heartbeat' signal to the other hosts in the cluster. The
    other cluster nodes monitor this heartbeat. The heartbeat can be
    transmitted over many different systems, including shared network
    devices, dedicated network interfaces and serial connections.
    Failure to get a heartbeat from a node is treated as failure of the
    node. Although we do not know the reason for the failure (it could
    be an OS failure, a hardware failure in the server, or a failure in
    the network switch), it is safe to assume that if no heartbeat is
    produced there is a fault.
  </p><div class="figure"><a name="ha-heartbeat-overview"></a><p class="title"><b>Figure 14.3. Heartbeat Architecture</b></p><div class="mediaobject"><img src="images/ha-heartbeat-overview.png" width="513" height="413" alt="Heartbeat Architecture"></div></div><p>
    In addition to checking the heartbeat from the server, the system
    can also check the connectivity (using <span><strong class="command">ping</strong></span>) to
    another host on the network, such as the network router. This allows
    Heartbeat to detect a failure of communication between a server and
    the router (and therefore failure of the server, since it is no
    longer capable of providing the necessary service), even if the
    heartbeat between the servers in the clusters is working fine.
  </p><p>
    In the event of a failure, the resources on the failed host are
    disabled, and the resources on one of the replacement hosts is
    enabled instead. In addition, the Virtual IP address for the cluster
    is redirected to the new host in place of the failed device.
  </p><p>
    When used with MySQL and DRBD, the MySQL data is replicated from the
    master to the slave using the DRBD device, but MySQL is only running
    on the master. When the master fails, the slave switches the DRBD
    devices to be primary, the file systems on those devices are
    mounted, and MySQL is started. The original master (if still
    available) has its resources disabled, which means shutting down
    MySQL and unmounting the file systems and switching the DRBD device
    to secondary.
  </p><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-heartbeat-config"></a>14.2.1. Heartbeat Configuration</h3></div></div></div><p>
      Heartbeat configuration requires three files located in
      <code class="filename">/etc/ha.d</code>. The <code class="filename">ha.cf</code>
      contains the main heartbeat configuration, including the list of
      the nodes and times for identifying failures.
      <code class="filename">haresources</code> contains the list of resources to
      be managed within the cluster. The <code class="filename">authkeys</code>
      file contains the security information for the cluster.
    </p><p>
      The contents of these files should be identical on each host
      within the Heartbeat cluster. It is important that you keep these
      files in sync across all the hosts. Any changes in the information
      on one host should be copied to the all the others.
    </p><p>
      For these examples n example of the <code class="filename">ha.cf</code>
      file is shown below:
    </p><pre class="programlisting">logfacility local0
keepalive 500ms
deadtime 10
warntime 5
initdead 30
mcast bond0 225.0.0.1 694 2 0
mcast bond1 225.0.0.2 694 1 0
auto_failback off
node drbd1
node drbd2</pre><p>
      The individual lines in the file can be identified as follows:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          <code class="literal">logfacility</code> — sets the logging, in
          this case setting the logging to use
          <span><strong class="command">syslog</strong></span>.
        </p></li><li><p>
          <code class="literal">keepalive</code> — defines how frequently
          the heartbeat signal is sent to the other hosts.
        </p></li><li><p>
          <code class="literal">deadtime</code>— the delay in seconds before
          other hosts in the cluster are considered 'dead' (failed).
        </p></li><li><p>
          <code class="literal">warntime</code> — the delay in seconds
          before a warning is written to the log that a node cannot be
          contacted.
        </p></li><li><p>
          <code class="literal">initdead</code> — the period in seconds to
          wait during system startup before the other host is considered
          to be down.
        </p></li><li><p>
          <code class="literal">mcast</code> — defines a method for sending
          a heartbeat signal. In the above example, a multicast network
          address is being used over a bonded network device. If you
          have multiple clusters then the multicast address for each
          cluster should be unique on your network. Other choices for
          the heartbeat exchange exist, including a serial connection.
        </p><p>
          If you are using multiple network interfaces (for example, one
          interface for your server connectivity and a secondary and/or
          bonded interface for your DRBD data exchange) then you should
          use both interfaces for your heartbeat connection. This
          decreases the chance of a transient failure causing a invalid
          failure event.
        </p></li><li><p>
          <code class="literal">auto_failback</code> — sets whether the
          original (preferred) server should be enabled again if it
          becomes available. Switching this to <code class="literal">on</code> may
          cause problems if the preferred went offline and then comes
          back on line again. If the DRBD device has not been synced
          properly, or if the problem with the original server happens
          again you may end up with two different datasets on the two
          servers, or with a continually changing environment where the
          two servers flip-flop as the preferred server reboots and then
          starts again.
        </p></li><li><p>
          <code class="literal">node</code> — sets the nodes within the
          Heartbeat cluster group. There should be one
          <code class="literal">node</code> for each server.
        </p></li></ul></div><p>
      An optional additional set of information provides the
      configuration for a ping test that will check the connectivity to
      another host. You should use this to ensure that you have
      connectivity on the public interface for your servers, so the ping
      test should be to a reliable host such as a router or switch. The
      additional lines specify the destination machine for the
      <code class="literal">ping</code>, which should be specified as an IP
      address, rather than a host name; the command to run when a
      failure occurs, the authority for the failure and the timeout
      before an nonresponse triggers a failure. A sample configure is
      shown below:
    </p><pre class="programlisting">ping 10.0.0.1
respawn hacluster /usr/lib64/heartbeat/ipfail
apiauth ipfail gid=haclient uid=hacluster
deadping 5</pre><p>
      In the above example, the <span><strong class="command">ipfail</strong></span> command, which
      is part of the Heartbeat solution, is called on a failure and
      'fakes' a fault on the currently active server. You need to
      configure the user and group ID under which the command should be
      executed (using the <code class="literal">apiauth</code>). The failure will
      be triggered after 5 seconds.
    </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
        The <code class="literal">deadping</code> value must be less than the
        <code class="literal">deadtime</code> value.
      </p></div><p>
      The <code class="filename">authkeys</code> file holds the authorization
      information for the Heartbeat cluster. The authorization relies on
      a single unique 'key' that is used to verify the two machines in
      the Heartbeat cluster. The file is used only to confirm that the
      two machines are in the same cluster and is used to ensure that
      the multiple clusters can co-exist within the same network.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-heartbeat-drbd"></a>14.2.2. Using Heartbeat with MySQL and DRBD</h3></div></div></div><p>
      To use Heartbeat in combination with MySQL you should be using
      DRBD (see <a href="ha-overview.html#ha-drbd" title="14.1. Using MySQL with DRBD">Section 14.1, “Using MySQL with DRBD”</a>) or another solution that
      allows for sharing of the MySQL database files in event of a
      system failure. In these examples, DRBD is used as the data
      sharing solution.
    </p><p>
      Heartbeat manages the configuration of different resources to
      manage the switching between two servers in the event of a
      failure. The resource configuration defines the individual
      services that should be brought up (or taken down) in the event of
      a failure.
    </p><p>
      The <code class="filename">haresources</code> file within
      <code class="filename">/etc/ha.d</code> defines the resources that should
      be managed, and the individual resource mentioned in this file in
      turn relates to scripts located within
      <code class="filename">/etc/ha.d/resource.d</code>. The resource definition
      is defined all on one line:
    </p><pre class="programlisting">drbd1 drbddisk Filesystem::/dev/drbd0::/drbd::ext3 mysql 10.0.0.100</pre><p>
      The line is notionally split by whitespace. The first entry
      (<code class="literal">drbd1</code>) is the name of the preferred host; that
      is the server that is normally responsible for handling the
      service. The last field is virtual IP address or name that should
      be used to share the service. This is the IP address that should
      be used to connect to the MySQL server. It will automatically be
      allocated to the server that is active when Heartbeat starts.
    </p><p>
      The remaining fields between these two fields define the resources
      that should be managed. Each Field should contain the name of the
      resource (and each name should refer to a script within
      <code class="filename">/etc/ha.d/resource.d</code>). In the event of a
      failure, these resources are started on the backup server by
      calling the corresponding script (with a single argument,
      <code class="literal">start</code>), in order from left to right. If there
      are additional arguments to the script, you can use a double colon
      to separate each additional argument.
    </p><p>
      In the above example, we manage the following resources:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          <code class="literal">drbddisk</code> — the DRBD resource script,
          this will switch the DRBD disk on the secondary host into
          primary mode, making the device read/write.
        </p></li><li><p>
          <code class="literal">Filesystem</code> — manages the Filesystem
          resource. In this case we have supplied additional arguments
          to specify the DRBD device, mount point and file system type.
          When executed this should mount the specified file system.
        </p></li><li><p>
          <code class="literal">mysql</code> — manages the MySQL instances
          and starts the MySQL server. You should copy the
          <code class="filename">mysql.resource</code> file from the
          <code class="filename">support-files</code> directory from any MySQL
          release into the <code class="filename">/etc/ha.d/resources.d</code>
          directory.
        </p><p>
          If this file is not available in your distribution, you can
          use the following as the contents of the
          <code class="filename">/etc/ha.d/resource.d/mysql.resource</code> file:
        </p><pre class="programlisting">#!/bin/bash
#
# This script is inteded to be used as resource script by heartbeat
#
# Mar 2006 by Monty Taylor
#
###

. /etc/ha.d/shellfuncs

case "$1" in
    start)
        res=`/etc/init.d/mysql start`
        ret=$?
        ha_log $res
        exit $ret
        ;;
    stop)
        res=`/etc/init.d/mysql stop`
        ret=$?
        ha_log $res
        exit $ret
        ;;
    status)
        if [ `ps -ef | grep '[m]ysqld'` ] ; then
           echo "running"
        else
           echo "stopped"
        fi
        ;;
    *)
        echo "Usage: mysql {start|stop|status}"
        exit 1
        ;;
esac

exit 0
        </pre></li></ul></div><p>
      If you want to be notified of the failure by email, you can add
      another line to the <code class="filename">haresources</code> file with the
      address for warnings and the warning text:
    </p><pre class="programlisting">MailTo::youremail@address.com::DRBDFailure</pre><p>
      With the Heartbeat configuration in place, copy the
      <code class="filename">haresources</code>, <code class="filename">authkeys</code>
      and <code class="filename">ha.cf</code> files from your primary and
      secondary servers to make sure that the configuration is
      identical. Then start the Heartbeat service, either by calling
      <code class="filename">/etc/init.d/heartbeat start</code> or by rebooting
      both primary and secondary servers.
    </p><p>
      You can test the configuration by running a manual failover,
      connect to the primary node and run:
    </p><pre class="programlisting">root-shell&gt; /usr/lib64/heartbeat/hb_standby</pre><p>
      This will cause the current node to relinquish its resources
      cleanly to the other node.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-heartbeat-drbd-dopd"></a>14.2.3. Using Heartbeat with DRBD and <span><strong class="command">dopd</strong></span></h3></div></div></div><p>
      As a further extension to using DRBD and Heartbeat together, you
      can enable <span><strong class="command">dopd</strong></span>. The <span><strong class="command">dopd</strong></span>
      daemon handles the situation where a DRBD node is out of date
      compared to the master and prevents the slave from being promoted
      to master in the event of a failure. This stops a situation where
      you have two machines that have been masters ending up different
      data on the underlying device.
    </p><p>
      For example, imagine that you have a two server DRBD setup, master
      and slave. If the DRBD connectivity between master and slave fails
      then the slave would be out of the sync with the master. If
      Heartbeat identifies a connectivity issue for master and then
      switches over to the slave, the slave DRBD device will be promoted
      to the primary device, even though the data on the slave and the
      master is not in synchronization.
    </p><p>
      In this situation, with <span><strong class="command">dopd</strong></span> enabled, the
      connectivity failure between the master and slave would be
      identified and the metadata on the slave would be set to
      <code class="literal">Outdated</code>. Heartbeat will then refuse to switch
      over to the slave even if the master failed. In a dual-host
      solution this would effectively render the cluster out of action,
      as there is no additional fail over server. In an HA cluster with
      three or more servers, control would be passed to the slave that
      has an up to date version of the DRBD device data.
    </p><p>
      To enable <span><strong class="command">dopd</strong></span>, you need to modify the
      Heartbeat configuration and specify <span><strong class="command">dopd</strong></span> as
      part of the commands executed during the monitoring process. Add
      the following lines to your <code class="filename">ha.cf</code> file:
    </p><pre class="programlisting">respawn hacluster /usr/lib/heartbeat/dopd
apiauth dopd gid=haclient uid=hacluster</pre><p>
      Make sure you make the same modification on both your primary and
      secondary nodes.
    </p><p>
      You will need to reload the Heartbeat configuration:
    </p><pre class="programlisting">root-shell&gt; /etc/init.d/heartbeat reload</pre><p>
      You will also need to modify your DRBD configuration by
      configuration the <code class="literal">outdate-peer</code> option. You will
      need to add the configuration line into the
      <code class="literal">common</code> section of
      <code class="filename">/etc/drbd.conf</code> on both hosts. An example of
      the full block is shown below:
    </p><pre class="programlisting">common {
  handlers {
    outdate-peer "/usr/lib/heartbeat/drbd-peer-outdater";
  }
}</pre><p>
      Finally, set the <code class="literal">fencing</code> option on your DRBD
      configured resources:
    </p><pre class="programlisting">resource my-resource {
  disk {
    fencing    resource-only;
  }
}</pre><p>
      Now reload your DRBD configuration:
    </p><pre class="programlisting">root-shell&gt; drbdadmin adjust all</pre><p>
      You can test the system by unplugging your DRBD link and
      monitoring the output from <code class="filename">/proc/drbd</code>.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-heartbeat-errors"></a>14.2.4. Dealing with System Level Errors</h3></div></div></div><p>
      Because a kernel panic or oops may indicate potential problem with
      your server, you should configure your server to remove itself
      from the cluster in the event of a problem. Typically on a kernel
      panic your system will automatically trigger a hard reboot. For a
      kernel oops a reboot may not happen automatically, but the issue
      that caused that oops may still lead to potential problems.
    </p><p>
      You can force a reboot by setting the
      <code class="literal">kernel.panic</code> and
      <code class="literal">kernel.panic_on_oops</code> parameters of the kernel
      control file <code class="filename">/etc/sysctl.conf</code>. For example:
    </p><pre class="programlisting"> kernel.panic_on_oops = 1
 kernel.panic = 1
  </pre><p>
      You can also set these parameters during runtime by using the
      <span><strong class="command">sysctl</strong></span> command. You can either specify the
      parameters on the command line:
    </p><pre class="programlisting">shell&gt; sysctl -w kernel.panic=1
  </pre><p>
      Or you can edit your <code class="filename">sysctl.conf</code> file and
      then reload the configuration information:
    </p><pre class="programlisting">shell&gt; sysctl -p
 </pre><p>
      By setting both these parameters to a positive value (actually the
      number of seconds to wait before triggering the reboot), the
      system will reboot. Your second heartbeat node should then detect
      that the server is down and then switch over to the failover host.
    </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ha-vm"></a>14.3. MySQL and Virtualization</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-vm-commonissues">14.3.1. Common Issues with Virtualization</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-aws">14.3.2. Using MySQL within an Amazon EC2 Instance</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-resources">14.3.3. Virtualization Resources</a></span></dt></dl></div><p>
    Using virtualization can be an effective way of better utilizing the
    hardware of your machine when using MySQL, or to provide improved
    security or isolation of different instances of MySQL on the same
    machine. In some circumstances, virtualization may be a suitable
    solution for scaling out your database environment by enabling you
    to easily deploy additional instances of a pre-configured MySQL
    server and application environment to new virtualization hosts.
  </p><p>
    With any virtualization solution there is often a tradeoff between
    the flexibility and ease of deployment and performance, or between
    the potential performance advantage and complexities of effectively
    configuring multiple instances of MySQL to reside within a single
    physical host.
  </p><p>
    Different issues are experienced according to the virtualization
    environment you are using. Virtualization generally falls into one
    of the following categories:
  </p><div class="itemizedlist"><ul type="disc"><li><p>
        <span class="bold"><strong>Native virtualization</strong></span>,
        including products like VMware Workstation, Parallels
        Desktop/Parallels Workstation, Microsoft Virtual PC and
        VirtualBox, all work by acting as an application that runs
        within an existing operating system environment. Recent versions
        can take advantage of the virtualization extensions in the Intel
        and AMD CPUs to help improve performance.
      </p><p>
        The application-based solutions have a number of advantages,
        including the ability to prioritize CPU usage (including
        multiple CPUs) and easily run multiple virtualized environments
        simultaneously.
      </p><p>
        With these solutions, you also have the ability to easily create
        a virtualized environment that can be packaged and shared among
        different virtualization hosts. For example, you can create a
        MySQL environment and configuration that can be deployed
        multiple times to help extend an existing scalability or HA
        environment.
      </p><p>
        The major disadvantage of this type of virtualization
        environment is the effect of the host on the performance of the
        virtualization instances. Disk storage is typically provided by
        using one or more files on the host OS which are then emulated
        to provide physical disks within the virtual instance. Other
        resources on the host are similarly shared, including CPU,
        network interfaces and additional devices (USB). It is also
        difficult to directly share lower-level components, such as PCI
        devices and that the ability to take advantage of RAID storage
        solutions.
      </p></li><li><p>
        <span class="bold"><strong>Paravirtualization
        (Hypervisor)</strong></span>, including Xen, Solaris xVM (based on
        Xen), VMware ESX Server, Windows Server 2008 Hyper-V, and
        Solaris Logical Domains (LDOM), work by running a specialized
        version of the host operating system. The host OS then allows
        slightly modified versions of different operating systems to run
        within the virtualized environment.
      </p><p>
        With paravirtualization, the level of performance and the
        control over the underlying hardware used to support the
        virtualized environments is higher than native virtualization
        solutions. For example, using paravirtualization you can
        dedicate individual CPU cores, RAM, disk drives and even PCI
        devices to be accessible to individual and specific virtual
        instances.
      </p><p>
        For example, within a paravirtualized environment you could
        dedicate a physical disk drive or subsystem to a particular
        virtual environment and gain a performance benefit over a
        typical file-based solution virtual disk.
      </p></li><li><p>
        <span class="bold"><strong>Operating system-level
        virtualization</strong></span>, including BSD jails, and Solaris
        Containers/Zones, offer methods for isolating different
        instances of an operating system environment while sharing the
        same hardware environment. Unlike the other virtualization
        solutions, operating system level virtualization is not normally
        used to run other operating systems, but instead to provide a
        level of security isolation and resource control within the core
        operating environment.
      </p><p>
        The isolation of these different instances is the key advantage
        of this type of virtualization. Each virtualized instance sees
        its environment as if it were completely different system. The
        solution can be an effective method to provide isolated
        computing resources for different departments or users, or to
        provide unique instances for testing and development.
      </p></li></ul></div><p>
    The main reasons for using virtualization, particularly with a
    database or an application stack that includes a database component,
    include:
  </p><div class="itemizedlist"><ul type="disc"><li><p>
        <span class="bold"><strong>Security</strong></span> — separate
        instances of different operating systems running within a single
        host but with effective isolation from each other. When used
        with MySQL, you can provide an increased level of security
        between different instances of each server.
      </p></li><li><p>
        <span class="bold"><strong>Consolidation</strong></span> — merging a
        number of individual systems with a relatively small load onto a
        single, larger, server. This can help reduce footprint and
        energy costs, or make more efficient use of a larger machine.
        Performance is the main issue with this solution as the load of
        many MySQL databases running in individual virtual instances on
        a single machine can be considerable.
      </p></li><li><p>
        <span class="bold"><strong>Development/QA/Testing</strong></span> —
        by creating different instances of different environments and
        operating systems you can test your MySQL-based application in
        different environments.
      </p></li><li><p>
        <span class="bold"><strong>Scalability</strong></span> — although
        using virtualization imposes a performance hit, many
        virtualization solutions allow you to create a packaged version
        of an environment, including MySQL and the other application
        components. By distributing the virtualization environment
        package to new hosts you can often very quickly scale out by
        adding new hosts and deploying the virtualized environment.
      </p></li></ul></div><p>
    The remainder of this chapter looks at common issues with using
    MySQL in a virtualized environment and tips for using MySQL within
    different virtualization tools.
  </p><p>
    For advice on common issues and problems, including performance and
    configuration issues, when using virtualized instances, see
    <a href="ha-overview.html#ha-vm-commonissues" title="14.3.1. Common Issues with Virtualization">Section 14.3.1, “Common Issues with Virtualization”</a>.
  </p><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-vm-commonissues"></a>14.3.1. Common Issues with Virtualization</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-vm-commonissues-performance">14.3.1.1. Virtualization Performance Issues</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-commonissues-storage">14.3.1.2. Virtualization Storage Issues</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-commonissues-networking">14.3.1.3. Virtualization Networking Issues</a></span></dt></dl></div><p>
      There are many issues related to using MySQL within a virtualized
      environment that are common across the different virtualization
      types. Most are directly related to the performance or security of
      the environment in which you are deploying the MySQL server
      compared to the host on which you are running the virtualization
      solution.
    </p><p>
      Before deciding to use virtualization as a solution for your
      database, you should ensure that the expected load for the server
      and the expected performance when run in a virtualized environment
      meet your needs and requirements.
    </p><p>
      To help you determine the issues and some of the potential
      solutions, use the following sections:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          For general performance issues, problems and the probable
          causes, see <a href="ha-overview.html#ha-vm-commonissues-performance" title="14.3.1.1. Virtualization Performance Issues">Section 14.3.1.1, “Virtualization Performance Issues”</a>.
        </p></li><li><p>
          Disk and storage concerns directly affect database storage
          because most database access is limited by the I/O bandwidth.
          For some examples and issues, see
          <a href="ha-overview.html#ha-vm-commonissues-storage" title="14.3.1.2. Virtualization Storage Issues">Section 14.3.1.2, “Virtualization Storage Issues”</a>.
        </p></li><li><p>
          Issues related to network configuration and performance may
          need more careful planning, especially if you are using
          network-specific technologies such as MySQL replication. For
          further examples and details, see
          <a href="ha-overview.html#ha-vm-commonissues-networking" title="14.3.1.3. Virtualization Networking Issues">Section 14.3.1.3, “Virtualization Networking Issues”</a>.
        </p></li></ul></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-vm-commonissues-performance"></a>14.3.1.1. Virtualization Performance Issues</h4></div></div></div><p>
        Often the biggest consideration is the performance of a
        virtualized environment once hosted. In most cases, the
        virtualized environment involves some level of emulation of one
        or more of the hardware interfaces (CPU, network or disk) of the
        host environment. The effect is to reduce the effective
        performance of the virtualized environment compared to running
        an application natively on the host.
      </p><p>
        Some core resourcing issues to be aware of include:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            Using virtualization does not reduce the amount of CPU
            required to support a particular application or environment.
            If your application stack requires 2GB of RAM on an
            individual machine, the same RAM requirement will apply
            within your virtualized environment. The additional overhead
            of the virtualization layer and host operating system or
            environment often mean that you will need 2.5GB or 3GB of
            RAM to run the same application within the virtualized
            environment.
          </p><p>
            You should configure your virtualization environment with
            the correct RAM allocation according to your applications
            needs, and not to maximize the number of virtualized
            environments that you can execute within the virtualization
            host.
          </p></li><li><p>
            Virtualization of the CPU resources is more complex. If your
            MySQL database and application stack do not have a high CPU
            load, then consolidating multiple environments onto a single
            host is often more efficient. You should keep in mind that
            at peak times your application and database CPU requirement
            may need to grow beyond your default allocation.
          </p><p>
            With some virtualization environments (Xen, Solaris
            Containers, Solaris LDOMs) you can dedicate CPU or core to a
            virtual instance. You should use this functionality to
            improve performance for database or application loads that
            have a high constant CPU requirement as the performance
            benefit will outweigh the flexibility of dynamic allocation
            of the CPU resources.
          </p></li><li><p>
            Contention of resources within the host should be taken into
            account. In a system with high CPU loads, even when
            dedicating RAM and CPU resources, the I/O channels and
            interfaces to storage and networking resources may exceed
            the capacity of the host. Solutions such as Xen and Solaris
            LDOMs dedicate specific resources to individual virtual
            instances, but this will not eliminate the effects of the
            overall load on the host.
          </p></li><li><p>
            If your database application is time sensitive, including
            logging and real-time database applications, or you are
            using MySQL Cluster, then the effects of virtualization may
            severely reduce the performance of your application. Because
            of the way the virtualized instances are executed and shared
            between CPUs and the effects of load on other resources, the
            response times for your database or application may be much
            higher than normal. This is especially true if you are
            running a large number of virtualized instances on a single
            host.
          </p></li><li><p>
            Be aware of the limitation of using a single host to run
            multiple virtualized instances. In the event of a machine or
            component failure, the problem will affect more than just
            one database instance. For example, a failure in a storage
            device could bring down all your virtualized instances.
            Using a RAID solution that supports fault tolerance (RAID
            levels 1,3,4,5 or 6) will help protect you from the effects
            of this.
          </p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-vm-commonissues-storage"></a>14.3.1.2. Virtualization Storage Issues</h4></div></div></div><p>
        Due to the random I/O nature of any database solution, running
        MySQL within a virtualized environment places a heavy load on
        the storage solution you are using. To help keep the performance
        of your virtualized solution at the highest level, you should
        use the following notes to help configure your systems.
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            Some virtualization solutions allow you to use a physical
            disk directly within your virtual host as if it were a local
            disk. You should use this whenever possible to ensure that
            disk contention issues do not affect the performance of your
            virtual environment.
          </p><p>
            When running multiple virtual machines, you should use an
            individual disk for each virtual instance. Using a single
            disk and multiple partitions, with each partition dedicated
            to a virtual host, will lead to the same contention issues.
          </p></li><li><p>
            If you are using standard file-based storage for your
            virtualized disks:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                File-based storage is subject to fragmentation on the
                host disk. To prevent fragmentation, create a fixed-size
                disk (that is, one where the entire space for the disk
                file is preallocated) instead of a dynamic disk that
                will grow with usage. Also be prepared to defragment the
                disk hosting the files at regular intervals to reduce
                the fragmentation.
              </p></li><li><p>
                Use separate disk files for the operating system and
                database disks, and try to avoid partitioning a disk
                file as this increases the contention within the file.
              </p></li><li><p>
                Use a high-performance disk solution, such as RAID or
                SAN, to store the disk files for your virtualized
                environments. This will improve the performance of what
                is essentially a large single file on a physical device.
              </p></li><li><p>
                When running a number of different virtualized
                environments within a single host, do not use the same
                physical host drive for multiple virtual disks. Instead,
                spread the virtual disks among multiple physical disks.
                Even when using a RAID device, be aware that each
                virtual host is equivalent to increasing the load
                linearly on the host RAID device.
              </p></li></ul></div></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-vm-commonissues-networking"></a>14.3.1.3. Virtualization Networking Issues</h4></div></div></div><p>
        When running multiple virtual machines on a host, you should be
        aware of the networking implications of each virtualized
        instance. If your host machine has only one network card, then
        you will be sharing the networking throughput for all of your
        machines through only one card, and this may severely limit the
        performance of your virtual environments.
      </p><p>
        If possible, you should use multiple network cards to support
        your virtualized instances. Depending on the expected load of
        each instance, you should dedicate or spread the allocation of
        the virtual network devices across these physical devices to
        ensure that you do not reach saturation.
      </p><p>
        If you are using packaged virtual machines as the basis for
        deployment of your MySQL database solution, you should make sure
        that the network interfaces are correctly reconfigured. Some
        solutions duplicate the hardware MAC address which will cause
        problems when you start up additional instances of the same
        virtualized environment.
      </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-vm-aws"></a>14.3.2. Using MySQL within an Amazon EC2 Instance</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-setup">14.3.2.1. Setting Up MySQL on an EC2 AMI</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-instance">14.3.2.2. EC2 Instance Limitations</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-vm-aws-deploy">14.3.2.3. Deploying a MySQL Database Using EC2</a></span></dt></dl></div><p>
      The Amazon Elastic Compute Cloud (EC2) service provides virtual
      servers that you can build and deploy to run a variety of
      different applications and services, including MySQL. The EC2
      service is based around the Xen framework, supporting x86, Linux
      based, platforms with individual instances of a virtual machine
      referred to as an Amazon Machine Image (AMI). You have complete
      (root) access to the AMI instance that you create, allowing you to
      configure and install your AMI in any way you choose.
    </p><p>
      To use EC2, you create an AMI based on the configuration and
      applications that you want to use and upload the AMI to the Amazon
      Simple Storage Service (S3). From the S3 resource, you can deploy
      one or more copies of the AMI to run as an instance within the EC2
      environment. The EC2 environment provides management and control
      of the instance and contextual information about the instance
      while it is running.
    </p><p>
      Because you can create and control the AMI, the configuration, and
      the applications, you can deploy and create any environment you
      choose. This includes a basic MySQL server in addition to more
      extensive replication, HA and scalability scenarios that enable
      you to take advantage of the EC2 environment, and the ability to
      deploy additional instances as the demand for your MySQL services
      and applications grow.
    </p><p>
      To aid the deployment and distribution of work, three different
      Amazon EC2 instances are available, small (identified as
      <code class="literal">m1.small</code>), large (<code class="literal">m1.large</code>)
      and extra large (<code class="literal">m1.xlarge</code>). The different
      types provide different levels of computing power measured in EC2
      computer units (ECU). A summary of the different instance
      configurations is shown here.
    </p><div class="informaltable"><table border="1"><colgroup><col><col><col><col></colgroup><thead><tr><th> </th><th>Small</th><th>Large</th><th>Extra Large</th></tr></thead><tbody><tr><td>Platform</td><td>32-bit</td><td>64-bit</td><td>64-bit</td></tr><tr><td>CPU cores</td><td>1</td><td>2</td><td>4</td></tr><tr><td>ECUs</td><td>1</td><td>4</td><td>8</td></tr><tr><td>RAM</td><td>1.7GB</td><td>7.5GB</td><td>15GB</td></tr><tr><td>Storage</td><td>150GB</td><td>840GB</td><td>1680GB</td></tr><tr><td>I/O Performance</td><td>Medium</td><td>High</td><td>High</td></tr></tbody></table></div><p>
      The typical model for deploying and using MySQL within the EC2
      environment is to create a basic AMI that you can use to hold your
      database data and application. Once the basic environment for your
      database and application has been created you can then choose to
      deploy the AMI to a suitable instance. Here the flexibility of
      having an AMI that can be re-deployed from the small to the large
      or extra large EC2 instance makes it easy to upgrade the hardware
      environment without rebuilding your application or database stack.
    </p><p>
      To get started with MySQL on EC2, including information on how to
      set up and install MySQL within an EC2 installation and how to
      port and migrate your data to the running instance, see
      <a href="ha-overview.html#ha-vm-aws-setup" title="14.3.2.1. Setting Up MySQL on an EC2 AMI">Section 14.3.2.1, “Setting Up MySQL on an EC2 AMI”</a>.
    </p><p>
      For tips and advice on how to create a scalable EC2 environment
      using MySQL, including guides on setting up replication, see
      <a href="ha-overview.html#ha-vm-aws-deploy" title="14.3.2.3. Deploying a MySQL Database Using EC2">Section 14.3.2.3, “Deploying a MySQL Database Using EC2”</a>.
    </p><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-vm-aws-setup"></a>14.3.2.1. Setting Up MySQL on an EC2 AMI</h4></div></div></div><p>
        There are many different ways of setting up an EC2 AMI with
        MySQL, including using any of the pre-configured AMIs supplied
        by Amazon.
      </p><p>
        The default <span class="emphasis"><em>Getting Started</em></span> AMI provided by
        Amazon uses Fedora Core 4, and you can install MySQL by using
        <span><strong class="command">yum</strong></span>:
      </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>yum install mysql</code></strong></pre><p>
        This will install both the MySQL server and the Perl DBD::mysql
        driver for the Perl DBI API.
      </p><p>
        Alternatively, you can use one of the AMIs that include MySQL
        within the standard installation.
      </p><p>
        Finally, you can also install a standard version of MySQL
        downloaded from the MySQL website. The installation process and
        instructions are identical to any other installation of MySQL on
        Linux. See <a href="installing.html" title="Chapter 2. Installing and Upgrading MySQL">Chapter 2, <i>Installing and Upgrading MySQL</i></a>.
      </p><p>
        The standard configuration for MySQL places the data files in
        the default location, <code class="filename">/var/lib/mysql</code>. The
        default data directory on an EC2 instance is
        <code class="filename">/mnt</code> (although on the large and extra large
        instance you can alter this configuration). You must edit
        <code class="filename">/etc/my.cnf</code> to set the
        <a href="server-administration.html#option_mysqld_datadir"><code class="option">datadir</code></a> option to point to the
        larger storage area.
      </p><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3><p>
          The first time you use the main storage location within an EC2
          instance it needs to be initialized. The initialization
          process starts automatically the first time you write to the
          device. You can start using the device right away, but the
          write performance of the new device is significantly lower on
          the initial writes until the initialization process has
          finished.
        </p><p>
          To avoid this problem when setting up a new instance, you
          should start the initialization process before populating your
          MySQL database. One way to do this is to use
          <span><strong class="command">dd</strong></span> to write to the file system:
        </p><pre class="programlisting">root-shell&gt; <strong class="userinput"><code>dd if=/dev/zero of=initialize bs=1024M count=50</code></strong></pre><p>
          The preceding will create a 50GB on the file system and start
          the initialization process. You should delete the file once
          the process has finished.
        </p><p>
          The initialization process can be time-consuming. On the small
          instance, initialization will take between two and three
          hours. For the large and extra large drives, the
          initialization will be 10 or 20 hours, respectively.
        </p></div><p>
        In addition to configuring the correct storage location for your
        MySQL data files, you should also consider setting the following
        other settings in your instance before you save the instance
        configuration for deployment:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            Set the MySQL server ID so that when you use it for
            replication the ID information is set correctly.
          </p></li><li><p>
            Enabling binary logging so that replication can be
            initialized without starting and stopping the server.
          </p></li><li><p>
            Set the caching and memory parameters for your storage
            engines. There are no limitations or restrictions on what
            storage engines you use in your EC2 environment. Choose a
            configuration, possibly using one of the standard
            configurations provided with MySQL appropriate for the
            instance on which you expect to deploy. The large and extra
            large instances have RAM that can be dedicated to caching.
            Be aware that if you choose to install
            <span><strong class="command">memcached</strong></span> on the servers as part of your
            application stack you must ensure there is enough memory for
            both MySQL and <span><strong class="command">memcached</strong></span>.
          </p></li></ul></div><p>
        Once you have configured your AMI with MySQL and the rest of
        your application stack, you should save the AMI so that you can
        deploy and reuse the instance.
      </p><p>
        Once you have your application stack configured in an AMI,
        populating your MySQL database with data should be performed by
        creating a dump of your database using
        <code class="literal">mysqldump</code>, transferring the dump to the EC2
        instance, and then reloading the information into the EC2
        instance database.
      </p><p>
        Before using your instance with your application in a production
        situation you should be aware of the limitations of the EC2
        instance environment. See <a href="ha-overview.html#ha-vm-aws-instance" title="14.3.2.2. EC2 Instance Limitations">Section 14.3.2.2, “EC2 Instance Limitations”</a>.
        To begin using your MySQL AMI, you should consult the notes on
        deployment. See <a href="ha-overview.html#ha-vm-aws-deploy" title="14.3.2.3. Deploying a MySQL Database Using EC2">Section 14.3.2.3, “Deploying a MySQL Database Using EC2”</a>.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-vm-aws-instance"></a>14.3.2.2. EC2 Instance Limitations</h4></div></div></div><p>
        There are some limitations of the EC2 instances that you should
        be aware of before deploying your applications. Although these
        shouldn't affect your ability to deploy within the Amazon EC2
        environment, they may alter the way you setup and configure your
        environment to support your application.
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            Data stored within instances is not persistent. If you
            create an instance and populate the instance with data, then
            the data will only remain in place while the machine is
            running. The data will survive a reboot. If you shut down
            the instance, any data it contained will be lost.
          </p><p>
            To ensure that you do not lose information, take regular
            backups using <a href="programs.html#mysqldump" title="4.5.4. mysqldump — A Database Backup Program"><span><strong class="command">mysqldump</strong></span></a>. If the data
            being stored is critical, consider using replication to keep
            a “<span class="quote">live</span>” backup of your data in the event of a
            failure. When creating a backup, write the data to the
            Amazon S3 service to avoid the transfer charges applied when
            copying data offsite.
          </p></li><li><p>
            EC2 instances are not persistent. If the hardware on which
            an instance is running fails, then the instance will be shut
            down. This can lead to loss of data or service.
          </p></li><li><p>
            If you want to use replication with your EC2 instances to a
            non-EC2 environment, be aware of the transfer costs to and
            from the EC2 service. Data transfer between different EC2
            instances is free, so using replication within the EC2
            environment does not incur additional charges.
          </p></li><li><p>
            Certain HA features are either not directly supported, or
            have limiting factors or problems that may reduce their
            utility. For example, using DRBD or MySQL Cluster may not
            work. The default storage configuration is also not
            redundant. You can use software-based RAID to improve
            redundancy, but this implies a further performance hit.
          </p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-vm-aws-deploy"></a>14.3.2.3. Deploying a MySQL Database Using EC2</h4></div></div></div><p>
        Because you cannot guarantee the uptime and availability of your
        EC2 instances, when deploying MySQL within the EC2 environment
        you should use an approach that enables you to easily distribute
        work among your EC2 instances. There are a number of ways of
        doing this. Using sharding techniques, where you split the
        application across multiple servers dedicating specific blocks
        of your dataset and users to different servers is an effective
        way of doing this. As a general rule, it is easier to create
        more EC2 instances to support more users than to upgrade the
        instance to a larger machine.
      </p><p>
        The EC2 architecture means that you should treat the EC2
        instances as temporary, cache-based solutions, rather than as a
        long-term, high availability solution. In addition to using
        multiple machines, you should also take advantage of other
        services, such as <span><strong class="command">memcached</strong></span> to provide
        additional caching for your application to help reduce the load
        on the MySQL server so that it can concentrate on writes. On the
        large and extra large instances within EC2, the RAM available
        can be used to provide a large memory cache for data.
      </p><p>
        Most types of scale out topology that you would use with your
        own hardware can be used and applied within the EC2 environment.
        However, you should be use the limitations and advice already
        given to ensure that any potential failures do not lose you any
        data. Also, because the relative power of each EC2 instance is
        so low, you should be prepared to alter your application to use
        sharding and add further EC2 instances to improve the
        performance of your application.
      </p><p>
        For example, take the typical scale-out environment shown
        following, where a single master replicates to one or more
        slaves (three in this example), with a web server running on
        each replication slave.
      </p><div class="mediaobject"><img src="images/ec2fig1.png" width="493" height="167" alt="Typical standard scale out
          structure"></div><p>
        You can reproduce this structure completely within the EC2
        environment, using an EC2 instance for the master, and one
        instance for each of the web and MySQL slave servers.
      </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          Within the EC2 environment, internal (private) IP addresses
          used by the EC2 instances are constant. You should always use
          these internal addresses and names when communicating between
          instances. Only use public IP addresses when communicating
          with the outside world - for example, when publicizing your
          application.
        </p></div><p>
        To ensure reliability of your database, you should add at least
        one replication slave dedicated to providing an active backup
        and storage to the Amazon S3 facility. You can see an example of
        this in the following topology.
      </p><div class="mediaobject"><img src="images/ec2fig2.png" width="493" height="433" alt="Typical standard scale out structure with
          backup using EC2"></div><p>
        <span class="bold"><strong>Using
        <span><strong class="command">memcached</strong></span></strong></span> within your EC2
        instances should provide better performance. The large and extra
        large instances have a significant amount of RAM. To use
        <span><strong class="command">memcached</strong></span> in your application, when loading
        information from the database, first check whether the item
        exists in the cache. If the data you are looking for exists in
        the cache, use it. If not, reload the data from the database and
        populate the cache.
      </p><p>
        <span class="bold"><strong>Sharding</strong></span> divides up data in
        your entire database by allocating individual machines or
        machine groups to provide a unique set of data according to an
        appropriate group. For example, you might put all users with a
        surname ending in the letters A-D onto a single server. When a
        user connects to the application and their surname is known,
        queries can be redirected to the appropriate MySQL server.
      </p><p>
        When using sharding with EC2 you should separate the web server
        and MySQL server into separate EC2 instances, and then apply the
        sharding decision logic into your application. Once you know
        which MySQL server you should be using for accessing the data
        you then distribute queries to the appropriate server. You can
        see a sample of this in the following illustration.
      </p><div class="mediaobject"><img src="images/ec2fig3.png" width="493" height="333" alt="Using sharding in EC2 to spread the
          load"></div><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>
          With sharding and EC2 you should be careful that the potential
          for failure of an instance does not affect your application.
          If the EC2 instance that provides the MySQL server for a
          particular shard fails, then all of the data on that shard
          will be unavailable.
        </p></div></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-vm-resources"></a>14.3.3. Virtualization Resources</h3></div></div></div><p>
      For more information on virtualization, see the following links:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          <a href="http://forums.mysql.com/list.php?149" target="_top">MySQL Virtualization
          Forum</a>
        </p></li><li><p>
          <a href="http://aws.amazon.com/ec2" target="_top">Amazon Elastic Compute
          Cloud (Amazon EC2)</a>
        </p></li><li><p>
          <a href="http://www.mysql.com/products/enterprise/cloud.html" target="_top">MySQL
          and Cloud Computing</a>
        </p></li><li><p>
          <a href="http://www.mysql.com/products/enterprise/ec2.html" target="_top">MySQL
          Enterprise for Amazon EC2</a>
        </p></li></ul></div></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ha-zfs-replication"></a>14.4. Using ZFS Replication</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-zfs-config">14.4.1. Using ZFS for Filesystem Replication</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-zfs-mysql">14.4.2. Configurating MySQL for ZFS Replication</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-zfs-mysql-recovery">14.4.3. Handling MySQL Recovery with ZFS</a></span></dt></dl></div><p>
    To support high availability environments, providing an instant copy
    of the information on both the currently active machine and the hot
    backup is a critical part of the HA solution. There are many
    solutions to this problem, including <a href="replication.html" title="Chapter 16. Replication">Chapter 16, <i>Replication</i></a>
    and <a href="ha-overview.html#ha-drbd" title="14.1. Using MySQL with DRBD">Section 14.1, “Using MySQL with DRBD”</a>.
  </p><p>
    The ZFS filesystem provides functionality that allows you to create
    a snapshot of the filesystem contents and to then transfer the
    snapshot to another machine and extract the snapshot to recreate the
    filesystem. You can create a snapshot at any time, and you can
    create as many snapshots as you like. By continually creating,
    transferring and restoring snapshots you can provide synchronization
    between one ore more machines in a fashion similar to DRBD.
  </p><p>
    To understand the replication solution within ZFS, you must first
    understand the ZFS environment. Below is a simple OpenSolaris system
    running with two pools, the <code class="literal">root</code> pool and another
    pool mounted at <code class="literal">/opt</code>:
  </p><pre class="programlisting">Filesystem             size   used  avail capacity  Mounted on
rpool/ROOT/opensolaris-1
                       7.3G   3.6G   508M    88%    /
/devices                 0K     0K     0K     0%    /devices
/dev                     0K     0K     0K     0%    /dev
ctfs                     0K     0K     0K     0%    /system/contract
proc                     0K     0K     0K     0%    /proc
mnttab                   0K     0K     0K     0%    /etc/mnttab
swap                   465M   312K   465M     1%    /etc/svc/volatile
objfs                    0K     0K     0K     0%    /system/object
sharefs                  0K     0K     0K     0%    /etc/dfs/sharetab
/usr/lib/libc/libc_hwcap1.so.1
                       4.1G   3.6G   508M    88%    /lib/libc.so.1
fd                       0K     0K     0K     0%    /dev/fd
swap                   466M   744K   465M     1%    /tmp
swap                   465M    40K   465M     1%    /var/run
rpool/export           7.3G    19K   508M     1%    /export
rpool/export/home      7.3G   1.5G   508M    75%    /export/home
rpool                  7.3G    60K   508M     1%    /rpool
rpool/ROOT             7.3G    18K   508M     1%    /rpool/ROOT
opt                    7.8G   1.0G   6.8G    14%    /opt
</pre><p>
    The MySQL data will be stored in a directory on
    <code class="literal">/opt</code>. To help demonstrate some of the basic
    replication functionality, there are also other items stored in
    <code class="literal">/opt</code> as well:
  </p><pre class="programlisting">total 17
drwxr-xr-x  31 root     bin           50 Jul 21 07:32 DTT/
drwxr-xr-x   4 root     bin            5 Jul 21 07:32 SUNWmlib/
drwxr-xr-x  14 root     sys           16 Nov  5 09:56 SUNWspro/
drwxrwxrwx  19 1000     1000          40 Nov  6 19:16 emacs-22.1/
</pre><p>
    To create a snapshot of the filesystem, you use <code class="literal">zfs
    snapshot</code>, and then specify the pool and the snapshot name:
  </p><pre class="programlisting">root-shell&gt; zfs snapshot opt@snap1</pre><p>
    To get a list of snapshots already taken:
  </p><pre class="programlisting">root-shell&gt; zfs list -t snapshot
NAME                                         USED  AVAIL  REFER  MOUNTPOINT
opt@snap1                                       0      -  1.03G  -
rpool@install                               19.5K      -    55K  -
rpool/ROOT@install                            15K      -    18K  -
rpool/ROOT/opensolaris-1@install            59.8M      -  2.22G  -
rpool/ROOT/opensolaris-1@opensolaris-1       100M      -  2.29G  -
rpool/ROOT/opensolaris-1/opt@install            0      -  3.61M  -
rpool/ROOT/opensolaris-1/opt@opensolaris-1      0      -  3.61M  -
rpool/export@install                          15K      -    19K  -
rpool/export/home@install                     20K      -    21K  -

</pre><p>
    The snapshots themselves are stored within the filesystem metadata,
    and the space required to keep them will vary as time goes on
    because of the way the snapshots are created. The initial creation
    of a snapshot is really quick, because instead of taking an entire
    copy of the data and metadata required to hold the entire snapshot,
    ZFS merely records the point in time and metadata of when the
    snaphot was created.
  </p><p>
    As more changes to the original filesystem are made, the size of the
    snapshot increases because more space is required to keep the record
    of the old blocks. Furthermore, if you create lots of snapshots, say
    one per day, and then delete the snapshots from earlier in the week,
    the size of the newer snapshots may also increase, as the changes
    that make up the newer state have to be included in the more recent
    snapshots, rather than being spread over the seven snapshots that
    make up the week.
  </p><p>
    The only issue, from a backup perspective, is that snaphots exist
    within the confines of the original filesystem. To get the snapshot
    out into a format that you can copy to another filesystem, tape,
    etc. you use the <code class="literal">zfs send</code> command to create a
    stream version of the snapshot.
  </p><p>
    For example, to write out the snapshot to a file:
  </p><pre class="programlisting">root-shell&gt; zfs send opt@snap1 &gt;/backup/opt-snap1</pre><p>
    Or tape:
  </p><pre class="programlisting">root-shell&gt; zfs send opt@snap1 &gt;/dev/rmt/0</pre><p>
    You can also write out the incremental changes between two snapshots
    using <code class="literal">zfs send</code>:
  </p><pre class="programlisting">root-shell&gt; zfs send opt@snap1 opt@snap2 &gt;/backup/opt-changes</pre><p>
    To recover a snapshot, you use <code class="literal">zfs recv</code> which
    applies the snapshot information either to a new filesytem, or to an
    existing one.
  </p><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-zfs-config"></a>14.4.1. Using ZFS for Filesystem Replication</h3></div></div></div><p>
      Because <code class="literal">zfs send</code> and <code class="literal">zfs
      recv</code> use streams to exchange data, you can use them to
      replicate information from one system to another by combining
      <code class="literal">zfs send</code>, <code class="literal">ssh</code>, and
      <code class="literal">zfs recv</code>.
    </p><p>
      For example, if a snapshot of the <code class="literal">opt</code>
      filesystem has been created and this needs to be copied to a new
      system or filesystem called <code class="literal">slavepool</code>. You
      would use the following command, combining the snapshot of
      <code class="literal">opt</code>, the transmission to the slave machine
      (using <span><strong class="command">ssh</strong></span>), and the recovery of the snapshot
      on the slave using <span><strong class="command">zfs revc</strong></span>:
    </p><pre class="programlisting">root-shell&gt; zfs send opt@snap1 |ssh mc@slave pfexec zfs recv -F slavepool</pre><p>
      The first part, <code class="literal">zfs send opt@snap1</code>, streams the
      snapshot, the second, <code class="literal">ssh mc@slave</code>, and the
      third, <code class="literal">pfexec zfs recv -F slavepool</code>, receives
      the streamed snapshot data and writes it to slavepool. In this
      instance, I've specified the <code class="literal">-F</code> option which
      forces the snapshot data to be applied, and is therefore
      destructive. This is fine, as I'm creating the first version of my
      replicated filesystem.
    </p><p>
      On the slave machine, the replicated filesystem contains the exact
      same content:
    </p><pre class="programlisting">root-shell&gt; ls -al /slavepool/
total 23
drwxr-xr-x   6 root     root           7 Nov  8 09:13 ./
drwxr-xr-x  29 root     root          34 Nov  9 07:06 ../
drwxr-xr-x  31 root     bin           50 Jul 21 07:32 DTT/
drwxr-xr-x   4 root     bin            5 Jul 21 07:32 SUNWmlib/
drwxr-xr-x  14 root     sys           16 Nov  5 09:56 SUNWspro/
drwxrwxrwx  19 1000     1000          40 Nov  6 19:16 emacs-22.1/
</pre><p>
      Once a snapshot has been created, to synchronize the filesystem
      again, you need to create a new snapshot, and then use the
      incremental snapshot feature of <code class="literal">zfs send</code> to
      send the changes between the two snapshots to the slave machine
      again:
    </p><pre class="programlisting">root-shell&gt; zfs send -i opt@snapshot1 opt@snapshot2 |ssh mc@192.168.0.93 pfexec zfs recv slavepool</pre><p>
      Without further modification, this operation will fail. The reason
      is that the filesystem on the slave machine can currently be
      modified, and you can't apply the incremental changes to a
      destination filesystem that has changed. It is the metadata that
      has changed. The metadata about the filesystem, like the last time
      it was accessed - in this case, it will have been our
      <code class="literal">ls</code> that caused the problem.
    </p><p>
      To prevent changes on the slave filesystem, you must set the
      filesystem on the slave to be read-only:
    </p><pre class="programlisting">root-shell&gt; zfs set readonly=on slavepool</pre><p>
      Setting <code class="literal">readonly</code> means that you cannot change
      the filesystem on the slave by normal means, including the
      filesystem metadata. Operations that would normally update
      metadata (like our <code class="literal">ls</code>) will silently perform
      their function without attempting to update the filesystem state.
    </p><p>
      In essence, the slave filesystem is nothing but a static copy of
      the original filesystem. However, even when configured to to be
      read-only, a filesystem can have snapshots applied to it. Now the
      filesystem is read only, re-run the initial copy:
    </p><pre class="programlisting">root-shell&gt; zfs send opt@snap1 |ssh mc@slave pfexec zfs recv -F slavepool</pre><p>
      Now you can make changes to the original filesystem and replicate
      them to the slave.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-zfs-mysql"></a>14.4.2. Configurating MySQL for ZFS Replication</h3></div></div></div><p>
      Configuring MySQL on the source filesystem is a case of creating
      the data on the filesystem that you will be replicating. The
      configuration file in the example below has been updated to use
      <code class="literal">/opt/mysql-data</code> as the data directory, and now
      I can initialize the tables:
    </p><pre class="programlisting">root-shell&gt; mysql_install_db --defaults-file=/etc/mysql/5.0/my.cnf --user=mysql</pre><p>
      To synchronize the initial information, perform a new snapshot and
      then send an incremental snapshot to the slave using <code class="literal">zfs
      send</code>:
    </p><pre class="programlisting">root-shell&gt; zfs snapshot opt@snap2
root-shell&gt; zfs send -i opt@snap1 opt@snap2|ssh mc@192.168.0.93 pfexec zfs recv slavepool
</pre><p>
      Double check that the slave has the data by looking at the MySQL
      data directory on the <code class="literal">slavepool</code>:
    </p><pre class="programlisting">root-shell&gt; ls -al /slavepool/mysql-data/</pre><p>
      Now we can start up MySQL, create some data, and then replicate
      the changes using <code class="literal">zfs send</code>/<code class="literal"> zfs
      recv</code> to the slave to synchronize the changes.
    </p><p>
      The rate at which you perform the synchronization is dependent on
      your application and environment. The limitation is the speed
      required to perform the snapshot and then to send the changes over
      the network.
    </p><p>
      To automate the process, you should create a script that performs
      the snapshot, send, and receive operation, and then use
      <code class="literal">cron</code> to synchronize the changes at set times or
      intervals. For automated operations, see
      <a href="http://blogs.sun.com/timf/entry/zfs_automatic_snapshots_now_with" target="_top">Tim
      Foster's zfs replication tool</a>.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-zfs-mysql-recovery"></a>14.4.3. Handling MySQL Recovery with ZFS</h3></div></div></div><p>
      When using ZFS replication to provide a constant copy of your
      data, you should ensure that you can recover your tables, either
      manually or automatically, in the event of a failure of the
      original system.
    </p><p>
      In the event of a failure, you should follow this sequence:
    </p><div class="orderedlist"><ol type="1"><li><p>
          Stop the script on the master, if it is still up and running.
        </p></li><li><p>
          Set the slave filesystem to be read/write:

</p><pre class="programlisting">root-shell&gt; zfs set readonly=off slavepool </pre><p>
        </p></li><li><p>
          Start up <a href="programs.html#mysqld" title="4.3.1. mysqld — The MySQL Server"><span><strong class="command">mysqld</strong></span></a> on the slave. If you are
          using <code class="literal">InnoDB</code>, <code class="literal">Falcon</code> or
          <code class="literal">Maria</code> you should get auto-recovery, if it
          is needed, to make sure the table data is correct, as shown
          here when I started up from our mid-INSERT snapshot:

</p><pre class="programlisting">InnoDB: The log sequence number in ibdata files does not match
InnoDB: the log sequence number in the ib_logfiles!
081109 15:59:59  InnoDB: Database was not shut down normally!
InnoDB: Starting crash recovery.
InnoDB: Reading tablespace information from the .ibd files...
InnoDB: Restoring possible half-written data pages from the doublewrite
InnoDB: buffer...
081109 16:00:03  InnoDB: Started; log sequence number 0 1142807951
081109 16:00:03 [Note] /slavepool/mysql-5.0.67-solaris10-i386/bin/mysqld: ready for connections.
Version: '5.0.67'  socket: '/tmp/mysql.sock'  port: 3306  MySQL Community Server (GPL)
</pre><p>
        </p></li></ol></div><p>
      On MyISAM, or other tables, you may need to run <code class="literal">REPAIR
      TABLE</code>, and you might even have lost some information.
      You should use a recovery-capable storage engine and a regular
      synchronization schedule to reduce the risk for significant data
      loss.
    </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ha-memcached"></a>14.5. Using MySQL with <span><strong class="command">memcached</strong></span></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-memcached-install">14.5.1. Installing <span><strong class="command">memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using">14.5.2. Using <span><strong class="command">memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces">14.5.3. <span><strong class="command">memcached</strong></span> Interfaces</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats">14.5.4. Getting <span><strong class="command">memcached</strong></span> Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-faq">14.5.5. <span><strong class="command">memcached</strong></span> FAQ</a></span></dt></dl></div><p>
    The largest problem with scalability within a typical environment is
    the speed with which you can access information. For frequently
    accessed information, using MySQL can be slow because each access of
    information requires execution of the SQL query and recovery of the
    information from the database. This also means that queries on
    tables that are locked or blocking may delay your query and reduce
    the speed of recovery of information.
  </p><p>
    <span><strong class="command">memcached</strong></span> is a simple, yet highly scalable
    key-based cache that stores data and objects wherever dedicated or
    spare RAM is available for very quick access by applications. To
    use, you run <span><strong class="command">memcached</strong></span> on one or more hosts and
    then use the shared cache to store objects.Because each host's RAM
    is storing information, the access speed will be much faster than
    having to load the information from disk. This can provide a
    significant performance boost in retrieving data versus loading the
    data natively from a database. Also, because the cache is just a
    repository for information, you can use the cache to store any data,
    including complex structures that would normally require a
    significant amount of effort to create, but in a ready-to-use
    format, helping to reduce the load on your MySQL servers.
  </p><p>
    The typical usage environment is to modify your application so that
    information is read from the cache provided by
    <span><strong class="command">memcached</strong></span>. If the information isn't in
    <span><strong class="command">memcached</strong></span>, then the data is loaded from the MySQL
    database and written into the cache so that future requests for the
    same object benefit from the cached data.
  </p><p>
    For a typical deployment layout, see
    <a href="ha-overview.html#ha-memcached-fig-overview" title="Figure 14.4. memcached Architecture Overview">Figure 14.4, “<span>memcached</span> Architecture Overview”</a>.
  </p><div class="figure"><a name="ha-memcached-fig-overview"></a><p class="title"><b>Figure 14.4. <span>memcached</span> Architecture Overview</b></p><div class="mediaobject"><img src="images/memcached-overview.png" width="540" height="296" alt="memcached Architecture
        Overview"></div></div><p>
    In the example structure, any of the clients can contact one of the
    <span><strong class="command">memcached</strong></span> servers to request a given key. Each
    client is configured to talk to all of the servers shown in the
    illustration. Within the client, when the request is made to store
    the information, the key used to reference the data is hashed and
    this hash is then used to select one of the
    <span><strong class="command">memcached</strong></span> servers. The selection of the
    <span><strong class="command">memcached</strong></span> server takes place on the client before
    the server is contacted, keeping the process lightweight.
  </p><p>
    The same algorithm is used again when a client requests the same
    key. The same key will generate the same hash, and the same
    <span><strong class="command">memcached</strong></span> server will be selected as the source
    for the data. Using this method, the cached data is spread among all
    of the <span><strong class="command">memcached</strong></span> servers, and the cached
    information is accessible from any client. The result is a
    distributed, memory-based, cache that can return information,
    particularly complex data and structures, much faster than natively
    reading the information from the database.
  </p><p>
    The data held within a <span><strong class="command">memcached</strong></span> server is never
    stored on disk (only in RAM, which means there is no persistence of
    data), and the RAM cache is always populated from the backing store
    (a MySQL database). If a <span><strong class="command">memcached</strong></span> server fails,
    the data can always be recovered from the MySQL database, albeit at
    a slower speed than loading the information from the cache.
  </p><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-memcached-install"></a>14.5.1. Installing <span><strong class="command">memcached</strong></span></h3></div></div></div><p>
      You can build and install <span><strong class="command">memcached</strong></span> from the
      source code directly, or you can use an existing operating system
      package or installation.
    </p><p>
      <span class="bold"><strong>Installing <span><strong class="command">memcached</strong></span> from
      a Binary Distribution</strong></span>
    </p><p>
      To install <span><strong class="command">memcached</strong></span> on a RedHat, Fedora or
      CentOS host, use <span><strong class="command">yum</strong></span>:
    </p><pre class="programlisting">root-shell&gt; yum install memcached</pre><p>
      To install <span><strong class="command">memcached</strong></span> on a Debian or Ubuntu
      host, use <span><strong class="command">apt-get</strong></span>:
    </p><pre class="programlisting">root-shell&gt; apt-get install memcached</pre><p>
      To install <span><strong class="command">memcached</strong></span> on a Gentoo host, use
      <span><strong class="command">emerge</strong></span>:
    </p><pre class="programlisting">root-shell&gt; emerge install memcached</pre><p>
      To install on OpenSolaris, use the <span><strong class="command">pkg</strong></span> command
      to install the <code class="literal">SUNWmemcached</code> package:
    </p><pre class="programlisting">root-shell&gt; pkg install SUNWmemcached</pre><p>
      You may also find <span><strong class="command">memcached</strong></span> in the Coolstack
      project. For more details, see
      <a href="http://cooltools.sunsource.net/coolstack/" target="_top">http://cooltools.sunsource.net/coolstack/</a>.
    </p><p>
      <span class="bold"><strong>Building <span><strong class="command">memcached</strong></span> from
      Source</strong></span>
    </p><p>
      On other Unix-based platforms, including Solaris, AIX, HP-UX and
      Mac OS X, and Linux distributions not mentioned already, you will
      need to install from source. For Linux, make sure you have a
      2.6-based kernel, which includes the improved
      <code class="literal">epoll</code> interface. For all platforms, ensure that
      you have <code class="literal">libevent</code> 1.1 or higher installed. You
      can obtain <code class="literal">libevent</code> from
      <a href="http://www.monkey.org/~provos/libevent/" target="_top"><code class="literal">libevent</code>
      web page</a>.
    </p><p>
      You can obtain the source for <span><strong class="command">memcached</strong></span> from
      <a href="http://www.danga.com/memcached" target="_top"><span><strong class="command">memcached</strong></span>
      website</a>.
    </p><p>
      To build <span><strong class="command">memcached</strong></span>, follow these steps:
    </p><div class="orderedlist"><ol type="1"><li><p>
          Extract the <span><strong class="command">memcached</strong></span> source package:
        </p><pre class="programlisting">shell&gt; gunzip -c memcached-<em class="replaceable"><code>1.2.5</code></em>.tar.gz | tar xf - </pre></li><li><p>
          Change to the
          <span><strong class="command">memcached-<em class="replaceable"><code>1.2.5</code></em>
          directory:</strong></span>
        </p><pre class="programlisting">shell&gt; cd memcached-<em class="replaceable"><code>1.2.5</code></em></pre></li><li><p>
          Run <span><strong class="command">configure</strong></span>
        </p><pre class="programlisting">shell&gt; ./configure</pre><p>
          Some additional options you may want to specify to
          <span><strong class="command">configure</strong></span>:
        </p><div class="itemizedlist"><ul type="disc"><li><p>
              <code class="literal">--prefix</code>
            </p><p>
              If you want to specify a different installation directory,
              use the <a href="installing.html#option_configure_prefix"><code class="option">--prefix</code></a> option:
            </p><pre class="programlisting">shell&gt; ./configure --prefix=/opt</pre><p>
              The default is to use the <code class="filename">/usr/local</code>
              directory.
            </p></li><li><p>
              <code class="literal">--with-libevent</code>
            </p><p>
              If you have installed <code class="filename">libevent</code> and
              <span><strong class="command">configure</strong></span> cannot find the library, use
              the <a href="installing.html#option_configure_with-libevent"><code class="option">--with-libevent</code></a>
              option to specify the location of the installed library.
            </p></li><li><p>
              <code class="literal">--enable-64bit</code>
            </p><p>
              To build a 64-bit version of <span><strong class="command">memcached</strong></span>
              (which will allow you to use a single instance with a
              large RAM allocation), use
              <span><strong class="command">--enable-64bit</strong></span>.
            </p></li><li><p>
              <code class="literal">--enable-threads</code>
            </p><p>
              To enable multi-threading support in
              <span><strong class="command">memcached</strong></span>, which will improve the
              response times on servers with a heavy load, use
              <code class="literal">--enable-threads</code>. You must have support
              for the POSIX threads within your operating system to
              enable thread support. For more information on the
              threading support, see
              <a href="ha-overview.html#ha-memcached-using-threads" title="14.5.2.7. memcached thread Support">Section 14.5.2.7, “<span><strong class="command">memcached</strong></span> thread Support”</a>.
            </p></li><li><p>
              <code class="literal">--enable-dtrace</code>
            </p><p>
              <span><strong class="command">memcached</strong></span> includes a range of DTrace
              threads that can be used to monitor and benchmark a
              <span><strong class="command">memcached</strong></span> instance. For more
              information, see
              <a href="ha-overview.html#ha-memcached-using-dtrace" title="14.5.2.5. Using memcached and DTrace">Section 14.5.2.5, “Using <span><strong class="command">memcached</strong></span> and DTrace”</a>.
            </p></li></ul></div></li><li><p>
          Run <span><strong class="command">make</strong></span> to build
          <span><strong class="command">memcached</strong></span>:
        </p><pre class="programlisting">shell&gt; make</pre></li><li><p>
          Run <span><strong class="command">make install</strong></span> to install
          <span><strong class="command">memcached</strong></span>:
        </p><pre class="programlisting">shell&gt; make install</pre></li></ol></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-memcached-using"></a>14.5.2. Using <span><strong class="command">memcached</strong></span></h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-deployment">14.5.2.1. <span><strong class="command">memcached</strong></span> Deployment</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-namespaces">14.5.2.2. Using namespaces</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-expiry">14.5.2.3. Data Expiry</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-hashtypes">14.5.2.4. <span><strong class="command">memcached</strong></span> Distribution Types</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-dtrace">14.5.2.5. Using <span><strong class="command">memcached</strong></span> and DTrace</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-memory">14.5.2.6. Memory allocation within <span><strong class="command">memcached</strong></span></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-using-threads">14.5.2.7. <span><strong class="command">memcached</strong></span> thread Support</a></span></dt></dl></div><p>
      To start using <span><strong class="command">memcached</strong></span>, you must start the
      <span><strong class="command">memcached</strong></span> service on one or more servers.
      Running <span><strong class="command">memcached</strong></span> sets up the server, allocates
      the memory and starts listening for connections from clients.
    </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
        You do not need to be privileged user (<code class="literal">root</code>)
        to run <span><strong class="command">memcached</strong></span> unless you want to listen on
        one of the privileged TCP/IP ports (below 1024). You must,
        however, use a user that has not had their memory limits
        restricted using <span><strong class="command">setrlimit</strong></span> or similar.
      </p></div><p>
      To start the server, run <span><strong class="command">memcached</strong></span> as a
      nonprivileged (that is, non-<code class="literal">root</code>) user:
    </p><pre class="programlisting">shell&gt; memcached</pre><p>
      By default, <span><strong class="command">memcached</strong></span> uses the following
      settings:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          Memory allocation of 64MB
        </p></li><li><p>
          Listens for connections on all network interfaces, using port
          11211
        </p></li><li><p>
          Supports a maximum of 1024 simultaneous connections
        </p></li></ul></div><p>
      Typically, you would specify the full combination of options that
      you want when starting <span><strong class="command">memcached</strong></span>, and normally
      provide a startup script to handle the initialization of
      <span><strong class="command">memcached</strong></span>. For example, the following line
      starts <span><strong class="command">memcached</strong></span> with a maximum of 1024MB RAM
      for the cache, listening on port 11121 on the IP address
      192.168.0.110, running has a background daemon:
    </p><pre class="programlisting">shell&gt; memcached -d -m 1024 -p 11121 -l 192.168.0.110</pre><p>
      To ensure that <span><strong class="command">memcached</strong></span> is started up on boot
      you should check the init script and configuration parameters. On
      OpenSolaris, <span><strong class="command">memcached</strong></span> is controlled by SMF.
      You can enable it by using:
    </p><pre class="programlisting">root-shell&gt; svcadm enable memcached</pre><p>
      <span><strong class="command">memcached</strong></span> supports the following options:
    </p><div class="itemizedlist"><a name="ha-memcached-cmdline-options"></a><ul type="disc"><li><p>
          <code class="option">-u user</code>
        </p><p>
          If you start <span><strong class="command">memcached</strong></span> as
          <code class="literal">root</code>, use the <code class="option">-u</code> option to
          specify the user for executing <span><strong class="command">memcached</strong></span>:
        </p><pre class="programlisting">shell&gt; memcached -u memcache</pre></li><li><p>
          <code class="option">-m memory</code>
        </p><p>
          Set the amount of memory allocated to
          <span><strong class="command">memcached</strong></span> for object storage. Default is
          64MB.
        </p><p>
          To increase the amount of memory allocated for the cache, use
          the <code class="option">-m</code> option to specify the amount of RAM to
          be allocated (in megabytes). The more RAM you allocate, the
          more data you can store and therefore the more effective your
          cache will be.
        </p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>
            Do not specify a memory allocation larger than your
            available RAM. If you specify too large a value, then some
            RAM allocated for <span><strong class="command">memcached</strong></span> will be using
            swap space, and not physical RAM. This may lead to delays
            when storing and retrieving values, because data will be
            swapped to disk, instead of storing the data directly in
            RAM.
          </p><p>
            You can use the output of the <span><strong class="command">vmstat</strong></span>
            command to get the free memory, as shown in
            <code class="literal">free</code> column:
          </p><pre class="programlisting">shell&gt; vmstat
kthr      memory            page            disk          faults      cpu
r b w   swap  free  re  mf pi po fr de sr s1 s2 -- --   in   sy   cs us sy id
0 0 0 5170504 3450392 2  7  2  0  0  0  4  0  0  0  0  296   54  199  0  0 100
</pre></div><p>
          For example, to allocate 3GB of RAM:
        </p><pre class="programlisting">shell&gt; memcached -m 3072</pre><p>
          On 32-bit x86 systems where you are using PAE to access memory
          above the 4GB limit, you will be unable to allocate RAM beyond
          the maximum process size. You can get around this by running
          multiple instances of <span><strong class="command">memcached</strong></span>, each
          listening on a different port:
        </p><pre class="programlisting">shell&gt; memcached -m 1024 -p11211
shell&gt; memcached -m 1024 -p11212
shell&gt; memcached -m 1024 -p11213</pre></li><li><p>
          <code class="option">-l interface</code>
        </p><p>
          Specify a network interface/address to listen for connections.
          The default is to listen on all available address
          (<code class="literal">INADDR_ANY</code>).
        </p><pre class="programlisting">shell&gt; memcached -l 192.168.0.110</pre><p>
          Support for IPv6 address support was added in
          <span><strong class="command">memcached</strong></span> 1.2.5.
        </p></li><li><p>
          <code class="option">-p port</code>
        </p><p>
          Specify the TCP port to use for connections. Default is 18080.
        </p><pre class="programlisting">shell&gt; memcached -p 18080</pre></li><li><p>
          <code class="option">-U port</code>
        </p><p>
          Specify the UDP port to use for connections. Default is 11211,
          0 switches UDP off.
        </p><pre class="programlisting">shell&gt; memcached -U 18080</pre></li><li><p>
          <code class="option">-s socket</code>
        </p><p>
          Specify a Unix socket to listen on.
        </p><p>
          If you are running <span><strong class="command">memcached</strong></span> on the same
          server as the clients, you can disable the network interface
          and use a local UNIX socket using the <code class="option">-s</code>
          option:
        </p><pre class="programlisting">shell&gt; memcached -s /tmp/memcached</pre><p>
          Using a UNIX socket automatically disables network support,
          and saves network ports (allowing more ports to be used by
          your web server or other process).
        </p></li><li><p>
          <code class="option">-a mask</code>
        </p><p>
          Specify the access mask to be used for the Unix socket, in
          octal. Default is 0700.
        </p></li><li><p>
          <code class="option">-c connections</code>
        </p><p>
          Specify the maximum number of simultaneous connections to the
          <span><strong class="command">memcached</strong></span> service. The default is 1024.
        </p><pre class="programlisting">shell&gt; memcached -c 2048</pre><p>
          You should use this option, either to reduce the number of
          connections (to prevent overloading
          <span><strong class="command">memcached</strong></span> service) or to increase the
          number to make more effective use of the server running
          <span><strong class="command">memcached</strong></span> server.
        </p></li><li><p>
          <code class="option">-t threads</code>
        </p><p>
          Specify the numnber of threads to use when processing incoming
          requests.
        </p><p>
          By default, <span><strong class="command">memcached</strong></span> is configured to use
          4 concurrent threads. The threading improves the performance
          of storing and retrieving data in the cache, using a locking
          system to prevent different threads overwriting or updating
          the same values. You may want to increase or decrease the
          number of threads, use the <code class="literal">-t</code> option:
        </p><pre class="programlisting">shell&gt; memcached -t 8</pre></li><li><p>
          <code class="option">-d</code>
        </p><p>
          Run <span><strong class="command">memcached</strong></span> as a daemon (background)
          process:
        </p><pre class="programlisting">shell&gt; memcached -d</pre></li><li><p>
          <code class="option">-r</code>
        </p><p>
          Maximize the size of the core file limit. In the event of a
          failure, this will attempt to dump the entire memory space to
          disk as a core file, up to any limits imposed by
          <span><strong class="command">setrlimit</strong></span>.
        </p></li><li><p>
          <code class="option">-M</code>
        </p><p>
          Return an error to the client when the memory has been
          exhausted. This replaces the normal behavior of removing older
          items from the cache to make way for new items.
        </p></li><li><p>
          <code class="option">-k</code>
        </p><p>
          Lock down all paged memory. This reserves the memory before
          use, instead of allocating new slabs of memory as new items
          are stored in the cache.
        </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
            There is a user-level limit on how much memory you may lock.
            Trying to allocate more than the available memory will fail.
            You can set the limit for the user you started the daemon
            with (not for the <code class="option">-u user</code> user) within the
            shell by using <span><strong class="command">ulimit -S -l NUM_KB</strong></span>
          </p></div></li><li><p>
          <code class="option">-v</code>
        </p><p>
          Verbose mode. Prints errors and warnings while executing the
          main event loop.
        </p></li><li><p>
          <code class="option">-vv</code>
        </p><p>
          Very verbose mode. In addition to information printed by
          <code class="option">-v</code>, also prints each client command and the
          response.
        </p></li><li><p>
          <code class="option">-vvv</code>
        </p><p>
          Extremely verbose mode. In addition to information printed by
          <code class="option">-vv</code>, also show the internal state changes.
        </p></li><li><p>
          <code class="option">-h</code>
        </p><p>
          Print the help message and exit.
        </p></li><li><p>
          <code class="option">-i</code>
        </p><p>
          Print the <span><strong class="command">memcached</strong></span> and
          <code class="literal">libevent</code> license.
        </p></li><li><p>
          <code class="option">-b</code>
        </p><p>
          Set the backlog queue limit. The default is 1024.
        </p></li><li><p>
          <code class="option">-P pidfile</code>
        </p><p>
          Save the process ID of the <span><strong class="command">memcached</strong></span>
          instance into <code class="literal">file</code>.
        </p></li><li><p>
          <code class="option">-f</code>
        </p><p>
          Set the chunk size growth factor. When allocating new memory
          chunks, the allocated size of new chunks will be determined by
          multiple the default slab size by this factor.
        </p></li><li><p>
          <code class="option">-n bytes</code>
        </p><p>
          The minimum space allocated for the key+value+flags
          information. The default is 48 bytes.
        </p></li><li><p>
          <code class="option">-L</code>
        </p><p>
          On systems that support large memory pages, enables large
          memory page use. Using large memory pages enables
          <span><strong class="command">memcached</strong></span> to allocate the item cache in one
          large chunk, which can improve the performance by reducing the
          number misses when accessing memory.
        </p></li><li><p>
          <code class="option">-C</code>
        </p><p>
          Disable the use of compare and swap (CAS) operations.
        </p><p>
          This option was added in <span><strong class="command">memcached</strong></span> 1.3.x.
        </p></li><li><p>
          <code class="option">-D char</code>
        </p><p>
          Set the default character to be used as a delimiter between
          the key prefixes and IDs. This is used for the per-prefix
          statistics reporting (see
          <a href="ha-overview.html#ha-memcached-stats" title="14.5.4. Getting memcached Statistics">Section 14.5.4, “Getting <span><strong class="command">memcached</strong></span> Statistics”</a>). The default is the
          colon (<code class="literal">:</code>). If this option is used,
          statistics collection is turned on automatically. If not used,
          you can enable stats collection by sending the <code class="literal">stats
          detail on</code> command to the server.
        </p><p>
          This option was added in <span><strong class="command">memcached</strong></span> 1.3.x.
        </p></li><li><p>
          <code class="option">-R num</code>
        </p><p>
          Sets the maximum number of requests per event process. The
          default is 20.
        </p></li><li><p>
          <code class="option">-B protocol</code>
        </p><p>
          Set the binding protocol, that is, the default
          <span><strong class="command">memcached</strong></span> protocol support for client
          connections. Options are <code class="literal">ascii</code>,
          <code class="literal">binary</code> or <code class="literal">auto</code>.
          Automatic (<code class="literal">auto</code>) is the default.
        </p><p>
          This option was added in <span><strong class="command">memcached</strong></span> 1.4.0.
        </p></li></ul></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-using-deployment"></a>14.5.2.1. <span><strong class="command">memcached</strong></span> Deployment</h4></div></div></div><p>
        When using <span><strong class="command">memcached</strong></span> you can use a number of
        different potential deployment strategies and topologies. The
        exact strategy you use will depend on your application and
        environment. When developing a system for deploying
        <span><strong class="command">memcached</strong></span> within your system, you should keep
        in mind the following points:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <span><strong class="command">memcached</strong></span> is only a caching mechanism. It
            shouldn't be used to store information that you cannot
            otherwise afford to lose and then load from a different
            location.
          </p></li><li><p>
            There is no security built into the
            <span><strong class="command">memcached</strong></span> protocol. At a minimum you
            should make sure that the servers running
            <span><strong class="command">memcached</strong></span> are only accessible from inside
            your network, and that the network ports being used are
            blocked (using a firewall or similar). If the information on
            the <span><strong class="command">memcached</strong></span> servers that is being
            stored is any sensitive, then encrypt the information before
            storing it in <span><strong class="command">memcached</strong></span>.
          </p></li><li><p>
            <span><strong class="command">memcached</strong></span> does not provide any sort of
            failover. Because there is no communication between
            different <span><strong class="command">memcached</strong></span> instances. If an
            instance fails, your application must capable of removing it
            from the list, reloading the data and then writing data to
            another <span><strong class="command">memcached</strong></span> instance.
          </p></li><li><p>
            Latency between the clients and the
            <span><strong class="command">memcached</strong></span> can be a problem if you are
            using different physical machines for these tasks. If you
            find that the latency is a problem, move the
            <span><strong class="command">memcached</strong></span> instances to be on the clients.
          </p></li><li><p>
            Key length is determined by the <span><strong class="command">memcached</strong></span>
            server. The default maximum key size is 250 bytes.
          </p></li><li><p>
            Using a single <span><strong class="command">memcached</strong></span> instance,
            especially for multiple clients, is generally a bad idea as
            it introduces a single point of failure. Instead provide at
            least two <span><strong class="command">memcached</strong></span> instances so that a
            failure can be handled appropriately. If possible, you
            should create as many <span><strong class="command">memcached</strong></span> nodes as
            possible. When adding and removing
            <span><strong class="command">memcached</strong></span> instances from a pool, the
            hashing and distribution of key/value pairs may be affected.
            For information on how to avoid problems, see
            <a href="ha-overview.html#ha-memcached-using-hashtypes" title="14.5.2.4. memcached Distribution Types">Section 14.5.2.4, “<span><strong class="command">memcached</strong></span> Distribution Types”</a>.
          </p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-using-namespaces"></a>14.5.2.2. Using namespaces</h4></div></div></div><p>
        The <span><strong class="command">memcached</strong></span> cache is a very simple massive
        key/value storage system, and as such there is no way of
        compartmentalizing data automatically into different sections.
        For example, if you are storing information by the unique ID
        returned from a MySQL database, then storing the data from two
        different tables will run into issues because the same ID will
        probably be valid in both tables.
      </p><p>
        Some interfaces provide an automated mechanism for creating
        <span class="emphasis"><em>namespaces</em></span> when storing information into
        the cache. In practice, these namespaces are merely a prefix
        before a given ID that is applied every time a value is stored
        or retrieve from the cache.
      </p><p>
        You can implement the same basic principle by using keys that
        describe the object and the unique identifier within the key
        that you supply when the object is stored. For example, when
        storing user data, prefix the ID of the user with
        <code class="literal">user:</code> or <code class="literal">user-</code>.
      </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          Using namespaces or prefixes only controls the keys
          stored/retrieved. There is no security within
          <span><strong class="command">memcached</strong></span>, and therefore no way to enforce
          that a particular client only accesses keys with a particular
          namespace. Namespaces are only useful as a method of
          identifying data and preventing corruption of key/value pairs.
        </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-using-expiry"></a>14.5.2.3. Data Expiry</h4></div></div></div><p>
        There are two types of data expiry within a
        <span><strong class="command">memcached</strong></span> instance. The first type is applied
        at the point when you store a new key/value pair into the
        <span><strong class="command">memcached</strong></span> instance. If there is not enough
        space within a suitable slab to store the value, then an
        existing least recently used (LRU) object is removed (evicted)
        from the cache to make room for the new item.
      </p><p>
        The LRU algorithm ensures that the object that is removed is one
        that is either no longer in active use or that was used so long
        ago that its data is potentially out of date or of little value.
        However, in a system where the memory allocated to
        <span><strong class="command">memcached</strong></span> is smaller than the number of
        regularly used objects required in the cache you will see a lot
        of expired items being removed from the cache even though they
        are in active use. You use the statistics mechanism to get a
        better idea of the level of evictions (expired objects). For
        more information, see <a href="ha-overview.html#ha-memcached-stats" title="14.5.4. Getting memcached Statistics">Section 14.5.4, “Getting <span><strong class="command">memcached</strong></span> Statistics”</a>.
      </p><p>
        You can change this eviction behavior by setting the
        <code class="literal">-M</code> command-line option when starting
        <span><strong class="command">memcached</strong></span>. This option forces an error to be
        returned when the memory has been exhausted, instead of
        automatically evicting older data.
      </p><p>
        The second type of expiry system is an explicit mechanism that
        you can set when a key/value pair is inserted into the cache, or
        when deleting an item from the cache. Using an expiration time
        can be a useful way of ensuring that the data in the cache is up
        to date and in line with your application needs and
        requirements.
      </p><p>
        A typical scenario for explicitly setting the expiry time might
        include caching session data for a user when accessing a
        website. <span><strong class="command">memcached</strong></span> uses a lazy expiry
        mechanism where the explicit expiry time that has been set is
        compared with the current time when the object is requested.
        Only objects that have not expired are returned.
      </p><p>
        You can also set the expiry time when explicitly deleting an
        object from the cache. In this case, the expiry time is really a
        timeout and indicates the period when any attempts to set the
        value for a given key are rejected.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-using-hashtypes"></a>14.5.2.4. <span><strong class="command">memcached</strong></span> Distribution Types</h4></div></div></div><p>
        The <span><strong class="command">memcached</strong></span> client interface supports a
        number of different distribution algorithms that are used in
        multi-server configurations to determine which host should be
        used when setting or getting data from a given
        <span><strong class="command">memcached</strong></span> instance. When you get or set a
        value, a hash is constructed from the supplied key and then used
        to select a host from the list of configured servers. Because
        the hashing mechanism uses the supplied key as the basis for the
        hash, the selected server will be the same during both set and
        get operations.
      </p><p>
        For example, if you have three servers, A, B, and C, and you set
        the value <code class="literal">myid</code>, then the
        <span><strong class="command">memcached</strong></span> client will create a hash based on
        the ID and select server B. When the same key is requested, the
        same hash is generated, and the same server, B, will be selected
        to request the value.
      </p><p>
        Because the hashing mechanism is part of the client interface,
        not the server interface, the hashing process and selection is
        very fast. By performing the hashing on the client, it also
        means that if you want to access the same data by the same ID
        from the same list of servers but from different client
        interfaces, you must use the same or compatible hashing
        mechanisms. If you do not use the same hashing mechanism then
        the same data may be recorded on different servers by different
        interfaces, both wasting space on your
        <span><strong class="command">memcached</strong></span> and leading to potential
        differences in the information.
      </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          One way to use a multi-interface compatible hashing mechanism
          is to use the <code class="literal">libmemcached</code> library and the
          associated interfaces. Because the interfaces for the
          different languages (including C, Ruby, Perl and Python) are
          using the same client library interface, they will always
          generate the same hash code from the ID.
        </p></div><p>
        One issue with the client-side hashing mechanism is that when
        using multiple servers and extending or shrinking the list of
        servers that you have configured for use with
        <span><strong class="command">memcached</strong></span>, the resulting hash may change. For
        example, if you have servers A, B, and C; the computed hash for
        key <code class="literal">myid</code> may equate to server B. If you add
        another server, D, into this list, then computing the hash for
        the same ID again may result in the selection of server D for
        that key.
      </p><p>
        This means that servers B and D both contain the information for
        key <code class="literal">myid</code>, but there may be differences
        between the data held by the two instances. A more significant
        problem is that you will get a much higher number of
        cache-misses when retrieving data as the addition of a new
        server will change the distribution of keys, and this will in
        turn require rebuilding the cached data on the
        <span><strong class="command">memcached</strong></span> instances and require an increase
        in database reads.
      </p><p>
        For this reason, there are two common types of hashing
        algorithm, <span class="emphasis"><em>consistent</em></span> and
        <span class="emphasis"><em>modula</em></span>.
      </p><p>
        With <span class="emphasis"><em>consistent</em></span> hashing algorithms, the
        same key when applied to a list of servers will always use the
        same server to store or retrieve the keys, even if the list of
        configured servers changes. This means that you can add and
        remove servers from the configure list and always use the same
        server for a given key. There are two types of consistent
        hashing algorithms available, Ketama and Wheel. Both types are
        supported by <code class="literal">libmemcached</code>, and
        implementations are available for PHP and Java.
      </p><p>
        There are some limitations with any consistent hashing
        algorithm. When adding servers to an existing list of configured
        servers, then keys will be distributed to the new servers as
        part of the normal distribution. When removing servers from the
        list, the keys will be re-allocated to another server within the
        list, which will mean that the cache will need to be
        re-populated with the information. Also, a consistent hashing
        algorithm does not resolve the issue where you want consistent
        selection of a server across multiple clients, but where each
        client contains a different list of servers. The consistency is
        enforced only within a single client.
      </p><p>
        With a <span class="emphasis"><em>modula</em></span> hashing algorithm, the client
        will select a server by first computing the hash and then
        choosing a server from the list of configured servers. As the
        list of servers changes, so the server selected when using a
        modula hashing algorithm will also change. The result is the
        behavior described above; changes to the list of servers will
        mean different servers are selected when retrieving data leading
        to cache misses and increase in database load as the cache is
        re-seeded with information.
      </p><p>
        If you use only a single <span><strong class="command">memcached</strong></span> instance
        for each client, or your list of <span><strong class="command">memcached</strong></span>
        servers configured for a client never changes, then the
        selection of a hashing algorithm is irrelevant, as you will not
        notice the effect.
      </p><p>
        If you change your servers regularly, or you use a common set of
        servers that are shared among a large number of clients, then
        using a consistent hashing algorithm should help to ensure that
        your cache data is not duplicated and the data is evenly
        distributed.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-using-dtrace"></a>14.5.2.5. Using <span><strong class="command">memcached</strong></span> and DTrace</h4></div></div></div><p>
        <span><strong class="command">memcached</strong></span> includes a number of different
        DTrace probes that can be used to monitor the operation of the
        server. The probes included can monitor individual connections,
        slab allocations, and modifications to the hash table when a
        key/value pair is added, updated, or removed.
      </p><p>
        For more information on DTrace and writing DTrace scripts, read
        the
        <a href="http://docs.sun.com/app/docs/doc/819-5488?l=en" target="_top">DTrace
        User Guide</a>.
      </p><p>
        Support for DTrace probes was added to
        <span><strong class="command">memcached</strong></span> 1.2.6 includes a number of DTrace
        probes that can be used to help monitor your application. DTrace
        is supported on Solaris 10, OpenSolaris, Mac OS X 10.5 and
        FreeBSD. To enable the DTrace probes in
        <span><strong class="command">memcached</strong></span>, you should build from source and
        use the <code class="option">--enable-dtrace</code> option. For more
        information, see <a href="ha-overview.html#ha-memcached-install" title="14.5.1. Installing memcached">Section 14.5.1, “Installing <span><strong class="command">memcached</strong></span>”</a>.
      </p><p>
        The probes supported by <span><strong class="command">memcached</strong></span> are:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <code class="literal">conn-allocate(connid)</code>
          </p><p>
            Fired when a connection object is allocated from the
            connection pool.
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — the connection id
              </p></li></ul></div></li><li><p>
            <code class="literal">conn-release(connid)</code>
          </p><p>
            Fired when a connection object is released back to the
            connection pool.
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — the connection id
              </p></li></ul></div></li><li><p>
            <code class="literal">conn-create(ptr)</code>
          </p><p>
            Fired when a new connection object is being created (that
            is, there are no free connection objects in the connection
            pool).
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">ptr</code> — pointer to the connection
                object
              </p></li></ul></div></li><li><p>
            <code class="literal">conn-destroy(ptr)</code>
          </p><p>
            Fired when a connection object is being destroyed.
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">ptr</code> — pointer to the connection
                object
              </p></li></ul></div></li><li><p>
            <code class="literal">conn-dispatch(connid, threadid)</code>
          </p><p>
            Fired when a connection is dispatched from the main or
            connection-management thread to a worker thread.
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — the connection id
              </p></li><li><p>
                <code class="literal">threadid</code> — the thread id
              </p></li></ul></div></li><li><p>
            <code class="literal">slabs-allocate(size, slabclass, slabsize,
            ptr)</code>
          </p><p>
            Allocate memory from the slab allocator
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">size</code> — the requested size
              </p></li><li><p>
                <code class="literal">slabclass</code> — the allocation will
                be fulfilled in this class
              </p></li><li><p>
                <code class="literal">slabsize</code> — the size of each
                item in this class
              </p></li><li><p>
                <code class="literal">ptr</code> — pointer to allocated
                memory
              </p></li></ul></div></li><li><p>
            <code class="literal">slabs-allocate-failed(size, slabclass)</code>
          </p><p>
            Failed to allocate memory (out of memory)
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">size</code> — the requested size
              </p></li><li><p>
                <code class="literal">slabclass</code> — the class that
                failed to fulfill the request
              </p></li></ul></div></li><li><p>
            <code class="literal">slabs-slabclass-allocate(slabclass)</code>
          </p><p>
            Fired when a slab class needs more space
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">slabclass</code> — class that needs
                more memory
              </p></li></ul></div></li><li><p>
            <code class="literal">slabs-slabclass-allocate-failed(slabclass)</code>
          </p><p>
            Failed to allocate memory (out of memory)
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">slabclass</code> — the class that
                failed grab more memory
              </p></li></ul></div></li><li><p>
            <code class="literal">slabs-free(size, slabclass, ptr)</code>
          </p><p>
            Release memory
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">size</code> — the size of the memory
              </p></li><li><p>
                <code class="literal">slabclass</code> — the class the
                memory belongs to
              </p></li><li><p>
                <code class="literal">ptr</code> — pointer to the memory to
                release
              </p></li></ul></div></li><li><p>
            <code class="literal">assoc-find(key, depth)</code>
          </p><p>
            Fired when the when we have searched the hash table for a
            named key. These two elements provide an insight in how well
            the hash function operates. Traversals are a sign of a less
            optimal function, wasting cpu capacity.
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">key</code> — the key searched for
              </p></li><li><p>
                <code class="literal">depth</code> — the depth in the list
                of hash table
              </p></li></ul></div></li><li><p>
            <code class="literal">assoc-insert(key, nokeys)</code>
          </p><p>
            Fired when a new item has been inserted.
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">key</code> — the key just inserted
              </p></li><li><p>
                <code class="literal">nokeys</code> — the total number of
                keys currently being stored, including the key for which
                insert was called.
              </p></li></ul></div></li><li><p>
            <code class="literal">assoc-delete(key, nokeys)</code>
          </p><p>
            Fired when a new item has been removed.
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">key</code> — the key just deleted
              </p></li><li><p>
                <code class="literal">nokeys</code> — the total number of
                keys currently being stored, excluding the key for which
                delete was called.
              </p></li></ul></div></li><li><p>
            <code class="literal">item-link(key, size)</code>
          </p><p>
            Fired when an item is being linked in the cache
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">key</code> — the items key
              </p></li><li><p>
                <code class="literal">size</code> — the size of the data
              </p></li></ul></div></li><li><p>
            <code class="literal">item-unlink(key, size)</code>
          </p><p>
            Fired when an item is being deleted
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">key</code> — the items key
              </p></li><li><p>
                <code class="literal">size</code> — the size of the data
              </p></li></ul></div></li><li><p>
            <code class="literal">item-remove(key, size)</code>
          </p><p>
            Fired when the refcount for an item is reduced
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">key</code> — the items key
              </p></li><li><p>
                <code class="literal">size</code> — the size of the data
              </p></li></ul></div></li><li><p>
            <code class="literal">item-update(key, size)</code>
          </p><p>
            Fired when the "last referenced" time is updated
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">key</code> — the items key
              </p></li><li><p>
                <code class="literal">size</code> — the size of the data
              </p></li></ul></div></li><li><p>
            <code class="literal">item-replace(oldkey, oldsize, newkey,
            newsize)</code>
          </p><p>
            Fired when an item is being replaced with another item
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">oldkey</code> — the key of the item to
                replace
              </p></li><li><p>
                <code class="literal">oldsize</code> — the size of the old
                item
              </p></li><li><p>
                <code class="literal">newkey</code> — the key of the new
                item
              </p></li><li><p>
                <code class="literal">newsize</code> — the size of the new
                item
              </p></li></ul></div></li><li><p>
            <code class="literal">process-command-start(connid, request,
            size)</code>
          </p><p>
            Fired when the processing of a command starts
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — the connection id
              </p></li><li><p>
                <code class="literal">request</code> — the incoming request
              </p></li><li><p>
                <code class="literal">size</code> — the size of the request
              </p></li></ul></div></li><li><p>
            <code class="literal">process-command-end(connid, response,
            size)</code>
          </p><p>
            Fired when the processing of a command is done
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — the connection id
              </p></li><li><p>
                <code class="literal">respnse</code> — the response to send
                back to the client
              </p></li><li><p>
                <code class="literal">size</code> — the size of the response
              </p></li></ul></div></li><li><p>
            <code class="literal">command-get(connid, key, size)</code>
          </p><p>
            Fired for a get-command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — requested key
              </p></li><li><p>
                <code class="literal">size</code> — size of the key's data
                (or -1 if not found)
              </p></li></ul></div></li><li><p>
            <code class="literal">command-gets(connid, key, size, casid)</code>
          </p><p>
            Fired for a gets command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — requested key
              </p></li><li><p>
                <code class="literal">size</code> — size of the key's data
                (or -1 if not found)
              </p></li><li><p>
                <code class="literal">casid</code> — the casid for the item
              </p></li></ul></div></li><li><p>
            <code class="literal">command-add(connid, key, size)</code>
          </p><p>
            Fired for a add-command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — requested key
              </p></li><li><p>
                <code class="literal">size</code> — the new size of the
                key's data (or -1 if not found)
              </p></li></ul></div></li><li><p>
            <code class="literal">command-set(connid, key, size)</code>
          </p><p>
            Fired for a set-command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — requested key
              </p></li><li><p>
                <code class="literal">size</code> — the new size of the
                key's data (or -1 if not found)
              </p></li></ul></div></li><li><p>
            <code class="literal">command-replace(connid, key, size)</code>
          </p><p>
            Fired for a replace-command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — requested key
              </p></li><li><p>
                <code class="literal">size</code> — the new size of the
                key's data (or -1 if not found)
              </p></li></ul></div></li><li><p>
            <code class="literal">command-prepend(connid, key, size)</code>
          </p><p>
            Fired for a prepend-command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — requested key
              </p></li><li><p>
                <code class="literal">size</code> — the new size of the
                key's data (or -1 if not found)
              </p></li></ul></div></li><li><p>
            <code class="literal">command-append(connid, key, size)</code>
          </p><p>
            Fired for a append-command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — requested key
              </p></li><li><p>
                <code class="literal">size</code> — the new size of the
                key's data (or -1 if not found)
              </p></li></ul></div></li><li><p>
            <code class="literal">command-cas(connid, key, size, casid)</code>
          </p><p>
            Fired for a cas-command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — requested key
              </p></li><li><p>
                <code class="literal">size</code> — size of the key's data
                (or -1 if not found)
              </p></li><li><p>
                <code class="literal">casid</code> — the cas id requested
              </p></li></ul></div></li><li><p>
            <code class="literal">command-incr(connid, key, val)</code>
          </p><p>
            Fired for incr command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — the requested key
              </p></li><li><p>
                <code class="literal">val</code> — the new value
              </p></li></ul></div></li><li><p>
            <code class="literal">command-decr(connid, key, val)</code>
          </p><p>
            Fired for decr command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — the requested key
              </p></li><li><p>
                <code class="literal">val</code> — the new value
              </p></li></ul></div></li><li><p>
            <code class="literal">command-delete(connid, key, exptime)</code>
          </p><p>
            Fired for a delete command
          </p><p>
            Arguments:
          </p><div class="itemizedlist"><ul type="circle"><li><p>
                <code class="literal">connid</code> — connection id
              </p></li><li><p>
                <code class="literal">key</code> — the requested key
              </p></li><li><p>
                <code class="literal">exptime</code> — the expiry time
              </p></li></ul></div></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-using-memory"></a>14.5.2.6. Memory allocation within <span><strong class="command">memcached</strong></span></h4></div></div></div><p>
        When you first start <span><strong class="command">memcached</strong></span>, the memory
        that you have configured is not automatically allocated.
        Instead, <span><strong class="command">memcached</strong></span> only starts allocating and
        reserving physical memory once you start saving information into
        the cache.
      </p><p>
        When you start to store data into the cache,
        <span><strong class="command">memcached</strong></span> does not allocate the memory for
        the data on an item by item basis. Instead, a slab allocation is
        used to optimize memory usage and prevent memory fragmentation
        when information expires from the cache.
      </p><p>
        With slab allocation, memory is reserved in blocks of 1MB. The
        slab is divided up into a number of blocks of equal size. When
        you try to store a value into the cache,
        <span><strong class="command">memcached</strong></span> checks the size of the value that
        you are adding to the cache and determines which slab contains
        the right size allocation for the item. If a slab with the item
        size already exists, the item is written to the block within the
        slab.
      </p><p>
        If the new item is bigger than the size of any existing blocks,
        then a new slab is created, divided up into blocks of a suitable
        size. If an existing slab with the right block size already
        exists, but there are no free blocks, a new slab is created. If
        you update an existing item with data that is larger than the
        existing block allocation for that key, then the key is
        re-allocated into a suitable slab.
      </p><p>
        For example, the default size for the smallest block is 88 bytes
        (40 bytes of value, and the default 48 bytes for the key and
        flag data). If the size of the first item you store into the
        cache is less than 40 bytes, then a slab with a block size of 88
        bytes is created and the value stored.
      </p><p>
        If the size of the data that you want to store is larger than
        this value, then the block size is increased by the chunk size
        factor until a block size large enough to hold the value is
        determined. The block size is always a function of the scale
        factor, rounded up to a block size which is exactly divisible
        into the chunk size.
      </p><p>
        For a sample of the structure, see
        <a href="ha-overview.html#ha-memcached-fig-slabs" title="Figure 14.5. Memory Allocation in memcached">Figure 14.5, “Memory Allocation in <span>memcached</span>”</a>.
      </p><div class="figure"><a name="ha-memcached-fig-slabs"></a><p class="title"><b>Figure 14.5. Memory Allocation in <span>memcached</span></b></p><div class="mediaobject"><img src="images/memcached-memalloc.png" width="406" height="232" alt="Memory Allocation in
            memcached "></div></div><p>
        The result is that you have multiple pages allocated within the
        range of memory allocated to <span><strong class="command">memcached</strong></span>. Each
        page is 1MB in size (by default), and will be split into a
        different number of chunks, according to the chunk size required
        to store the key/value pairs. Each instance will have multiple
        pages allocated, and a page will always be created when a new
        item needs to be created requiring a chunk of a particular size.
        A slab may consist of multiple pages, and each page within a
        slab will contain an equal number of chunks.
      </p><p>
        The chunk size of a new slab is determined by the base chunk
        size combined with the chunk size growth factor. For example, if
        the initial chunks are 104 bytes in size, and the default chunk
        size growth factor is used (1.25), then the next chunk size
        allocated would be the best power of 2 fit for 104*1.25, or 136
        bytes.
      </p><p>
        Allocating the pages in this way ensures that memory does not
        get fragmented. However, depending on the distribution of the
        objects that you want to store, it may lead to an inefficient
        distribution of the slabs and chunks if you have significantly
        different sized items. For example, having a relatively small
        number of items within each chunk size may waste a lot of memory
        with just few chunks in each allocated page.
      </p><p>
        You can tune the growth factor to reduce this effect by using
        the <code class="literal">-f</code> command line option. This will adapt
        the growth factor applied to make more effective use of the
        chunks and slabs allocated. For information on how to determine
        the current slab allocation statistics, see
        <a href="ha-overview.html#ha-memcached-stats-slabs" title="14.5.4.2. memcached Slabs Statistics">Section 14.5.4.2, “<span><strong class="command">memcached</strong></span> Slabs Statistics”</a>.
      </p><p>
        If your operating system supports it, you can also start
        <span><strong class="command">memcached</strong></span> with the <code class="literal">-L</code>
        command line option. With this option enabled, it will
        preallocate all the memory during startup using large memory
        pages. This can improve performance by reducing the number of
        misses in the CPU memory cache.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-using-threads"></a>14.5.2.7. <span><strong class="command">memcached</strong></span> thread Support</h4></div></div></div><p>
        If you enable the thread implementation within when building
        <span><strong class="command">memcached</strong></span> from source, then
        <span><strong class="command">memcached</strong></span> will use multiple threads in
        addition to the <code class="literal">libevent</code> system to handle
        requests.
      </p><p>
        When enabled, the threading implementation operates as follows:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            Threading is handled by wrapping functions within the code
            to provide basic protection from updating the same global
            structures at the same time.
          </p></li><li><p>
            Each thread uses its own instance of the
            <code class="literal">libevent</code> to help improve performance.
          </p></li><li><p>
            TCP/IP connections are handled with a single thread
            listening on the TCP/IP socket. Each connection is then
            distribution to one of the active threads on a simple
            round-robin basis. Each connection then operates solely
            within this thread while the connection remains open.
          </p></li><li><p>
            For UDP connections, all the threads listen to a single UDP
            socket for incoming requests. Threads that are not currently
            dealing with another request ignore the incoming packet. One
            of the remaining, nonbusy, threads will read the request and
            send the response. This implementation can lead to increased
            CPU load as threads will wake from sleep to potentially
            process the request.
          </p></li></ul></div><p>
        Using threads can increase the performance on servers that have
        multiple CPU cores available, as the requests to update the hash
        table can be spread between the individual threads. However,
        because of the locking mechanism employed you may want to
        experiment with different thread values to achieve the best
        performance based on the number and type of requests within your
        given workload.
      </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-memcached-interfaces"></a>14.5.3. <span><strong class="command">memcached</strong></span> Interfaces</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-libmemcached">14.5.3.1. Using <code class="literal">libmemcached</code></a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-perl">14.5.3.2. Using MySQL and <span><strong class="command">memcached</strong></span> with Perl</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-python">14.5.3.3. Using MySQL and <span><strong class="command">memcached</strong></span> with Python</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-php">14.5.3.4. Using MySQL and <span><strong class="command">memcached</strong></span> with PHP</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-ruby">14.5.3.5. Using MySQL and <span><strong class="command">memcached</strong></span> with Ruby</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-java">14.5.3.6. Using MySQL and <span><strong class="command">memcached</strong></span> with Java</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-mysqludf">14.5.3.7. Using the MySQL <span><strong class="command">memcached</strong></span> UDFs</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-protocol">14.5.3.8. <span><strong class="command">memcached</strong></span> Protocol</a></span></dt></dl></div><p>
      A number of interfaces from different languages exist for
      interacting with <span><strong class="command">memcached</strong></span> servers and storing
      and retrieving information. Interfaces for the most common
      language platforms including Perl, PHP, Python, Ruby, C and Java.
    </p><p>
      Data stored into a <span><strong class="command">memcached</strong></span> server is referred
      to by a single string (the key), with storage into the cache and
      retrieval from the cache using the key as the reference. The cache
      therefore operates like a large associative array or hash. It is
      not possible to structure or otherwise organize the information
      stored in the cache. If you want to store information in a
      structured way, you must use 'formatted' keys.
    </p><p>
      The following tips may be useful to you when using
      <span><strong class="command">memcached</strong></span>:
    </p><p>
      The general sequence for using <span><strong class="command">memcached</strong></span> in any
      language as a caching solution is as follows:
    </p><div class="orderedlist"><ol type="1"><li><p>
          Request the item from the cache.
        </p></li><li><p>
          If the item exists, use the item data.
        </p></li><li><p>
          If the item does not exist, load the data from MySQL, and
          store the value into the cache. This means the value will be
          available to the next client that requests it from the cache.
        </p></li></ol></div><p>
      For a flow diagram of this sequence, see
      <a href="ha-overview.html#ha-memcached-fig-basicflow" title="Figure 14.6. Typical memcached Application Flowchart">Figure 14.6, “Typical <span>memcached</span> Application Flowchart”</a>.
    </p><div class="figure"><a name="ha-memcached-fig-basicflow"></a><p class="title"><b>Figure 14.6. Typical <span>memcached</span> Application Flowchart</b></p><div class="mediaobject"><img src="images/memcached-flow.png" width="288" height="437" alt="Typical memcached
          Application Flowchart"></div></div><p>
      The interface to <span><strong class="command">memcached</strong></span> supports the
      following methods for storing and retrieving information in the
      cache, and these are consistent across all the different APIs,
      even though the language specific mechanics may be different:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          <code class="function">get(key)</code> — retrieves information
          from the cache. Returns the value if it exists, or
          <code class="literal">NULL</code>, <code class="literal">nil</code>, or
          <code class="literal">undefined</code> or the closest equivalent in the
          corresponding language, if the specified key does not exist.
        </p></li><li><p>
          <code class="function">set(key, value [, expiry])</code> — sets
          the key in the cache to the specified value. Note that this
          will either update an existing key if it already exists, or
          add a new key/value pair if the key doesn't exist. If the
          expiry time is specified, then the key will expire (be
          deleted) when the expiry time is reached. The time should be
          specified in seconds, and is taken as a relative time if the
          value is less than 30 days (30*24*60*60), or an absolute time
          (epoch) if larger than this value.
        </p></li><li><p>
          <code class="function">add(key, value [, expiry])</code> — adds
          the key to the cache, if the specified key doesn't already
          exist.
        </p></li><li><p>
          <code class="function">replace(key, value [, expiry])</code> —
          replace the <code class="literal">value</code> of the specified
          <code class="literal">key</code>, only if the key already exists.
        </p></li><li><p>
          <code class="function">delete(key [, time])</code> — Deletes the
          <code class="literal">key</code> from the cache. If you supply a
          <code class="literal">time</code>, then adding a value with the
          specified <code class="literal">key</code> is blocked for the specified
          period.
        </p></li><li><p>
          <code class="function">incr(key [, value])</code> — Increment the
          specified <code class="literal">key</code> by one or the specified
          <code class="literal">value</code>.
        </p></li><li><p>
          <code class="function">decr(key [, value])</code> — Decrement the
          specified <code class="literal">key</code> by one or the specified
          <code class="literal">value</code>.
        </p></li><li><p>
          <code class="function">flush_all</code> — invalidates (or
          expires) all the current items in the cache. Technically they
          will still exist (they are not deleted), but they will be
          silently destroyed the next time you try to access them.
        </p></li></ul></div><p>
      In all implementations, most or all of these functions are
      duplicated through the corresponding native language interface.
    </p><p>
      For all languages and interfaces, you should use
      <span><strong class="command">memcached</strong></span> to store full items, rather than
      simply caching single rows of information from the database. For
      example, when displaying a record about an object (invoice, user
      history, or blog post), all the data for the associated entry
      should be loaded from the database, and compiled into the internal
      structure that would normally be required by the application. You
      then save the complete object into the cache.
    </p><p>
      Data cannot be stored directly, it needs to be serialized, and
      most interfaces will serialize the data for you. Perl uses
      <code class="literal">Storable</code>, PHP uses
      <code class="literal">serialize</code>, Python uses
      <code class="literal">cPickle</code> (or <code class="literal">Pickle</code>) and Java
      uses the <code class="literal">Serializable</code> interface. In most cases,
      the serialization interface used is customizable. If you want to
      share data stored in <span><strong class="command">memcached</strong></span> instances
      between different language interfaces, consider using a common
      serialization solution such as JSON (Javascript Object Notation).
    </p><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-interfaces-libmemcached"></a>14.5.3.1. Using <code class="literal">libmemcached</code></h4></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-libmemcached-base">14.5.3.1.1. <code class="literal">libmemcached</code> Base Functions</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-libmemcached-servers">14.5.3.1.2. <code class="literal">libmemcached</code> Server Functions</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-libmemcached-set">14.5.3.1.3. <code class="literal">libmemcached</code> Set Functions</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-libmemcached-get">14.5.3.1.4. <code class="literal">libmemcached</code> Get Functions</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-libmemcached-behaviors">14.5.3.1.5. <code class="literal">libmemcached</code> Behaviors</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-libmemcached-utilities">14.5.3.1.6. <span><strong class="command">libmemcached</strong></span> Command-line Utilities</a></span></dt></dl></div><p>
        The <code class="literal">libmemcached</code> library provides both C and
        C++ interfaces to <span><strong class="command">memcached</strong></span> and is also the
        basis for a number of different additional API implementations,
        including Perl, Python and Ruby. Understanding the core
        <code class="literal">libmemcached</code> functions can help when using
        these other interfaces.
      </p><p>
        The C library is the most comprehensive interface library for
        <span><strong class="command">memcached</strong></span> and provides a wealth of functions
        and operational systems not always exposed in the other
        interfaces not based on the <code class="literal">libmemcached</code>
        library.
      </p><p>
        The different functions can be divided up according to their
        basic operation. In addition to functions that interface to the
        core API, there are a number of utility functions that provide
        extended functionality, such as appending and prepending data.
      </p><p>
        To build and install <code class="literal">libmemcached</code>, download
        the <code class="literal">libmemcached</code> package, run configure, and
        then build and install:
      </p><pre class="programlisting">shell&gt; tar xjf libmemcached-0.21.tar.gz
shell&gt; cd libmemcached-0.21
shell&gt; ./configure
shell&gt; make
shell&gt; make install</pre><p>
        On many Linux operating systems, you can install the
        corresponding <code class="literal">libmemcached</code> package through
        the usual <span><strong class="command">yum</strong></span>, <span><strong class="command">apt-get</strong></span> or
        similar commands. On OpenSolaris, use <span><strong class="command">pkg</strong></span> to
        install the <code class="literal">SUNWlibmemcached</code> package.
      </p><p>
        To build an application that uses the library, you need to first
        set the list of servers. You can do this either by directly
        manipulating the servers configured within the main
        <code class="literal">memcached_st</code> structure, or by separately
        populating a list of servers, and then adding this list to the
        <code class="literal">memcached_st</code> structure. The latter method is
        used in the following example. Once the server list has been
        set, you can call the functions to store or retrieve data. A
        simple application for setting a preset value to localhost is
        provided here:
      </p><pre class="programlisting">#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;
#include &lt;libmemcached/memcached.h&gt;

int main(int argc, char *argv[])
{
  memcached_server_st *servers = NULL;
  memcached_st *memc;
  memcached_return rc;
  char *key= "keystring";
  char *value= "keyvalue";

  memcached_server_st *memcached_servers_parse (char *server_strings);
  memc= memcached_create(NULL);

  servers= memcached_server_list_append(servers, "localhost", 11211, &amp;rc);
  rc= memcached_server_push(memc, servers);

  if (rc == MEMCACHED_SUCCESS)
    fprintf(stderr,"Added server successfully\n");
  else
    fprintf(stderr,"Couldn't add server: %s\n",memcached_strerror(memc, rc));

  rc= memcached_set(memc, key, strlen(key), value, strlen(value), (time_t)0, (uint32_t)0);

  if (rc == MEMCACHED_SUCCESS)
    fprintf(stderr,"Key stored successfully\n");
  else
    fprintf(stderr,"Couldn't store key: %s\n",memcached_strerror(memc, rc));

  return 0;
}</pre><p>
        You can test the success of an operation by using the return
        value, or populated result code, for a given function. The value
        will always be set to <code class="literal">MEMCACHED_SUCCESS</code> if
        the operation succeeded. In the event of a failure, use the
        <code class="literal">memcached_strerror()</code> function to translate
        the result code into a printable string.
      </p><p>
        To build the application, you must specify the
        <code class="literal">memcached</code> library:
      </p><pre class="programlisting">shell&gt; gcc -o memc_basic memc_basic.c -lmemcached</pre><p>
        Running the above sample application, after starting a
        <span><strong class="command">memcached</strong></span> server, should return a success
        message:
      </p><pre class="programlisting">shell&gt; memc_basic
Added server successfully
Key stored successfully
</pre><div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="ha-memcached-interfaces-libmemcached-base"></a>14.5.3.1.1. <code class="literal">libmemcached</code> Base Functions</h5></div></div></div><p>
          The base <code class="literal">libmemcached</code> functions allow you
          to create, destroy and clone the main
          <code class="literal">memcached_st</code> structure that is used to
          interface to the <code class="literal">memcached</code> servers. The
          main functions are defined below:
        </p><pre class="programlisting">memcached_st *memcached_create (memcached_st *ptr);</pre><p>
          Creates a new <code class="literal">memcached_st</code> structure for
          use with the other <code class="literal">libmemcached</code> API
          functions. You can supply an existing, static,
          <code class="literal">memcached_st</code> structure, or
          <code class="literal">NULL</code> to have a new structured allocated.
          Returns a pointer to the created structure, or
          <code class="literal">NULL</code> on failure.
        </p><pre class="programlisting">void memcached_free (memcached_st *ptr);
</pre><p>
          Free the structure and memory allocated to a previously
          created <code class="literal">memcached_st</code> structure.
        </p><pre class="programlisting">memcached_st *memcached_clone(memcached_st *clone, memcached_st *source);
</pre><p>
          Clone an existing <code class="literal">memcached</code> structure from
          the specified <code class="literal">source</code>, copying the defaults
          and list of servers defined in the structure.
        </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="ha-memcached-interfaces-libmemcached-servers"></a>14.5.3.1.2. <code class="literal">libmemcached</code> Server Functions</h5></div></div></div><p>
          The <code class="literal">libmemcached</code> API uses a list of
          servers, stored within the
          <code class="literal">memcached_server_st</code> structure, to act as
          the list of servers used by the rest of the functions. To use
          <code class="literal">memcached</code>, you first create the server
          list, and then apply the list of servers to a valid
          <code class="literal">libmemcached</code> object.
        </p><p>
          Because the list of servers, and the list of servers within an
          active <code class="literal">libmemcached</code> object can be
          manipulated separately, you can update and manage server lists
          while an active <code class="literal">libmemcached</code> interface is
          running.
        </p><p>
          The functions for manipulating the list of servers within a
          <code class="literal">memcached_st</code> structure are given below:
        </p><pre class="programlisting">memcached_return
           memcached_server_add (memcached_st *ptr,
                                 char *hostname,
                                 unsigned int port);
</pre><p>
          Add a server, using the given <code class="literal">hostname</code> and
          <code class="literal">port</code> into the
          <code class="literal">memcached_st</code> structure given in
          <code class="literal">ptr</code>.
        </p><pre class="programlisting">memcached_return
           memcached_server_add_unix_socket (memcached_st *ptr,
                                             char *socket);
</pre><p>
          Add a Unix socket to the list of servers configured in the
          <code class="literal">memcached_st</code> structure.
        </p><pre class="programlisting">unsigned int memcached_server_count (memcached_st *ptr);
</pre><p>
          Return a count of the number of configured servers within the
          <code class="literal">memcached_st</code> structure.
        </p><pre class="programlisting">memcached_server_st *
           memcached_server_list (memcached_st *ptr);</pre><p>
          Returns an array of all the defined hosts within a
          <code class="literal">memcached_st</code> structure.
        </p><pre class="programlisting">memcached_return
           memcached_server_push (memcached_st *ptr,
                                  memcached_server_st *list);
</pre><p>
          Pushes an existing list of servers onto list of servers
          configured for a current <code class="literal">memcached_st</code>
          structure. This adds servers to the end of the existing list,
          and duplicates are not checked.
        </p><p>
          The <code class="literal">memcached_server_st</code> structure can be
          used to create a list of <code class="literal">memcached</code> servers
          which can then be applied individually to
          <code class="literal">memcached_st</code> structures.
        </p><pre class="programlisting">memcached_server_st *
           memcached_server_list_append (memcached_server_st *ptr,
                                         char *hostname,
                                         unsigned int port,
                                         memcached_return *error);
</pre><p>
          Add a server, with <code class="literal">hostname</code> and
          <code class="literal">port</code>, to the server list in
          <code class="literal">ptr</code>. The result code is handled by the
          <code class="literal">error</code> argument, which should point to an
          existing <code class="literal">memcached_return</code> variable. The
          function returns a pointer to the returned list.
        </p><pre class="programlisting"> unsigned int memcached_server_list_count (memcached_server_st *ptr);
</pre><p>
          Return the number of the servers in the server list.
        </p><pre class="programlisting">void memcached_server_list_free (memcached_server_st *ptr);
</pre><p>
          Free up the memory associated with a server list.
        </p><pre class="programlisting">memcached_server_st *memcached_servers_parse (char *server_strings);
</pre><p>
          Parses a string containing a list of servers, where individual
          servers are separated by a comma and/or space, and where
          individual servers are of the form
          <code class="literal">server[:port]</code>. The return value is a server
          list structure.
        </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="ha-memcached-interfaces-libmemcached-set"></a>14.5.3.1.3. <code class="literal">libmemcached</code> Set Functions</h5></div></div></div><p>
          The set related functions within
          <code class="literal">libmemcached</code> provide the same functionality
          as the core functions supported by the
          <code class="literal">memcached</code> protocol. The full definition for
          the different functions is the same for all the base functions
          (add, replace, prepend, append). For example, the function
          definition for <code class="literal">memcached_set()</code> is:
        </p><pre class="programlisting">memcached_return
           memcached_set (memcached_st *ptr,
                          const char *key,
                          size_t key_length,
                          const char *value,
                          size_t value_length,
                          time_t expiration,
                          uint32_t flags);
</pre><p>
          The <code class="literal">ptr</code> is the
          <code class="literal">memcached_st</code> structure. The
          <code class="literal">key</code> and <code class="literal">key_length</code>
          define the key name and length, and <code class="literal">value</code>
          and <code class="literal">value_length</code> the corresponding value
          and length. You can also set the expiration and optional
          flags. For more information, see
          <a href="ha-overview.html#ha-memcached-interfaces-libmemcached-behaviors" title="14.5.3.1.5. libmemcached Behaviors">Section 14.5.3.1.5, “<code class="literal">libmemcached</code> Behaviors”</a>.
        </p><p>
          The following table outlines the remainder of the set-related
          functions.
        </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th><code class="literal">libmemcached</code> Function</th><th>Equivalent to</th></tr></thead><tbody><tr><td><code class="literal">memcached_set(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Generic <code class="literal">set()</code> operation.</td></tr><tr><td><code class="literal">memcached_add(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Generic <code class="literal">add()</code> function.</td></tr><tr><td><code class="literal">memcached_replace(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Generic <code class="literal">replace()</code>.</td></tr><tr><td><code class="literal">memcached_prepend(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Prepends the specified <code class="literal">value</code> before the current value
                  of the specified <code class="literal">key</code>.</td></tr><tr><td><code class="literal">memcached_append(memc, key, key_length, value, value_length,
                  expiration, flags)</code></td><td>Appends the specified <code class="literal">value</code> after the current value
                  of the specified <code class="literal">key</code>.</td></tr><tr><td><code class="literal">memcached_cas(memc, key, key_length, value, value_length,
                  expiration, flags, cas)</code></td><td>Overwrites the data for a given key as long as the corresponding
                  <code class="literal">cas</code> value is still the same within
                  the server.</td></tr><tr><td><code class="literal">memcached_set_by_key(memc, master_key, master_key_length, key,
                  key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the generic <code class="literal">set()</code>, but has the option of
                  an additional master key that can be used to identify
                  an individual server.</td></tr><tr><td><code class="literal">memcached_add_by_key(memc, master_key, master_key_length, key,
                  key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the generic <code class="literal">add()</code>, but has the option of
                  an additional master key that can be used to identify
                  an individual server.</td></tr><tr><td><code class="literal">memcached_replace_by_key(memc, master_key, master_key_length,
                  key, key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the generic <code class="literal">replace()</code>, but has the option
                  of an additional master key that can be used to
                  identify an individual server.</td></tr><tr><td><code class="literal">memcached_prepend_by_key(memc, master_key, master_key_length,
                  key, key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the <code class="literal">memcached_prepend()</code>, but has the
                  option of an additional master key that can be used to
                  identify an individual server.</td></tr><tr><td><code class="literal">memcached_append_by_key(memc, master_key, master_key_length,
                  key, key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the <code class="literal">memcached_append()</code>, but has the option
                  of an additional master key that can be used to
                  identify an individual server.</td></tr><tr><td><code class="literal">memcached_cas_by_key(memc, master_key, master_key_length, key,
                  key_length, value, value_length, expiration,
                  flags)</code></td><td>Similar to the <code class="literal">memcached_cas()</code>, but has the option of
                  an additional master key that can be used to identify
                  an individual server.</td></tr></tbody></table></div><p>
          The <code class="literal">by_key</code> methods add two further
          arguments, the master key, to be used and applied during the
          hashing stage for selecting the servers. You can see this in
          the following definition:
        </p><pre class="programlisting">memcached_return
           memcached_set_by_key(memcached_st *ptr,
                                const char *master_key,
                                size_t master_key_length,
                                const char *key,
                                size_t key_length,
                                const char *value,
                                size_t value_length,
                                time_t expiration,
                                uint32_t flags);
</pre><p>
          All the functions return a value of type
          <code class="literal">memcached_return</code>, which you can compare
          against the <code class="literal">MEMCACHED_SUCCESS</code> constant.
        </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="ha-memcached-interfaces-libmemcached-get"></a>14.5.3.1.4. <code class="literal">libmemcached</code> Get Functions</h5></div></div></div><p>
          The <code class="literal">libmemcached</code> functions provide both
          direct access to a single item, and a multiple-key request
          mechanism that provides much faster responses when fetching a
          large number of keys simultaneously.
        </p><p>
          The main get-style function, which is equivalent to the
          generic <code class="literal">get()</code> is
          <code class="literal">memcached_get()</code>. The functions a string
          pointer to the returned value for a corresponding key.
        </p><pre class="programlisting">char *memcached_get (memcached_st *ptr,
                     const char *key, size_t key_length,
                     size_t *value_length,
                     uint32_t *flags,
                     memcached_return *error);
</pre><p>
          A multi-key get, <code class="literal">memcached_mget()</code>, is also
          available. Using a multiple key get operation is much quicker
          to do in one block than retrieving the key values with
          individual calls to <code class="literal">memcached_get()</code>. To
          start the multi-key get, you need to call
          <code class="literal">memcached_mget()</code>:
        </p><pre class="programlisting">memcached_return
         memcached_mget (memcached_st *ptr,
                         char **keys, size_t *key_length,
                         unsigned int number_of_keys);
</pre><p>
          The return value is the success of the operation. The
          <code class="literal">keys</code> parameter should be an array of
          strings containing the keys, and <code class="literal">key_length</code>
          an array containing the length of each corresponding key.
          <code class="literal">number_of_keys</code> is the number of keys
          supplied in the array.
        </p><p>
          To fetch the individual values, you need to use
          <code class="literal">memcached_fetch()</code> to get each corresponding
          value.
        </p><pre class="programlisting">char *memcached_fetch (memcached_st *ptr,
                         const char *key, size_t *key_length,
                         size_t *value_length,
                         uint32_t *flags,
                         memcached_return *error);
</pre><p>
          The function returns the key value, with the
          <code class="literal">key</code>, <code class="literal">key_length</code> and
          <code class="literal">value_length</code> parameters being populated
          with the corresponding key and length information. The
          function returns <code class="literal">NULL</code> when there are no
          more values to be returned. A full example, including the
          populating of the key data and the return of the information
          is provided here.
        </p><pre class="programlisting">#include &lt;stdio.h&gt;
#include &lt;sstring.h&gt;
#include &lt;unistd.h&gt;
#include &lt;libmemcached/memcached.h&gt;

int main(int argc, char *argv[])
{
  memcached_server_st *servers = NULL;
  memcached_st *memc;
  memcached_return rc;
  char *keys[]= {"huey", "dewey", "louie"};
  size_t key_length[3];
  char *values[]= {"red", "blue", "green"};
  size_t value_length[3];
  unsigned int x;
  uint32_t flags;

  char return_key[MEMCACHED_MAX_KEY];
  size_t return_key_length;
  char *return_value;
  size_t return_value_length;

  memc= memcached_create(NULL);

  servers= memcached_server_list_append(servers, "localhost", 11211, &amp;rc);
  rc= memcached_server_push(memc, servers);

  if (rc == MEMCACHED_SUCCESS)
    fprintf(stderr,"Added server successfully\n");
  else
    fprintf(stderr,"Couldn't add server: %s\n",memcached_strerror(memc, rc));

  for(x= 0; x &lt; 3; x++)
    {
      key_length[x] = strlen(keys[x]);
      value_length[x] = strlen(values[x]);

      rc= memcached_set(memc, keys[x], key_length[x], values[x],
                        value_length[x], (time_t)0, (uint32_t)0);
      if (rc == MEMCACHED_SUCCESS)
        fprintf(stderr,"Key %s stored successfully\n",keys[x]);
      else
        fprintf(stderr,"Couldn't store key: %s\n",memcached_strerror(memc, rc));
    }

  rc= memcached_mget(memc, keys, key_length, 3);

  if (rc == MEMCACHED_SUCCESS)
    {
      while ((return_value= memcached_fetch(memc, return_key, &amp;return_key_length,
                                            &amp;return_value_length, &amp;flags, &amp;rc)) != NULL)
        {
          if (rc == MEMCACHED_SUCCESS)
            {
              fprintf(stderr,"Key %s returned %s\n",return_key, return_value);
            }
        }
    }

  return 0;
}</pre><p>
          Running the above application:
        </p><pre class="programlisting">shell&gt; memc_multi_fetch
Added server successfully
Key huey stored successfully
Key dewey stored successfully
Key louie stored successfully
Key huey returned red
Key dewey returned blue
Key louie returned green
</pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="ha-memcached-interfaces-libmemcached-behaviors"></a>14.5.3.1.5. <code class="literal">libmemcached</code> Behaviors</h5></div></div></div><p>
          The behavior of <code class="literal">libmemcached</code> can be
          modified by setting one or more behavior flags. These can
          either be set globally, or they can be applied during the call
          to individual functions. Some behaviors also accept an
          additional setting, such as the hashing mechanism used when
          selecting servers.
        </p><p>
          To set global behaviors:
        </p><pre class="programlisting">memcached_return
           memcached_behavior_set (memcached_st *ptr,
                                   memcached_behavior flag,
                                   uint64_t data);
</pre><p>
          To get the current behavior setting:
        </p><pre class="programlisting">uint64_t
           memcached_behavior_get (memcached_st *ptr,
                                   memcached_behavior flag);
</pre><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Behavior</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">MEMCACHED_BEHAVIOR_NO_BLOCK</code></td><td>Caused <code class="literal">libmemcached</code> to use asynchronous I/O.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_TCP_NODELAY</code></td><td>Turns on no-delay for network sockets.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_HASH</code></td><td>Without a value, sets the default hashing algorithm for keys to use MD5.
                  Other valid values include
                  <code class="literal">MEMCACHED_HASH_DEFAULT</code>,
                  <code class="literal">MEMCACHED_HASH_MD5</code>,
                  <code class="literal">MEMCACHED_HASH_CRC</code>,
                  <code class="literal">MEMCACHED_HASH_FNV1_64</code>,
                  <code class="literal">MEMCACHED_HASH_FNV1A_64</code>,
                  <code class="literal">MEMCACHED_HASH_FNV1_32</code>, and
                  <code class="literal">MEMCACHED_HASH_FNV1A_32</code>.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_DISTRIBUTION</code></td><td>Changes the method of selecting the server used to store a given value.
                  The default method is
                  <code class="literal">MEMCACHED_DISTRIBUTION_MODULA</code>. You
                  can enable consistent hashing by setting
                  <code class="literal">MEMCACHED_DISTRIBUTION_CONSISTENT</code>.
                  <code class="literal">MEMCACHED_DISTRIBUTION_CONSISTENT</code>
                  is an alias for the value
                  <code class="literal">MEMCACHED_DISTRIBUTION_CONSISTENT_KETAMA</code>.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_CACHE_LOOKUPS</code></td><td>Cache the lookups made to the DNS service. This can improve the
                  performance if you are using names instead of IP
                  addresses for individual hosts.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_SUPPORT_CAS</code></td><td>Support CAS operations. By default, this is disabled because it imposes
                  a performance penalty.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_KETAMA</code></td><td>Sets the default distribution to
                  <code class="literal">MEMCACHED_DISTRIBUTION_CONSISTENT_KETAMA</code>
                  and the hash to <code class="literal">MEMCACHED_HASH_MD5</code>.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_POLL_TIMEOUT</code></td><td>Modify the timeout value used by <code class="literal">poll()</code>. You should
                  supply a <code class="literal">signed int</code> pointer for the
                  timeout value.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_BUFFER_REQUESTS</code></td><td>Buffers IO requests instead of them being sent. A get operation, or
                  closing the connection will cause the data to be
                  flushed.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_VERIFY_KEY</code></td><td>Forces <code class="literal">libmemcached</code> to verify that a specified key is
                  valid.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_SORT_HOSTS</code></td><td>If set, hosts added to the list of configured hosts for a
                  <code class="literal">memcached_st</code> structure will placed
                  into the host list in sorted order. This will break
                  consistent hashing if that behavior has been enabled.</td></tr><tr><td><code class="literal">MEMCACHED_BEHAVIOR_CONNECT_TIMEOUT</code></td><td>In nonblocking mode this changes the value of the timeout during socket
                  connection.</td></tr></tbody></table></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="ha-memcached-interfaces-libmemcached-utilities"></a>14.5.3.1.6. <span><strong class="command">libmemcached</strong></span> Command-line Utilities</h5></div></div></div><p>
          In addition to the main C library interface,
          <code class="literal">libmemcached</code> also includes a number of
          command line utilities that can be useful when working with
          and debugging <span><strong class="command">memcached</strong></span> applications.
        </p><p>
          All of the command line tools accept a number of arguments,
          the most critical of which is <code class="literal">servers</code>,
          which specifies the list of servers to connect to when
          returning information.
        </p><p>
          The main tools are:
        </p><div class="itemizedlist"><ul type="disc"><li><p>
              <span><strong class="command">memcat</strong></span> — display the value for
              each ID given on the command line:
            </p><pre class="programlisting">shell&gt; memcat --servers=localhost hwkey
Hello world</pre></li><li><p>
              <span><strong class="command">memcp</strong></span> — copy the contents of a
              file into the cache, using the file names as the key:
            </p><pre class="programlisting">shell&gt; echo "Hello World" &gt; hwkey
shell&gt; memcp --servers=localhost hwkey
shell&gt; memcat --servers=localhost hwkey
Hello world
</pre></li><li><p>
              <span><strong class="command">memrm</strong></span> — remove an item from the
              cache:
            </p><pre class="programlisting">shell&gt; memcat --servers=localhost hwkey
Hello world
shell&gt; memrm --servers=localhost hwkey
shell&gt; memcat --servers=localhost hwkey</pre></li><li><p>
              <span><strong class="command">memslap</strong></span> — test the load on one or
              more <span><strong class="command">memcached</strong></span> servers, simulating
              get/set and multiple client operations. For example, you
              can simulate the load of 100 clients performing get
              operations:
            </p><pre class="programlisting">shell&gt; memslap --servers=localhost --concurrency=100 --flush --test=get
memslap --servers=localhost --concurrency=100 --flush --test=get	Threads connecting to servers 100
	Took 13.571 seconds to read data
</pre></li><li><p>
              <span><strong class="command">memflush</strong></span> — flush (empty) the
              contents of the <span><strong class="command">memcached</strong></span> cache.
            </p><pre class="programlisting">shell&gt; memflush --servers=localhost</pre></li></ul></div></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-interfaces-perl"></a>14.5.3.2. Using MySQL and <span><strong class="command">memcached</strong></span> with Perl</h4></div></div></div><p>
        The <code class="literal">Cache::Memcached</code> module provides a native
        interface to the Memcache protocol, and provides support for the
        core functions offered by <span><strong class="command">memcached</strong></span>. You
        should install the module using your hosts native package
        management system. Alternatively, you can install the module
        using <code class="literal">CPAN</code>:
      </p><pre class="programlisting">root-shell&gt; perl -MCPAN -e 'install Cache::Memcached'</pre><p>
        To use <span><strong class="command">memcached</strong></span> from Perl through
        <code class="literal">Cache::Memcached</code> module, you first need to
        create a new <code class="literal">Cache::Memcached</code> object that
        defines the list of servers and other parameters for the
        connection. The only argument is a hash containing the options
        for the cache interface. For example, to create a new instance
        that uses three <span><strong class="command">memcached</strong></span> servers:
      </p><pre class="programlisting">use Cache::Memcached;

my $cache = new Cache::Memcached {
    'servers' =&gt; [
        '192.168.0.100:11211',
        '192.168.0.101:11211',
        '192.168.0.102:11211',
	],
};
</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          When using the <code class="literal">Cache::Memcached</code> interface
          with multiple servers, the API automatically performs certain
          operations across all the servers in the group. For example,
          getting statistical information through
          <code class="literal">Cache::Memcached</code> returns a hash that
          contains data on a host by host basis, as well as generalized
          statistics for all the servers in the group.
        </p></div><p>
        You can set additional properties on the cache object instance
        when it is created by specifying the option as part of the
        option hash. Alternatively, you can use a corresponding method
        on the instance:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <code class="literal">servers</code> or method
            <code class="literal">set_servers()</code> — specifies the list
            of the servers to be used. The servers list should be a
            reference to an array of servers, with each element as the
            address and port number combination (separated by a colon).
            You can also specify a local connection through a UNIX
            socket (for example
            <code class="filename">/tmp/sock/memcached</code>). You can also
            specify the server with a weight (indicating how much more
            frequently the server should be used during hashing) by
            specifying an array reference with the
            <span><strong class="command">memcached</strong></span> server instance and a weight
            number. Higher numbers give higher priority.
          </p></li><li><p>
            <code class="literal">compress_threshold</code> or method
            <code class="literal">set_compress_threshold()</code>— specifies
            the threshold when values are compressed. Values larger than
            the specified number are automatically compressed (using
            <code class="literal">zlib</code>) during storage and retrieval.
          </p></li><li><p>
            <code class="literal">no_rehash</code> or method
            <code class="literal">set_norehash()</code> — disables finding a
            new server if the original choice is unavailable.
          </p></li><li><p>
            <code class="literal">readonly</code> or method
            <code class="literal">set_readonly()</code>— disables writes to
            the <span><strong class="command">memcached</strong></span> servers.
          </p></li></ul></div><p>
        Once the <code class="literal">Cache::Memcached</code> object instance has
        been configured you can use the <code class="literal">set()</code> and
        <code class="literal">get()</code> methods to store and retrieve
        information from the <span><strong class="command">memcached</strong></span> servers.
        Objects stored in the cache are automatically serialized and
        deserialized using the <code class="literal">Storable</code> module.
      </p><p>
        The <code class="literal">Cache::Memcached</code> interface supports the
        following methods for storing/retrieving data, and relate to the
        generic methods as shown in the table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th><code class="literal">Cache::Memcached</code> Function</th><th>Equivalent to</th></tr></thead><tbody><tr><td><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code></td></tr><tr><td><code class="literal">get_multi(keys)</code></td><td>Gets multiple <code class="literal">keys</code> from memcache using just one
                query. Returns a hash reference of key/value pairs.</td></tr><tr><td><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code></td></tr><tr><td><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code></td></tr><tr><td><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code></td></tr><tr><td><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code></td></tr><tr><td><code class="literal">incr()</code></td><td>Generic <code class="literal">incr()</code></td></tr><tr><td><code class="literal">decr()</code></td><td>Generic <code class="literal">decr()</code></td></tr></tbody></table></div><p>
        Below is a complete example for using
        <span><strong class="command">memcached</strong></span> with Perl and the
        <code class="literal">Cache::Memcached</code> module:
      </p><pre class="programlisting">root-shell&gt;!/usr/bin/perl

use Cache::Memcached;
use DBI;
use Data::Dumper;

# Configure the memcached server

my $cache = new Cache::Memcached {
    'servers' =&gt; [
                   'localhost:11211',
                   ],
    };

# Get the film name from the command line
# memcached keys must not contain spaces, so create
# a key name by replacing spaces with underscores

my $filmname = shift or die "Must specify the film name\n";
my $filmkey = $filmname;
$filmkey =~ s/ /_/;

# Load the data from the cache

my $filmdata = $cache-&gt;get($filmkey);

# If the data wasn't in the cache, then we load it from the database

if (!defined($filmdata))
{
    $filmdata = load_filmdata($filmname);

    if (defined($filmdata))
    {

# Set the data into the cache, using the key

	if ($cache-&gt;set($filmkey,$filmdata))
        {
            print STDERR "Film data loaded from database and cached\n";
        }
        else
        {
            print STDERR "Couldn't store to cache\n";
	}
    }
    else
    {
     	die "Couldn't find $filmname\n";
    }
}
else
{
    print STDERR "Film data loaded from Memcached\n";
}

sub load_filmdata
{
    my ($filmname) = @_;

    my $dsn = "DBI:mysql:database=sakila;host=localhost;port=3306";

    $dbh = DBI-&gt;connect($dsn, 'sakila','password');

    my ($filmbase) = $dbh-&gt;selectrow_hashref(sprintf('select * from film where title = %s',
                                                     $dbh-&gt;quote($filmname)));

    if (!defined($filmname))
    {
     	return (undef);
    }

    $filmbase-&gt;{stars} =
	$dbh-&gt;selectall_arrayref(sprintf('select concat(first_name," ",last_name) ' .
                                         'from film_actor left join (actor) ' .
                                         'on (film_actor.actor_id = actor.actor_id) ' .
                                         ' where film_id=%s',
                                         $dbh-&gt;quote($filmbase-&gt;{film_id})));

    return($filmbase);
}
</pre><p>
        The example uses the Sakila database, obtaining film data from
        the database and writing a composite record of the film and
        actors to memcache. When calling it for a film does not exist,
        you should get this result:
      </p><pre class="programlisting">shell&gt; memcached-sakila.pl "ROCK INSTINCT"
Film data loaded from database and cached</pre><p>
        When accessing a film that has already been added to the cache:
      </p><pre class="programlisting">shell&gt; memcached-sakila.pl "ROCK INSTINCT"
Film data loaded from Memcached
</pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-interfaces-python"></a>14.5.3.3. Using MySQL and <span><strong class="command">memcached</strong></span> with Python</h4></div></div></div><p>
        The Python <span><strong class="command">memcache</strong></span> module interfaces to
        <span><strong class="command">memcached</strong></span> servers, and is written in pure
        python (that is, without using one of the C APIs). You can
        download and install a copy from
        <a href="http://www.tummy.com/Community/software/python-memcached/" target="_top">Python
        Memcached</a>.
      </p><p>
        To install, download the package and then run the Python
        installer:
      </p><pre class="programlisting">python setup.py install
running install
running bdist_egg
running egg_info
creating python_memcached.egg-info
...
removing 'build/bdist.linux-x86_64/egg' (and everything under it)
Processing python_memcached-1.43-py2.4.egg
creating /usr/lib64/python2.4/site-packages/python_memcached-1.43-py2.4.egg
Extracting python_memcached-1.43-py2.4.egg to /usr/lib64/python2.4/site-packages
Adding python-memcached 1.43 to easy-install.pth file

Installed /usr/lib64/python2.4/site-packages/python_memcached-1.43-py2.4.egg
Processing dependencies for python-memcached==1.43
Finished processing dependencies for python-memcached==1.43
</pre><p>
        Once installed, the <code class="literal">memcache</code> module provides
        a class-based interface to your <span><strong class="command">memcached</strong></span>
        servers. Serialization of Python structures is handled by using
        the Python <code class="literal">cPickle</code> or
        <code class="literal">pickle</code> modules.
      </p><p>
        To create a new <code class="literal">memcache</code> interface, import
        the <code class="literal">memcache</code> module and create a new instance
        of the <code class="literal">memcache.Client</code> class:
      </p><pre class="programlisting">import memcache
memc = memcache.Client(['127.0.0.1:11211'])</pre><p>
        The first argument should be an array of strings containing the
        server and port number for each <span><strong class="command">memcached</strong></span>
        instance you want to use. You can enable debugging by setting
        the optional <code class="literal">debug</code> parameter to 1.
      </p><p>
        By default, the hashing mechanism used is
        <code class="literal">crc32</code>. This provides a basic module hashing
        algorithm for selecting among multiple servers. You can change
        the function used by setting the value of
        <code class="literal">memcache.serverHashFunction</code> to the alternate
        function you want to use. For example:
      </p><pre class="programlisting">from zlib import adler32
memcache.serverHashFunction = adler32</pre><p>
        Once you have defined the servers to use within the
        <code class="literal">memcache</code> instance, the core functions provide
        the same functionality as in the generic interface
        specification. A summary of the supported functions is provided
        in the following table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Python <code class="literal">memcache</code> Function</th><th>Equivalent to</th></tr></thead><tbody><tr><td><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code></td></tr><tr><td><code class="literal">get_multi(keys)</code></td><td>Gets multiple values from the supplied array of <code class="literal">keys</code>.
                Returns a hash reference of key/value pairs.</td></tr><tr><td><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code></td></tr><tr><td><code class="literal">set_multi(dict [, expiry [, key_prefix]])</code></td><td>Sets multiple key/value pairs from the supplied <code class="literal">dict</code>.</td></tr><tr><td><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code></td></tr><tr><td><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code></td></tr><tr><td><code class="literal">prepend(key, value [, expiry])</code></td><td>Prepends the supplied <code class="literal">value</code> to the value of the
                existing <code class="literal">key</code>.</td></tr><tr><td><code class="literal">append(key, value [, expiry[)</code></td><td>Appends the supplied <code class="literal">value</code> to the value of the
                existing <code class="literal">key</code>.</td></tr><tr><td><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code></td></tr><tr><td><code class="literal">delete_multi(keys [, expiry [, key_prefix]] )</code></td><td>Deletes all the keys from the hash matching each string in the array
                <code class="literal">keys</code>.</td></tr><tr><td><code class="literal">incr()</code></td><td>Generic <code class="literal">incr()</code></td></tr><tr><td><code class="literal">decr()</code></td><td>Generic <code class="literal">decr()</code></td></tr></tbody></table></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          Within the Python <code class="literal">memcache</code> module, all the
          <code class="literal">*_multi()</code>functions support an optional
          <code class="literal">key_prefix</code> parameter. If supplied, then the
          string is used as a prefix to all key lookups. For example, if
          you call:
        </p><pre class="programlisting">memc.get_multi(['a','b'], key_prefix='users:')</pre><p>
          The function will retrieve the keys <code class="literal">users:a</code>
          and <code class="literal">users:b</code> from the servers.
        </p></div><p>
        An example showing the storage and retrieval of information to a
        <code class="literal">memcache</code> instance, loading the raw data from
        MySQL, is shown below:
      </p><pre class="programlisting">import sys
import MySQLdb
import memcache

memc = memcache.Client(['127.0.0.1:11211'], debug=1);

try:
    conn = MySQLdb.connect (host = "localhost",
                            user = "sakila",
                            passwd = "password",
                            db = "sakila")
except MySQLdb.Error, e:
     print "Error %d: %s" % (e.args[0], e.args[1])
     sys.exit (1)

popularfilms = memc.get('top5films')

if not popularfilms:
    cursor = conn.cursor()
    cursor.execute('select film_id,title from film order by rental_rate desc limit 5')
    rows = cursor.fetchall()
    memc.set('top5films',rows,60)
    print "Updated memcached with MySQL data"
else:
    print "Loaded data from memcached"
    for row in popularfilms:
        print "%s, %s" % (row[0], row[1])</pre><p>
        When executed for the first time, the data is loaded from the
        MySQL database and stored to the <span><strong class="command">memcached</strong></span>
        server.
      </p><pre class="programlisting">shell&gt; python memc_python.py
Updated memcached with MySQL data
</pre><p>
        The data is automatically serialized using
        <code class="literal">cPickle</code>/<code class="literal">pickle</code>. This means
        when you load the data back from <span><strong class="command">memcached</strong></span>,
        you can use the object directly. In the example above, the
        information stored to <code class="literal">memcached</code> is in the
        form of rows from a Python DB cursor. When accessing the
        information (within the 60 second expiry time), the data is
        loaded from <code class="literal">memcached</code> and dumped:
      </p><pre class="programlisting">shell&gt; python memc_python.py
Loaded data from memcached
2, ACE GOLDFINGER
7, AIRPLANE SIERRA
8, AIRPORT POLLOCK
10, ALADDIN CALENDAR
13, ALI FOREVER
</pre><p>
        The serialization and deserialization happens automatically, but
        be aware that serialization of Python data may be incompatible
        with other interfaces and languages. You can change the
        serialization module used during initialization, for example to
        use JSON, which will be more easily exchanged.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-interfaces-php"></a>14.5.3.4. Using MySQL and <span><strong class="command">memcached</strong></span> with PHP</h4></div></div></div><p>
        PHP provides support for the Memcache functions through a PECL
        extension. To enable the PHP <code class="literal">memcache</code>
        extensions, you must build PHP using the
        <code class="option">--enable-memcache</code> option to
        <span><strong class="command">configure</strong></span> when building from source.
      </p><p>
        If you are installing on a RedHat based server, you can install
        the <code class="literal">php-pecl-memcache</code> RPM:
      </p><pre class="programlisting">root-shell&gt; yum --install php-pecl-memcache</pre><p>
        On Debian based distributions, use the
        <code class="literal">php-memcache</code> package.
      </p><p>
        You can set global runtime configuration options by specifying
        the values in the following table within your
        <code class="filename">php.ini</code> file.
      </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><thead><tr><th>Configuration option</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">memcache.allow_failover</code></td><td>1</td><td>Specifies whether another server in the list should be queried if the
                first server selected fails.</td></tr><tr><td><code class="literal">memcache.max_failover_attempts</code></td><td>20</td><td>Specifies the number of servers to try before returning a failure.</td></tr><tr><td><code class="literal">memcache.chunk_size</code></td><td>8192</td><td>Defines the size of network chunks used to exchange data with the
                <span><strong class="command">memcached</strong></span> server.</td></tr><tr><td><code class="literal">memcache.default_port</code></td><td>11211</td><td>Defines the default port to use when communicating with the
                <span><strong class="command">memcached</strong></span> servers.</td></tr><tr><td><code class="literal">memcache.hash_strategy</code></td><td>standard</td><td>Specifies which hash strategy to use. Set to
                <code class="literal">consistent</code> to allow servers to be
                added or removed from the pool without causing the keys
                to be remapped to other servers. When set to
                <code class="literal">standard</code>, an older (modula) strategy
                is used that potentially uses different servers for
                storage.</td></tr><tr><td><code class="literal">memcache.hash_function</code></td><td>crc32</td><td>Specifies which function to use when mapping keys to servers.
                <code class="literal">crc32</code> uses the standard CRC32 hash.
                <code class="literal">fnv</code> uses the FNV-1a hashing
                algorithm.</td></tr></tbody></table></div><p>
        To create a connection to a <span><strong class="command">memcached</strong></span> server,
        you need to create a new <code class="literal">Memcache</code> object and
        then specifying the connection options. For example:
      </p><pre class="programlisting">&lt;?php

$cache = new Memcache;
$cache-&gt;connect('localhost',11121);
?&gt;</pre><p>
        This opens an immediate connection to the specified server.
      </p><p>
        To use multiple <span><strong class="command">memcached</strong></span> servers, you need
        to add servers to the memcache object using
        <code class="literal">addServer()</code>:
      </p><pre class="programlisting">bool Memcache::addServer ( string $host [, int $port [, bool $persistent
                 [, int $weight [, int $timeout [, int $retry_interval
                 [, bool $status [, callback $failure_callback
                 ]]]]]]] )</pre><p>
        The server management mechanism within the
        <code class="literal">php-memcache</code> module is a critical part of
        the interface as it controls the main interface to the
        <span><strong class="command">memcached</strong></span> instances and how the different
        instances are selected through the hashing mechanism.
      </p><p>
        To create a simple connection to two
        <span><strong class="command">memcached</strong></span> instances:
      </p><pre class="programlisting">&lt;?php

$cache = new Memcache;
$cache-&gt;addServer('192.168.0.100',11211);
$cache-&gt;addServer('192.168.0.101',11211);
?&gt;</pre><p>
        In this scenario the instance connection is not explicitly
        opened, but only opened when you try to store or retrieve a
        value. You can enable persistent connections to
        <span><strong class="command">memcached</strong></span> instances by setting the
        <code class="literal">$persistent</code> argument to true. This is the
        default setting, and will cause the connections to remain open.
      </p><p>
        To help control the distribution of keys to different instances,
        you should use the global
        <code class="literal">memcache.hash_strategy</code> setting. This sets the
        hashing mechanism used to select. You can also add an additional
        weight to each server, which effectively increases the number of
        times the instance entry appears in the instance list, therefore
        increasing the likelihood of the instance being chosen over
        other instances. To set the weight, set the value of the
        <code class="literal">$weight</code> argument to more than one.
      </p><p>
        The functions for setting and retrieving information are
        identical to the generic functional interface offered by
        <code class="literal">memcached</code>, as shown in this table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>PECL <code class="literal">memcache</code> Function</th><th>Equivalent to</th></tr></thead><tbody><tr><td><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code></td></tr><tr><td><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code></td></tr><tr><td><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code></td></tr><tr><td><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code></td></tr><tr><td><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code></td></tr><tr><td><code class="literal">increment()</code></td><td>Generic <code class="literal">incr()</code></td></tr><tr><td><code class="literal">decrement()</code></td><td>Generic <code class="literal">decr()</code></td></tr></tbody></table></div><p>
        A full example of the PECL <code class="literal">memcache</code> interface
        is provided below. The code loads film data from the Sakila
        database when the user provides a film name. The data stored
        into the <code class="literal">memcached</code> instance is recorded as a
        <code class="literal">mysqli</code> result row, and the API automatically
        serializes the information for you.
      </p><pre class="programlisting">&lt;?php

$memc = new Memcache;
$memc-&gt;addServer('localhost','11211');
?&gt;

&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"&gt;
&lt;head&gt;
 &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
 &lt;title&gt;Simple Memcache Lookup&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;form method="post"&gt;
  &lt;p&gt;&lt;b&gt;Film&lt;/b&gt;: &lt;input type="text" size="20" name="film"&gt;&lt;/p&gt;
&lt;input type="submit"&gt;
&lt;/form&gt;
&lt;hr/&gt;

&lt;?php

  echo "Loading data...\n";

$value = $memc-&gt;get($_REQUEST['film']);

if ($value)
  {
    printf("&lt;p&gt;Film data for %s loaded from memcache&lt;/p&gt;",$value['title']);

    foreach (array_keys($value) as $key)
      {
	printf("&lt;p&gt;&lt;b&gt;%s&lt;/b&gt;: %s&lt;/p&gt;",$key, $value[$key]);
      }
  }
 else
   {
     $con = new mysqli('localhost','sakila','password','sakila') or
       die ("&lt;h1&gt;Database problem&lt;/h1&gt;" . mysqli_connect_error());

     $result = $con-&gt;query(sprintf('select * from film where title ="%s"',$_REQUEST['film']));

     $row = $result-&gt;fetch_array(MYSQLI_ASSOC);

     $memc-&gt;set($row['title'],$row);

     printf("&lt;p&gt;Loaded %s from MySQL&lt;/p&gt;",$row['title']);
   }

?&gt;
</pre><p>
        With PHP, the connections to the <span><strong class="command">memcached</strong></span>
        instances are kept open as long as the PHP and associated Apache
        instance remain running. When adding a removing servers from the
        list in a running instance (for example, when starting another
        script that mentions additional servers), the connections will
        be shared, but the script will only select among the instances
        explicitly configured within the script.
      </p><p>
        To ensure that changes to the server list within a script do not
        cause problems, make sure to use the consistent hashing
        mechanism.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-interfaces-ruby"></a>14.5.3.5. Using MySQL and <span><strong class="command">memcached</strong></span> with Ruby</h4></div></div></div><p>
        There are a number of different modules for interfacing to
        <span><strong class="command">memcached</strong></span> within Ruby. The
        <code class="literal">Ruby-MemCache</code> client library provides a
        native interface to <span><strong class="command">memcached</strong></span> that does not
        require any external libraries, such as
        <code class="literal">libmemcached</code>. You can obtain the installer
        package from
        <a href="http://www.deveiate.org/projects/RMemCache" target="_top">http://www.deveiate.org/projects/RMemCache</a>.
      </p><p>
        To install, extract the package and then run
        <span><strong class="command">install.rb</strong></span>:
      </p><pre class="programlisting">shell&gt; install.rb</pre><p>
        If you have RubyGems, you can install the
        <code class="literal">Ruby-MemCache</code> gem:
      </p><pre class="programlisting">shell&gt; gem install Ruby-MemCache
Bulk updating Gem source index for: http://gems.rubyforge.org
Install required dependency io-reactor? [Yn]  y
Successfully installed Ruby-MemCache-0.0.1
Successfully installed io-reactor-0.05
Installing ri documentation for io-reactor-0.05...
Installing RDoc documentation for io-reactor-0.05...
</pre><p>
        To use a <span><strong class="command">memcached</strong></span> instance from within Ruby,
        create a new instance of the <code class="literal">MemCache</code> object.
      </p><pre class="programlisting">require 'memcache'
memc = MemCache::new '192.168.0.100:11211'</pre><p>
        You can add a weight to each server to increase the likelihood
        of the server being selected during hashing by appending the
        weight count to the server host name/port string:
      </p><pre class="programlisting">require 'memcache'
memc = MemCache::new '192.168.0.100:11211:3'</pre><p>
        To add servers to an existing list, you can append them directly
        to the <code class="literal">MemCache</code> object:
      </p><pre class="programlisting">memc += ["192.168.0.101:11211"]</pre><p>
        To set data into the cache, you can just assign a value to a key
        within the new cache object, which works just like a standard
        Ruby hash object:
      </p><pre class="programlisting">memc["key"] = "value"</pre><p>
        Or to retrieve the value:
      </p><pre class="programlisting">print memc["key"]</pre><p>
        For more explicit actions, you can use the method interface,
        which mimics the main <span><strong class="command">memcached</strong></span> API
        functions, as summarized in the following table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Ruby <code class="literal">MemCache</code> Method</th><th>Equivalent to</th></tr></thead><tbody><tr><td><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code></td></tr><tr><td><code class="literal">get_hash(keys)</code></td><td>Get the values of multiple <code class="literal">keys</code>, returning the
                information as a hash of the keys and their values.</td></tr><tr><td><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code></td></tr><tr><td><code class="literal">set_many(pairs)</code></td><td>Set the values of the keys and values in the hash
                <code class="literal">pairs</code>.</td></tr><tr><td><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code></td></tr><tr><td><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code></td></tr><tr><td><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code></td></tr><tr><td><code class="literal">incr()</code></td><td>Generic <code class="literal">incr()</code></td></tr><tr><td><code class="literal">decr()</code></td><td>Generic <code class="literal">decr()</code></td></tr></tbody></table></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-interfaces-java"></a>14.5.3.6. Using MySQL and <span><strong class="command">memcached</strong></span> with Java</h4></div></div></div><p>
        The <code class="literal">com.danga.MemCached</code> class within Java
        provides a native interface to <span><strong class="command">memcached</strong></span>
        instances. You can obtain the client from
        <a href="http://whalin.com/memcached/" target="_top">http://whalin.com/memcached/</a>. The Java class uses
        hashes that are compatible with <code class="literal">libmemcached</code>,
        so you can mix and match Java and
        <code class="literal">libmemcached</code> applications accessing the same
        <span><strong class="command">memcached</strong></span> instances. The serialization
        between Java and other interfaces will not be compatible. If
        this is a problem, use JSON or a similar nonbinary serialization
        format.
      </p><p>
        On most systems you can download the package and use the
        <code class="filename">jar</code> directly. On OpenSolaris, use
        <span><strong class="command">pkg</strong></span> to install the
        <code class="literal">SUNWmemcached-java</code> package.
      </p><p>
        To use the <code class="literal">com.danga.MemCached</code> interface, you
        create a <code class="literal">MemCachedClient</code> instance and then
        configure the list of servers by configuring the
        <code class="literal">SockIOPool</code>. Through the pool specification
        you set up the server list, weighting, and the connection
        parameters to optimized the connections between your client and
        the <span><strong class="command">memcached</strong></span> instances that you configure.
      </p><p>
        Generally you can configure the <span><strong class="command">memcached</strong></span>
        interface once within a single class and then use this interface
        throughout the rest of your application.
      </p><p>
        For example, to create a basic interface, first configure the
        <code class="literal">MemCachedClient</code> and base
        <code class="literal">SockIOPool</code> settings:
      </p><pre class="programlisting">public class MyClass {

    protected static MemCachedClient mcc = new MemCachedClient();

    static {
	
        String[] servers =
            {
                "localhost:11211",
            };
	
        Integer[] weights = { 1 };
	
        SockIOPool pool = SockIOPool.getInstance();
	
        pool.setServers( servers );
        pool.setWeights( weights );

</pre><p>
        In the above sample, the list of servers is configured by
        creating an array of the <span><strong class="command">memcached</strong></span> instances
        that you want to use. You can then configure individual weights
        for each server.
      </p><p>
        The remainder of the properties for the connection are optional,
        but you can set the connection numbers (initial connections,
        minimum connections, maximum connections, and the idle timeout)
        by setting the pool parameters:
      </p><pre class="programlisting">pool.setInitConn( 5 );
pool.setMinConn( 5 );
pool.setMaxConn( 250 );
pool.setMaxIdle( 1000 * 60 * 60 * 6 </pre><p>
        Once the parameters have been configured, initialize the
        connection pool:
      </p><pre class="programlisting">pool.initialize();</pre><p>
        The pool, and the connection to your
        <span><strong class="command">memcached</strong></span> instances should now be ready to
        use.
      </p><p>
        To set the hashing algorithm used to select the server used when
        storing a given key you can use
        <code class="literal">pool.setHashingAlg()</code>:
      </p><pre class="programlisting">pool.setHashingAlg( SockIOPool.NEW_COMPAT_HASH );</pre><p>
        Valid values ares <code class="literal">NEW_COMPAT_HASH</code>,
        <code class="literal">OLD_COMPAT_HASH</code> and
        <code class="literal">NATIVE_HASH</code> are also basic modula hashing
        algorithms. For a consistent hashing algorithm, use
        <code class="literal">CONSISTENT_HASH</code>. These constants are
        equivalent to the corresponding hash settings within
        <code class="literal">libmemcached</code>.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Java <code class="literal">com.danga.MemCached</code> Method</th><th>Equivalent to</th></tr></thead><tbody><tr><td><code class="literal">get()</code></td><td>Generic <code class="literal">get()</code></td></tr><tr><td><code class="literal">getMulti(keys)</code></td><td>Get the values of multiple <code class="literal">keys</code>, returning the
                information as Hash map using
                <code class="literal">java.lang.String</code> for the keys and
                <code class="literal">java.lang.Object</code> for the
                corresponding values.</td></tr><tr><td><code class="literal">set()</code></td><td>Generic <code class="literal">set()</code></td></tr><tr><td><code class="literal">add()</code></td><td>Generic <code class="literal">add()</code></td></tr><tr><td><code class="literal">replace()</code></td><td>Generic <code class="literal">replace()</code></td></tr><tr><td><code class="literal">delete()</code></td><td>Generic <code class="literal">delete()</code></td></tr><tr><td><code class="literal">incr()</code></td><td>Generic <code class="literal">incr()</code></td></tr><tr><td><code class="literal">decr()</code></td><td>Generic <code class="literal">decr()</code></td></tr></tbody></table></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-interfaces-mysqludf"></a>14.5.3.7. Using the MySQL <span><strong class="command">memcached</strong></span> UDFs</h4></div></div></div><p>
        The <span><strong class="command">memcached</strong></span> MySQL User Defined Functions
        (UDFs) enable you to set and retrieve objects from within MySQL
        5.0 or greater.
      </p><p>
        To install the MySQL <span><strong class="command">memcached</strong></span> UDFs, download
        the UDF package from
        <a href="http://tangent.org/586/Memcached_Functions_for_MySQL.html" target="_top">http://tangent.org/586/Memcached_Functions_for_MySQL.html</a>.
        You will need to unpack the package and run
        <span><strong class="command">configure</strong></span> to configure the build process.
        When running <span><strong class="command">configure</strong></span>, use the
        <code class="literal">--with-mysql</code> option and specify the location
        of the <a href="programs.html#mysql-config" title="4.7.2. mysql_config — Get Compile Options for Compiling Clients"><span><strong class="command">mysql_config</strong></span></a> command. Note that you
        must be running :
      </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>tar zxf memcached_functions_mysql-0.5.tar.gz</code></strong>
shell&gt; <strong class="userinput"><code>cd memcached_functions_mysql-0.5</code></strong>
shell&gt; <strong class="userinput"><code>./configure --with-mysql-config=/usr/local/mysql/bin/mysql_config</code></strong>
</pre><p>
        Now build and install the functions:
      </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>make</code></strong>
shell&gt; <strong class="userinput"><code>make install</code></strong></pre><p>
        You may want to copy the MySQL <span><strong class="command">memcached</strong></span> UDFs
        into your MySQL plugins directory:
      </p><pre class="programlisting">shell&gt; <strong class="userinput"><code>cp /usr/local/lib/libmemcached_functions_mysql* /usr/local/mysql/lib/mysql/plugins/</code></strong></pre><p>
        Once installed, you must initialize the function within MySQL
        using <code class="literal">CREATE</code> and specifying the return value
        and library. For example, to add the
        <code class="literal">memc_get()</code> function:
      </p><pre class="programlisting">mysql&gt; CREATE FUNCTION memc_get RETURNS STRING SONAME "libmemcached_functions_mysql.so";</pre><p>
        You must repeat this process for each function that you want to
        provide access to within MySQL. Once you have created the
        association, the information will be retained, even over
        restarts of the MySQL server. You can simplify the process by
        using the SQL script provided in the
        <code class="literal">memcached</code> UDFs package:
      </p><pre class="programlisting">shell&gt; mysql &lt;sql/install_functions.sql</pre><p>
        Alternatively, if you have Perl installed, then you can use the
        supplied Perl script, which will check for the existence of each
        function and create the function/library association if it has
        not already been defined:
      </p><pre class="programlisting">shell&gt; utils/install.pl --silent</pre><p>
        The <code class="literal">--silent</code> option installs everything
        automatically. Without this option, the script will ask whether
        you want to install each of the available functions.
      </p><p>
        The interface remains consistent with the other APIs and
        interfaces. To set up a list of servers, use the
        <code class="literal">memc_servers_set()</code> function, which accepts a
        single string containing and comma-separated list of servers:
      </p><pre class="programlisting">mysql&gt; SELECT memc_servers_set('192.168.0.1:11211,192.168.0.2:11211');</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          The list of servers used by the <span><strong class="command">memcached</strong></span>
          UDFs is not persistent over restarts of the MySQL server. If
          the MySQL server fails, then you must re-set the list of
          <span><strong class="command">memcached</strong></span> servers.
        </p></div><p>
        To set a value, use <code class="literal">memc_set</code>:
      </p><pre class="programlisting">mysql&gt; SELECT memc_set('myid', 'myvalue');</pre><p>
        To retrieve a stored value:
      </p><pre class="programlisting">mysql&gt; SELECT memc_get('myid');</pre><p>
        The list of functions supported by the UDFs, in relation to the
        standard protocol functions, is shown in the following table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>MySQL <code class="literal">memcached</code> UDF Function</th><th>Equivalent to</th></tr></thead><tbody><tr><td><code class="literal">memc_get()</code></td><td>Generic <code class="literal">get()</code></td></tr><tr><td><code class="literal">memc_get_by_key(master_key, key, value)</code></td><td>Like the generic <code class="literal">get()</code>, but uses the supplied master
                key to select the server to use.</td></tr><tr><td><code class="literal">memc_set()</code></td><td>Generic <code class="literal">set()</code></td></tr><tr><td><code class="literal">memc_set_by_key(master_key, key, value)</code></td><td>Like the generic <code class="literal">set()</code>, but uses the supplied master
                key to select the server to use.</td></tr><tr><td><code class="literal">memc_add()</code></td><td>Generic <code class="literal">add()</code></td></tr><tr><td><code class="literal">memc_add_by_key(master_key, key, value)</code></td><td>Like the generic <code class="literal">add()</code>, but uses the supplied master
                key to select the server to use.</td></tr><tr><td><code class="literal">memc_replace()</code></td><td>Generic <code class="literal">replace()</code></td></tr><tr><td><code class="literal">memc_replace_by_key(master_key, key, value)</code></td><td>Like the generic <code class="literal">replace()</code>, but uses the supplied
                master key to select the server to use.</td></tr><tr><td><code class="literal">memc_prepend(key, value)</code></td><td>Prepend the specified <code class="literal">value</code> to the current value of
                the specified <code class="literal">key</code>.</td></tr><tr><td><code class="literal">memc_prepend_by_key(master_key, key, value)</code></td><td>Prepend the specified <code class="literal">value</code> to the current value of
                the specified <code class="literal">key</code>, but uses the
                supplied master key to select the server to use.</td></tr><tr><td><code class="literal">memc_append(key, value)</code></td><td>Append the specified <code class="literal">value</code> to the current value of
                the specified <code class="literal">key</code>.</td></tr><tr><td><code class="literal">memc_append_by_key(master_key, key, value)</code></td><td>Append the specified <code class="literal">value</code> to the current value of
                the specified <code class="literal">key</code>, but uses the
                supplied master key to select the server to use.</td></tr><tr><td><code class="literal">memc_delete()</code></td><td>Generic <code class="literal">delete()</code></td></tr><tr><td><code class="literal">memc_delete_by_key(master_key, key, value)</code></td><td>Like the generic <code class="literal">delete()</code>, but uses the supplied
                master key to select the server to use.</td></tr><tr><td><code class="literal">memc_increment()</code></td><td>Generic <code class="literal">incr()</code></td></tr><tr><td><code class="literal">memc_decrement()</code></td><td>Generic <code class="literal">decr()</code></td></tr></tbody></table></div><p>
        The respective <code class="literal">*_by_key()</code> functions are
        useful when you want to store a specific value into a specific
        <span><strong class="command">memcached</strong></span> server, possibly based on a
        differently calculated or constructed key.
      </p><p>
        The <code class="literal">memcached</code> UDFs include some additional
        functions:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <code class="literal">memc_server_count()</code>
          </p><p>
            Returns a count of the number of servers in the list of
            registered servers.
          </p></li><li><p>
            <code class="literal">memc_servers_set_behavior(behavior_type,
            value)</code>, <code class="literal">memc_set_behavior(behavior_type,
            value)</code>
          </p><p>
            Set behaviors for the list of servers. These behaviors are
            identical to those provided by the
            <code class="literal">libmemcached</code> library. For more
            information on <code class="literal">libmemcached</code> behaviors,
            see <a href="ha-overview.html#ha-memcached-interfaces-libmemcached" title="14.5.3.1. Using libmemcached">Section 14.5.3.1, “Using <code class="literal">libmemcached</code>”</a>.
          </p><p>
            You can use the behavior name as the
            <code class="literal">behavior_type</code>:
          </p><pre class="programlisting">mysql&gt; SELECT memc_servers_behavior_set("MEMCACHED_BEHAVIOR_KETAMA",1);</pre></li><li><p>
            <code class="literal">memc_servers_behavior_get(behavior_type)</code>,
            <code class="literal">memc_get_behavior(behavior_type, value)</code>
          </p><p>
            Returns the value for a given behavior.
          </p></li><li><p>
            <code class="literal">memc_list_behaviors()</code>
          </p><p>
            Returns a list of the known behaviors.
          </p></li><li><p>
            <code class="literal">memc_list_hash_types()</code>
          </p><p>
            Returns a list of the supported key-hashing algorithms.
          </p></li><li><p>
            <code class="literal">memc_list_distribution_types()</code>
          </p><p>
            Returns a list of the supported distribution types to be
            used when selecting a server to use when storing a
            particular key.
          </p></li><li><p>
            <code class="literal">memc_libmemcached_version()</code>
          </p><p>
            Returns the version of the <code class="literal">libmemcached</code>
            library.
          </p></li><li><p>
            <code class="literal">memc_stats()</code>
          </p><p>
            Returns the general statistics information from the server.
          </p></li></ul></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-interfaces-protocol"></a>14.5.3.8. <span><strong class="command">memcached</strong></span> Protocol</h4></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-memcached-interfaces-protocol-tcp">14.5.3.8.1. Using the TCP text protocol</a></span></dt></dl></div><p>
        Communicating with a <span><strong class="command">memcached</strong></span> server can be
        achieved through either the TCP or UDP protocols. When using the
        TCP protocol you can use a simple text based interface for the
        exchange of information.
      </p><div class="section" lang="en"><div class="titlepage"><div><div><h5 class="title"><a name="ha-memcached-interfaces-protocol-tcp"></a>14.5.3.8.1. Using the TCP text protocol</h5></div></div></div><p>
          When communicating with <span><strong class="command">memcached</strong></span> you can
          connect to the server using the port configured for the
          server. You can open a connection with the server without
          requiring authorization or login. As soon as you have
          connected, you can start to send commands to the server. When
          you have finished, you can terminate the connection without
          sending any specific disconnection command. Clients are
          encouraged to keep their connections open to decrease latency
          and improve performance.
        </p><p>
          Data is sent to the <code class="literal">memcached</code> server in two
          forms:
        </p><div class="itemizedlist"><ul type="disc"><li><p>
              Text lines, which are used to send commands to the server,
              and receive responses from the server.
            </p></li><li><p>
              Unstructured data, which is used to receive or send the
              value information for a given key. Data is returned to the
              client in exactly the format it was provided.
            </p></li></ul></div><p>
          Both text lines (commands and responses) and unstructured data
          are always terminated with the string <code class="literal">\r\n</code>.
          Because the data being stored may contain this sequence, the
          length of the data (returned by the client before the
          unstructured data is transmitted should be used to determine
          the end of the data.
        </p><p>
          Commands to the server are structured according to their
          operation:
        </p><div class="itemizedlist"><ul type="disc"><li><p>
              <span class="bold"><strong>Storage commands</strong></span>:
              <code class="literal">set</code>, <code class="literal">add</code>,
              <code class="literal">replace</code>, <code class="literal">append</code>,
              <code class="literal">prepend</code>, <code class="literal">cas</code>
            </p><p>
              Storage commands to the server take the form:
            </p><pre class="programlisting">command key [flags] [exptime] length [noreply]</pre><p>
              Or when using compare and swap (cas):
            </p><pre class="programlisting">cas key [flags] [exptime] length [casunique] [noreply]</pre><p>
              Where:
            </p><div class="itemizedlist"><ul type="circle"><li><p>
                  <code class="literal">command</code> — the command name.
                </p><div class="itemizedlist"><ul type="square"><li><p>
                      <code class="literal">set</code> — Store value against
                      key
                    </p></li><li><p>
                      <code class="literal">add</code> — Store this value
                      against key if the key does not already exist
                    </p></li><li><p>
                      <code class="literal">replace</code> — Store this
                      value against key if the key already exists
                    </p></li><li><p>
                      <code class="literal">append</code> — Append the
                      supplied value to the end of the value for the
                      specified key. The <code class="literal">flags</code> and
                      <code class="literal">exptime</code> arguments should not be
                      used.
                    </p></li><li><p>
                      <code class="literal">prepend</code> — Append value
                      currently in the cache to the end of the supplied
                      value for the specified key. The
                      <code class="literal">flags</code> and
                      <code class="literal">exptime</code> arguments should not be
                      used.
                    </p></li><li><p>
                      <code class="literal">cas</code> — Set the specified
                      key to the supplied value, only if the supplied
                      <code class="literal">casunique</code> matches. This is
                      effectively the equivalent of change the
                      information if nobody has updated it since I last
                      fetched it.
                    </p></li></ul></div></li><li><p>
                  <code class="literal">key</code> — the key. All data is
                  stored using a the specific key. The key cannot
                  contain control characters or whitespace, and can be
                  up to 250 characters in size.
                </p></li><li><p>
                  <code class="literal">flags</code> — the flags for the
                  operation (as an integer). Flags in
                  <span><strong class="command">memcached</strong></span> are transparent. The
                  <span><strong class="command">memcached</strong></span> server ignores the
                  contents of the flags. They can be used by the client
                  to indicate any type of information. In
                  <span><strong class="command">memcached</strong></span> 1.2.0 and lower the value
                  is a 16-bit integer value. In
                  <span><strong class="command">memcached</strong></span> 1.2.1 and higher the
                  value is a 32-bit integer.
                </p></li><li><p>
                  <code class="literal">exptime</code> — the expiry time, or
                  zero for no expiry.
                </p></li><li><p>
                  <code class="literal">length</code> — the length of the
                  supplied value block in bytes, excluding the
                  terminating <code class="literal">\r\n</code> characters.
                </p></li><li><p>
                  <code class="literal">casunique</code> — is a unique
                  64-bit value of an existing entry. This will be used
                  to compare against the existing value. You should use
                  the value returned by the <code class="literal">gets</code>
                  command when issuing <code class="literal">cas</code> updates.
                </p></li><li><p>
                  <code class="literal">noreply</code> — tells the server
                  not to reply to the command.
                </p></li></ul></div><p>
              For example, to store the value <code class="literal">abcdef</code>
              into the key <code class="literal">xyzkey</code>, you would use:
            </p><pre class="programlisting">set xyzkey 0 0 6\r\nabcdef\r\n</pre><p>
              The return value from the server will be one line,
              specifying the status or error information. For more
              information, see
              <a href="ha-overview.html#ha-memcached-interfaces-protocol-responses" title="Table 14.2. memcached Protocol Responses">Table 14.2, “<span>memcached</span> Protocol Responses”</a>.
            </p></li><li><p>
              <span class="bold"><strong>Retrieval commands</strong></span>:
              <code class="literal">get</code>, <code class="literal">gets</code>
            </p><p>
              Retrieval commands take the form:
            </p><pre class="programlisting">get key1 [key2 .... keyn]
gets key1 [key2 ... keyn]</pre><p>
              You can supply multiple keys to the commands, with each
              requested key separated by whitespace.
            </p><p>
              The server will respond with an information line of the
              form:
            </p><pre class="programlisting">VALUE key flags bytes [casunique]</pre><p>
              Where:
            </p><div class="itemizedlist"><ul type="circle"><li><p>
                  <code class="literal">key</code> — the key name.
                </p></li><li><p>
                  <code class="literal">flags</code> — the value of the flag
                  integer supplied to the <span><strong class="command">memcached</strong></span>
                  server when the value was stored.
                </p></li><li><p>
                  <code class="literal">bytes</code> — the size (excluding
                  the terminating <code class="literal">\r\n</code> character
                  sequence) of the stored value.
                </p></li><li><p>
                  <code class="literal">casunique</code> — the unique 64-bit
                  integer that identifies the item.
                </p></li></ul></div><p>
              The information line will immediately be followed by the
              value data block. For example:
            </p><pre class="programlisting">get xyzkey\r\n
VALUE xyzkey 0 6\r\n
abcdef\r\n</pre><p>
              If you have requested multiple keys, an information line
              and data block will be returned for each key found. If a
              requested key does not exist in the cache, no information
              is returned.
            </p></li><li><p>
              <span class="bold"><strong>Delete commands</strong></span>:
              <code class="literal">delete</code>
            </p><p>
              Deletion commands take the form:
            </p><pre class="programlisting">delete key [time] [noreply]</pre><p>
              Where:
            </p><div class="itemizedlist"><ul type="circle"><li><p>
                  <code class="literal">key</code> — the key name.
                </p></li><li><p>
                  <code class="literal">time</code> — the time in seconds
                  (or a specific Unix time) for which the client wishes
                  the server to refuse <code class="literal">add</code> or
                  <code class="literal">replace</code> commands on this key. All
                  <code class="literal">add</code>, <code class="literal">replace</code>,
                  <code class="literal">get</code>, and <code class="literal">gets</code>
                  commands will fail during this period.
                  <code class="literal">set</code> operations will succeed. After
                  this period, the key will be deleted permanently and
                  all commands will be accepted.
                </p><p>
                  If not supplied, the value is assumed to be zero
                  (delete immediately).
                </p></li><li><p>
                  <code class="literal">noreply</code> — tells the server
                  not to reply to the command.
                </p></li></ul></div><p>
              Responses to the command will either be
              <code class="literal">DELETED</code> to indicate that the key was
              successfully removed, or <code class="literal">NOT_FOUND</code> to
              indicate that the specified key could not be found.
            </p></li><li><p>
              <span class="bold"><strong>Increment/Decrement</strong></span>:
              <code class="literal">incr</code>, <code class="literal">decr</code>
            </p><p>
              The increment and decrement commands change the value of a
              key within the server without performing a separate
              get/set sequence. The operations assume that the currently
              stored value is a 64-bit integer. If the stored value is
              not a 64-bit integer, then the value is assumed to be zero
              before the increment or decrement operation is applied.
            </p><p>
              Increment and decrement commands take the form:
            </p><pre class="programlisting">incr key value [noreply]
decr key value [noreply]</pre><p>
              Where:
            </p><div class="itemizedlist"><ul type="circle"><li><p>
                  <code class="literal">key</code> — the key name.
                </p></li><li><p>
                  <code class="literal">value</code> — an integer to be used
                  as the increment or decrement value.
                </p></li><li><p>
                  <code class="literal">noreply</code> — tells the server
                  not to reply to the command.
                </p></li></ul></div><p>
              The response will be:
            </p><div class="itemizedlist"><ul type="circle"><li><p>
                  <code class="literal">NOT_FOUND</code> — the specified key
                  could not be located.
                </p></li><li><p>
                  <code class="literal">value</code> — the new value of the
                  specified key.
                </p></li></ul></div><p>
              Values are assumed to be unsigned. For
              <code class="literal">decr</code> operations the value will never be
              decremented below 0. For <code class="literal">incr</code>
              operations, the value will be wrap around the 64-bit
              maximum.
            </p></li><li><p>
              <span class="bold"><strong>Statistics commands</strong></span>:
              <code class="literal">stats</code>
            </p><p>
              The <code class="literal">stats</code> command provides detailed
              statistical information about the current status of the
              <span><strong class="command">memcached</strong></span> instance and the data it is
              storing.
            </p><p>
              Statistics commands take the form:
            </p><pre class="programlisting">STAT [name] [value]</pre><p>
              Where:
            </p><div class="itemizedlist"><ul type="circle"><li><p>
                  <code class="literal">name</code> — is the optional name
                  of the statistics to return. If not specified, the
                  general statistics are returned.
                </p></li><li><p>
                  <code class="literal">value</code> — a specific value to
                  be used when performing certain statistics operations.
                </p></li></ul></div><p>
              The return value is a list of statistics data, formatted
              as follows:
            </p><pre class="programlisting">STAT name value</pre><p>
              The statistics are terminated with a single line,
              <code class="literal">END</code>.
            </p><p>
              For more information, see
              <a href="ha-overview.html#ha-memcached-stats" title="14.5.4. Getting memcached Statistics">Section 14.5.4, “Getting <span><strong class="command">memcached</strong></span> Statistics”</a>.
            </p></li></ul></div><p>
          For reference, a list of the different commands supported and
          their formats is provided below.
        </p><div class="table"><a name="id2189862"></a><p class="title"><b>Table 14.1. <span>memcached</span> Command Reference</b></p><table summary="memcached Command Reference" border="1"><colgroup><col><col></colgroup><thead><tr><th>Command</th><th>Command Formats</th></tr></thead><tbody><tr><td><code class="literal">set</code></td><td><code class="literal">set key flags exptime length</code>, <code class="literal">set key flags
                  exptime length noreply</code></td></tr><tr><td><code class="literal">add</code></td><td><code class="literal">add key flags exptime length</code>, <code class="literal">add key flags
                  exptime length noreply</code></td></tr><tr><td><code class="literal">replace</code></td><td><code class="literal">replace key flags exptime length</code>, <code class="literal">replace
                  key flags exptime length noreply</code></td></tr><tr><td><code class="literal">append</code></td><td><code class="literal">append key length</code>, <code class="literal">append key length
                  noreply</code></td></tr><tr><td><code class="literal">prepend</code></td><td><code class="literal">prepend key length</code>, <code class="literal">prepend key length
                  noreply</code></td></tr><tr><td><code class="literal">cas</code></td><td><code class="literal">cas key flags exptime length casunique</code>, <code class="literal">cas
                  key flags exptime length casunique noreply</code></td></tr><tr><td><code class="literal">get</code></td><td><code class="literal">get key1 [key2 ... keyn]</code></td></tr><tr><td><code class="literal">gets</code></td><td><code class="literal"></code></td></tr><tr><td><code class="literal">delete</code></td><td><code class="literal">delete key</code>, <code class="literal">delete key noreply</code>,
                  <code class="literal">delete key expiry</code>, <code class="literal">delete
                  key expory noreply</code></td></tr><tr><td><code class="literal">incr</code></td><td><code class="literal">incr key</code>, <code class="literal">incr key noreply</code>,
                  <code class="literal">incr key value</code>, <code class="literal">incr key
                  value noreply</code></td></tr><tr><td><code class="literal">decr</code></td><td><code class="literal">decr key</code>, <code class="literal">decr key noreply</code>,
                  <code class="literal">decr key value</code>, <code class="literal">decr key
                  value noreply</code></td></tr><tr><td><code class="literal">stat</code></td><td><code class="literal">stat</code>, <code class="literal">stat name</code>, <code class="literal">stat
                  name value</code></td></tr></tbody></table></div><p>
          When sending a command to the server, the response from the
          server will be one of the settings in the following table. All
          response values from the server are terminated by
          <code class="literal">\r\n</code>:
        </p><div class="table"><a name="ha-memcached-interfaces-protocol-responses"></a><p class="title"><b>Table 14.2. <span>memcached</span> Protocol Responses</b></p><table summary="memcached Protocol Responses" border="1"><colgroup><col><col></colgroup><thead><tr><th>String</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">STORED</code></td><td>Value has successfully been stored.</td></tr><tr><td><code class="literal">NOT_STORED</code></td><td>The value was not stored, but not because of an error. For commands
                  where you are adding a or updating a value if it
                  exists (such as <code class="literal">add</code> and
                  <code class="literal">replace</code>), or where the item has
                  already been set to be deleted.</td></tr><tr><td><code class="literal">EXISTS</code></td><td>When using a <code class="literal">cas</code> command, the item you are trying to
                  store already exists and has been modified since you
                  last checked it.</td></tr><tr><td><code class="literal">NOT_FOUND</code></td><td>The item you are trying to store, update or delete does not exist or has
                  already been deleted.</td></tr><tr><td><code class="literal">ERROR</code></td><td>You submitted a nonexistent command name.</td></tr><tr><td><code class="literal">CLIENT_ERROR errorstring</code></td><td>There was an error in the input line, the detail is contained in
                  <code class="literal">errorstring</code>.</td></tr><tr><td><code class="literal">SERVER_ERROR errorstring</code></td><td>There was an error in the server that prevents it from returning the
                  information. In extreme conditions, the server may
                  disconnect the client after this error occurs.</td></tr><tr><td><code class="literal">VALUE keys flags length</code></td><td>The requested key has been found, and the stored <code class="literal">key</code>,
                  <code class="literal">flags</code> and data block will be
                  returned, of the specified <code class="literal">length</code>.</td></tr><tr><td><code class="literal">DELETED</code></td><td>The requested key was deleted from the server.</td></tr><tr><td><code class="literal">STAT name value</code></td><td>A line of statistics data.</td></tr><tr><td><code class="literal">END</code></td><td>The end of the statistics data.</td></tr></tbody></table></div></div></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-memcached-stats"></a>14.5.4. Getting <span><strong class="command">memcached</strong></span> Statistics</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-general">14.5.4.1. <span><strong class="command">memcached</strong></span> General Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-slabs">14.5.4.2. <span><strong class="command">memcached</strong></span> Slabs Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-items">14.5.4.3. <span><strong class="command">memcached</strong></span> Item Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-sizes">14.5.4.4. <span><strong class="command">memcached</strong></span> Size Statistics</a></span></dt><dt><span class="section"><a href="ha-overview.html#ha-memcached-stats-detail">14.5.4.5. <code class="literal">memcached</code> Detail Statistics</a></span></dt></dl></div><p>
      The <span><strong class="command">memcached</strong></span> system has a built in statistics
      system that collects information about the data being stored into
      the cache, cache hit ratios, and detailed information on the
      memory usage and distribution of information through the slab
      allocation used to store individual items. Statistics are provided
      at both a basic level that provide the core statistics, and more
      specific statistics for specific areas of the
      <span><strong class="command">memcached</strong></span> server.
    </p><p>
      This information can prove be very useful to ensure that you are
      getting the correct level of cache and memory usage, and that your
      slab allocation and configuration properties are set at an optimal
      level.
    </p><p>
      The stats interface is available through the standard
      <span><strong class="command">memcached</strong></span> protocol, so the reports can be
      accessed by using <span><strong class="command">telnet</strong></span> to connect to the
      <span><strong class="command">memcached</strong></span>. Alternatively, most of the language
      API interfaces provide a function for obtaining the statistics
      from the server.
    </p><p>
      For example, to get the basic stats using
      <span><strong class="command">telnet</strong></span>:
    </p><pre class="programlisting">shell&gt; telnet localhost 11211
Trying ::1...
Connected to localhost.
Escape character is '^]'.
stats
STAT pid 23599
STAT uptime 675
STAT time 1211439587
STAT version 1.2.5
STAT pointer_size 32
STAT rusage_user 1.404992
STAT rusage_system 4.694685
STAT curr_items 32
STAT total_items 56361
STAT bytes 2642
STAT curr_connections 53
STAT total_connections 438
STAT connection_structures 55
STAT cmd_get 113482
STAT cmd_set 80519
STAT get_hits 78926
STAT get_misses 34556
STAT evictions 0
STAT bytes_read 6379783
STAT bytes_written 4860179
STAT limit_maxbytes 67108864
STAT threads 1
END
</pre><p>
      When using Perl and the <code class="literal">Cache::Memcached</code>
      module, the <code class="literal">stats()</code> function returns
      information about all the servers currently configured in the
      connection object, and total statistics for all the
      <span><strong class="command">memcached</strong></span> servers as a whole.
    </p><p>
      For example, the following Perl script will obtain the stats and
      dump the hash reference that is returned:
    </p><pre class="programlisting">use Cache::Memcached;
use Data::Dumper;

my $memc = new Cache::Memcached;
$memc-&gt;set_servers(\@ARGV);

print Dumper($memc-&gt;stats());
</pre><p>
      When executed on the same <span><strong class="command">memcached</strong></span> as used in
      the <span><strong class="command">Telnet</strong></span> example above we get a hash
      reference with the host by host and total statistics:
    </p><pre class="programlisting">$VAR1 = {
    'hosts' =&gt; {
           'localhost:11211' =&gt; {
                      'misc' =&gt; {
                            'bytes' =&gt; '2421',
                            'curr_connections' =&gt; '3',
                            'connection_structures' =&gt; '56',
                            'pointer_size' =&gt; '32',
                            'time' =&gt; '1211440166',
                            'total_items' =&gt; '410956',
                            'cmd_set' =&gt; '588167',
                            'bytes_written' =&gt; '35715151',
                            'evictions' =&gt; '0',
                            'curr_items' =&gt; '31',
                            'pid' =&gt; '23599',
                            'limit_maxbytes' =&gt; '67108864',
                            'uptime' =&gt; '1254',
                            'rusage_user' =&gt; '9.857805',
                            'cmd_get' =&gt; '838451',
                            'rusage_system' =&gt; '34.096988',
                            'version' =&gt; '1.2.5',
                            'get_hits' =&gt; '581511',
                            'bytes_read' =&gt; '46665716',
                            'threads' =&gt; '1',
                            'total_connections' =&gt; '3104',
                            'get_misses' =&gt; '256940'
                          },
                      'sizes' =&gt; {
                             '128' =&gt; '16',
                             '64' =&gt; '15'
                           }
                    }
         },
    'self' =&gt; {},
    'total' =&gt; {
           'cmd_get' =&gt; 838451,
           'bytes' =&gt; 2421,
           'get_hits' =&gt; 581511,
           'connection_structures' =&gt; 56,
           'bytes_read' =&gt; 46665716,
           'total_items' =&gt; 410956,
           'total_connections' =&gt; 3104,
           'cmd_set' =&gt; 588167,
           'bytes_written' =&gt; 35715151,
           'curr_items' =&gt; 31,
           'get_misses' =&gt; 256940
         }
        };
</pre><p>
      The statistics are divided up into a number of distinct sections,
      and then can be requested by adding the type to the
      <code class="literal">stats</code> command. Each statistics output is
      covered in more detail in the following sections.
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          General statistics, see
          <a href="ha-overview.html#ha-memcached-stats-general" title="14.5.4.1. memcached General Statistics">Section 14.5.4.1, “<span><strong class="command">memcached</strong></span> General Statistics”</a>.
        </p></li><li><p>
          Slab statistics (<code class="literal">slabs</code>), see
          <a href="ha-overview.html#ha-memcached-stats-slabs" title="14.5.4.2. memcached Slabs Statistics">Section 14.5.4.2, “<span><strong class="command">memcached</strong></span> Slabs Statistics”</a>.
        </p></li><li><p>
          Item statistics (<code class="literal">items</code>), see
          <a href="ha-overview.html#ha-memcached-stats-items" title="14.5.4.3. memcached Item Statistics">Section 14.5.4.3, “<span><strong class="command">memcached</strong></span> Item Statistics”</a>.
        </p></li><li><p>
          Size statistics (<code class="literal">sizes</code>), see
          <a href="ha-overview.html#ha-memcached-stats-sizes" title="14.5.4.4. memcached Size Statistics">Section 14.5.4.4, “<span><strong class="command">memcached</strong></span> Size Statistics”</a>.
        </p></li><li><p>
          Detailed status (<code class="literal">detail</code>), see
          <a href="ha-overview.html#ha-memcached-stats-detail" title="14.5.4.5. memcached Detail Statistics">Section 14.5.4.5, “<code class="literal">memcached</code> Detail Statistics”</a>.
        </p></li></ul></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-stats-general"></a>14.5.4.1. <span><strong class="command">memcached</strong></span> General Statistics</h4></div></div></div><p>
        The output of the general statistics provides an overview of the
        performance and use of the <span><strong class="command">memcached</strong></span>
        instance. The statistics returned by the command and their
        meaning is shown in the following table.
      </p><p>
        The following terms are used to define the value type for each
        statistics value:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <code class="literal">32u</code> — 32-bit unsigned integer
          </p></li><li><p>
            <code class="literal">64u</code> — 64-bit unsigned integer
          </p></li><li><p>
            <code class="literal">32u32u</code> — Two 32-bit unsigned
            integers separated by a colon
          </p></li><li><p>
            <code class="literal">String</code> — Character string
          </p></li></ul></div><div class="informaltable"><table border="1"><colgroup><col><col><col><col></colgroup><thead><tr><th>Statistic</th><th>Data type</th><th>Description</th><th>Version</th></tr></thead><tbody><tr><td>pid</td><td>32u</td><td>Process id of the <span><strong class="command">memcached</strong></span> instance.</td><td class="auto-generated"> </td></tr><tr><td>uptime</td><td>32u</td><td>Uptime (in seconds) for this <span><strong class="command">memcached</strong></span> instance.</td><td class="auto-generated"> </td></tr><tr><td>time</td><td>32u</td><td>Current time (as epoch).</td><td class="auto-generated"> </td></tr><tr><td>version</td><td>string</td><td>Version string of this instance.</td><td class="auto-generated"> </td></tr><tr><td>pointer_size</td><td>string</td><td>Size of pointers for this host specified in bits (32 or 64).</td><td class="auto-generated"> </td></tr><tr><td>rusage_user</td><td>32u:32u</td><td>Total user time for this instance (seconds:microseconds).</td><td class="auto-generated"> </td></tr><tr><td>rusage_system</td><td>32u:32u</td><td>Total system time for this instance (seconds:microseconds).</td><td class="auto-generated"> </td></tr><tr><td>curr_items</td><td>32u</td><td>Current number of items stored by this instance.</td><td class="auto-generated"> </td></tr><tr><td>total_items</td><td>32u</td><td>Total number of items stored during the life of this instance.</td><td class="auto-generated"> </td></tr><tr><td>bytes</td><td>64u</td><td>Current number of bytes used by this server to store items.</td><td class="auto-generated"> </td></tr><tr><td>curr_connections</td><td>32u</td><td>Current number of open connections.</td><td class="auto-generated"> </td></tr><tr><td>total_connections</td><td>32u</td><td>Total number of connections opened since the server started running.</td><td class="auto-generated"> </td></tr><tr><td>connection_structures</td><td>32u</td><td>Number of connection structures allocated by the server.</td><td class="auto-generated"> </td></tr><tr><td>cmd_get</td><td>64u</td><td>Total number of retrieval requests (<code class="literal">get</code> operations).</td><td class="auto-generated"> </td></tr><tr><td>cmd_set</td><td>64u</td><td>Total number of storage requests (<code class="literal">set</code> operations).</td><td class="auto-generated"> </td></tr><tr><td>get_hits</td><td>64u</td><td>Number of keys that have been requested and found present.</td><td class="auto-generated"> </td></tr><tr><td>get_misses</td><td>64u</td><td>Number of items that have been requested and not found.</td><td class="auto-generated"> </td></tr><tr><td>delete_hits</td><td>64u</td><td>Number of keys that have been deleted and found present.</td><td>1.3.x</td></tr><tr><td>delete_misses</td><td>64u</td><td>Number of items that have been delete and not found.</td><td>1.3.x</td></tr><tr><td>incr_hits</td><td>64u</td><td>Number of keys that have been incremented and found present.</td><td>1.3.x</td></tr><tr><td>incr_misses</td><td>64u</td><td>Number of items that have been incremented and not found.</td><td>1.3.x</td></tr><tr><td>decr_hits</td><td>64u</td><td>Number of keys that have been decremented and found present.</td><td>1.3.x</td></tr><tr><td>decr_misses</td><td>64u</td><td>Number of items that have been decremented and not found.</td><td>1.3.x</td></tr><tr><td>cas_hits</td><td>64u</td><td>Number of keys that have been compared and swapped and found present.</td><td>1.3.x</td></tr><tr><td>cas_misses</td><td>64u</td><td>Number of items that have been compared and swapped and not found.</td><td>1.3.x</td></tr><tr><td>cas_badvalue</td><td>64u</td><td>Number of keys that have been compared and swapped, but the comparison
                (original) value did not match the supplied value.</td><td>1.3.x</td></tr><tr><td>evictions</td><td>64u</td><td>Number of valid items removed from cache to free memory for new items.</td><td class="auto-generated"> </td></tr><tr><td>bytes_read</td><td>64u</td><td>Total number of bytes read by this server from network.</td><td class="auto-generated"> </td></tr><tr><td>bytes_written</td><td>64u</td><td>Total number of bytes sent by this server to network.</td><td class="auto-generated"> </td></tr><tr><td>limit_maxbytes</td><td>32u</td><td>Number of bytes this server is allowed to use for storage.</td><td class="auto-generated"> </td></tr><tr><td>threads</td><td>32u</td><td>Number of worker threads requested.</td><td class="auto-generated"> </td></tr><tr><td>conn_yields</td><td>64u</td><td>Number of yields for connections (related to the <code class="option">-R</code>
                option).</td><td>1.4.0</td></tr></tbody></table></div><p>
        The most useful statistics from those given here are the number
        of cache hits, misses, and evictions.
      </p><p>
        A large number of <code class="literal">get_misses</code> may just be an
        indication that the cache is still being populated with
        information. The number should, over time, decrease in
        comparison to the number of cache <code class="literal">get_hits</code>.
        If, however, you have a large number of cache misses compared to
        cache hits after an extended period of execution, it may be an
        indication that the size of the cache is too small and you
        either need to increase the total memory size, or increase the
        number of the <span><strong class="command">memcached</strong></span> instances to improve
        the hit ratio.
      </p><p>
        A large number of <code class="literal">evictions</code> from the cache,
        particularly in comparison to the number of items stored is a
        sign that your cache is too small to hold the amount of
        information that you regularly want to keep cached. Instead of
        items being retained in the cache, items are being evicted to
        make way for new items keeping the turnover of items in the
        cache high, reducing the efficiency of the cache.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-stats-slabs"></a>14.5.4.2. <span><strong class="command">memcached</strong></span> Slabs Statistics</h4></div></div></div><p>
        To get the <code class="literal">slabs</code> statistics, use the
        <code class="literal">stats slabs</code> command, or the API equivalent.
      </p><p>
        The slab statistics provide you with information about the slabs
        that have created and allocated for storing information within
        the cache. You get information both on each individual
        slab-class and total statistics for the whole slab.
      </p><pre class="programlisting">STAT 1:chunk_size 104
STAT 1:chunks_per_page 10082
STAT 1:total_pages 1
STAT 1:total_chunks 10082
STAT 1:used_chunks 10081
STAT 1:free_chunks 1
STAT 1:free_chunks_end 10079
STAT 9:chunk_size 696
STAT 9:chunks_per_page 1506
STAT 9:total_pages 63
STAT 9:total_chunks 94878
STAT 9:used_chunks 94878
STAT 9:free_chunks 0
STAT 9:free_chunks_end 0
STAT active_slabs 2
STAT total_malloced 67083616
END
</pre><p>
        Individual stats for each slab class are prefixed with the slab
        ID. A unique ID is given to each allocated slab from the
        smallest size up to the largest. The prefix number indicates the
        slab class number in relation to the calculated chunk from the
        specified growth factor. Hence in the example, 1 is the first
        chunk size and 9 is the 9th chunk allocated size.
      </p><p>
        The different parameters returned for each chunk size and the
        totals are shown in the following table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Statistic</th><th>Description</th></tr></thead><tbody><tr><td>chunk_size</td><td>Space allocated to each chunk within this slab class.</td></tr><tr><td>chunks_per_page</td><td>Number of chunks within a single page for this slab class.</td></tr><tr><td>total_pages</td><td>Number of pages allocated to this slab class.</td></tr><tr><td>total_chunks</td><td>Number of chunks allocated to the slab class.</td></tr><tr><td>used_chunks</td><td>Number of chunks allocated to an item..</td></tr><tr><td>free_chunks</td><td>Number of chunks not yet allocated to items.</td></tr><tr><td>free_chunks_end</td><td>Number of free chunks at the end of the last allocated page.</td></tr><tr><td>active_slabs</td><td>Total number of slab classes allocated.</td></tr><tr><td>total_malloced</td><td>Total amount of memory allocated to slab pages.</td></tr></tbody></table></div><p>
        The key values in the slab statistics are the
        <code class="literal">chunk_size</code>, and the corresponding
        <code class="literal">total_chunks</code> and
        <code class="literal">used_chunks</code> parameters. These given an
        indication of the size usage of the chunks within the system.
        Remember that one key/value pair will be placed into a chunk of
        a suitable size.
      </p><p>
        From these stats you can get an idea of your size and chunk
        allocation and distribution. If you are storing many items with
        a number of largely different sizes, then you may want to adjust
        the chunk size growth factor to increase in larger steps to
        prevent chunk and memory wastage. A good indication of a bad
        growth factor is a high number of different slab classes, but
        with relatively few chunks actually in use within each slab.
        Increasing the growth factor will create fewer slab classes and
        therefore make better use of the allocated pages.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-stats-items"></a>14.5.4.3. <span><strong class="command">memcached</strong></span> Item Statistics</h4></div></div></div><p>
        To get the <code class="literal">items</code> statistics, use the
        <code class="literal">stats items</code> command, or the API equivalent.
      </p><p>
        The <code class="literal">items</code> statistics give information about
        the individual items allocated within a given slab class.
      </p><pre class="programlisting">STAT items:2:number 1
STAT items:2:age 452
STAT items:2:evicted 0
STAT items:2:outofmemory 0
STAT items:27:number 1
STAT items:27:age 452
STAT items:27:evicted 0
STAT items:27:outofmemory 0
</pre><p>
        The prefix number against each statistics relates to the
        corresponding chunk size, as returned by the <code class="literal">stats
        slabs</code> statistics. The result is a display of the
        number of items stored within each chunk within each slab size,
        and specific statistics about their age, eviction counts, and
        out of memory counts. A summary of the statistics is given in
        the following table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Statistic</th><th>Description</th></tr></thead><tbody><tr><td>number</td><td>The number of items currently stored in this slab class.</td></tr><tr><td>age</td><td>The age of the oldest item within the slab class, in seconds.</td></tr><tr><td>evicted</td><td>The number of items evicted to make way for new entries.</td></tr><tr><td>outofmemory</td><td>The number of items for this slab class that have triggered an out of
                memory error (only value when the <code class="literal">-M</code>
                command line option is in effect).</td></tr></tbody></table></div><p>
        Item level statistics can be used to determine how many items
        are stored within a given slab and their freshness and recycle
        rate. You can use this to help identify whether there are
        certain slab classes that are triggering a much larger number of
        evictions that others.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-stats-sizes"></a>14.5.4.4. <span><strong class="command">memcached</strong></span> Size Statistics</h4></div></div></div><p>
        To get size statistics, use the <code class="literal">stats sizes</code>
        command, or the API equivalent.
      </p><p>
        The size statistics provide information about the sizes and
        number of items of each size within the cache. The information
        is returned as two columns, the first column is the size of the
        item (rounded up to the nearest 32 byte boundary), and the
        second column is the count of the number of items of that size
        within the cache:
      </p><pre class="programlisting">96 35
128 38
160 807
192 804
224 410
256 222
288 83
320 39
352 53
384 33
416 64
448 51
480 30
512 54
544 39
576 10065</pre><div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Caution</h3><p>
          Running this statistic will lock up your cache as each item is
          read from the cache and its size calculated. On a large cache,
          this may take some time and prevent any set or get operations
          until the process completes.
        </p></div><p>
        The item size statistics are useful only to determine the sizes
        of the objects you are storing. Since the actual memory
        allocation is relevant only in terms of the chunk size and page
        size, the information will only be useful during a careful
        debugging or diagnostic session.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="ha-memcached-stats-detail"></a>14.5.4.5. <code class="literal">memcached</code> Detail Statistics</h4></div></div></div><p>
        For <span><strong class="command">memcached</strong></span> 1.3.x and higher, you can
        enable and obtain detailed statistics about the get, set, and
        del operations on theindividual keys stored in the cache, and
        determine whether the attempts hit (found) a particular key.
        These operations are only recorded while the detailed stats
        analysis is turned on.
      </p><p>
        To enable detailed statistics, you must send the <code class="literal">stats
        detail on</code> command to the <span><strong class="command">memcached</strong></span>
        server:
      </p><pre class="programlisting">$ telnet localhost 11211
Trying 127.0.0.1...
Connected to tiger.
Escape character is '^]'.
<strong class="userinput"><code>stats detail on</code></strong>
OK
</pre><p>
        Individual statistics will be recorded for every
        <code class="literal">get</code>, <code class="literal">set</code> and
        <code class="literal">del</code> operation on a key, including keys that
        are not currently stored in the server. For example, if an
        attempt is made to obtain the value of key
        <code class="literal">abckey</code> and it does not exist, the
        <code class="literal">get</code> operating on the specified key will be
        recorded while detailed statistics are in effect, even if the
        key is not currently stored. The <code class="literal">hits</code>, that
        is, the number of <code class="literal">get</code> or
        <code class="literal">del</code> operations for a key that exists in the
        server are also counted.
      </p><p>
        To turn detailed statistics off, send the <code class="literal">stats detail
        off</code> command to the <span><strong class="command">memcached</strong></span>
        server:
      </p><pre class="programlisting">$ telnet localhost 11211
Trying 127.0.0.1...
Connected to tiger.
Escape character is '^]'.
<strong class="userinput"><code>stats detail on</code></strong>
OK
</pre><p>
        To obtain the detailed statistics recorded during the process,
        send the <code class="literal">stats detail dump</code> command to the
        <span><strong class="command">memcached</strong></span> server:
      </p><pre class="programlisting">stats detail dump
PREFIX hykkey get 0 hit 0 set 1 del 0
PREFIX xyzkey get 0 hit 0 set 1 del 0
PREFIX yukkey get 1 hit 0 set 0 del 0
PREFIX abckey get 3 hit 3 set 1 del 0
END
</pre><p>
        You can use the detailed statistics information to determine
        whether your <span><strong class="command">memcached</strong></span> clients are using a
        large number of keys that do not exist in the server by
        comparing the <code class="literal">hit</code> and <code class="literal">get</code>
        or <code class="literal">del</code> counts. Because the information is
        recorded by key, you can also determine whether the failures or
        operations are clustered around specific keys.
      </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="ha-memcached-faq"></a>14.5.5. <span><strong class="command">memcached</strong></span> FAQ</h3></div></div></div><p><span class="bold"><strong>Questions</strong></span></p><div class="itemizedlist"><ul type="disc"><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-1">14.5.5.1: </a>
        How does an event such as a crash of one of the
        <span><strong class="command">memcached</strong></span> servers handled by the
        <span><strong class="command">memcached</strong></span> client?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-2">14.5.5.2: </a>
        What's a recommended hardware config for a memcached server?
        Linux or Windows?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-3">14.5.5.3: </a>
        <span><strong class="command">memcached</strong></span> is fast - is there any overhead in
        not using persistent connections? If persistent is always
        recommended, what are the downsides (for example, locking up)?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-4">14.5.5.4: </a>
        How expensive is it to establish a memcache connection? Should
        those connections be pooled?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-5">14.5.5.5: </a>
        How will the data will be handled when the
        <span><strong class="command">memcached</strong></span> server is down?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-6">14.5.5.6: </a>
        Can memcached be run on a Windows environment?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-7">14.5.5.7: </a>
        What is the max size of an object you can store in memcache and
        is that configurable?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-8">14.5.5.8: </a>
        What are best practices for testing an implementation, to ensure
        that it is an improvement over the MySQL query cache, and to
        measure the impact of <span><strong class="command">memcached</strong></span> configuration
        changes? And would you recommend keeping the configuration very
        simple to start?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-9">14.5.5.9: </a>
        Can MySQL actually trigger/store the changed data to memcached?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-10">14.5.5.10: </a>
        So the responsibility lies with the application to populate and
        get records from the database as opposed to being a transparent
        cache layer for the db?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-11">14.5.5.11: </a>
        Is compression available?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-12">14.5.5.12: </a>
        File socket support for <span><strong class="command">memcached</strong></span> from the
        localhost use to the local memcached server?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-13">14.5.5.13: </a>
        Are there any, or are there any plans to introduce, a framework
        to hide the interaction of memcached from the application; that
        is, within hibernate?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-14">14.5.5.14: </a>
        What are the advantages of using UDFs when the get/sets are
        manageable from within the client code rather than the db?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-15">14.5.5.15: </a>
        Is <span><strong class="command">memcached</strong></span> typically a better solution for
        improving speed than MySQL Cluster and\or MySQL Proxy?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-16">14.5.5.16: </a>
        What speed trade offs is there between
        <span><strong class="command">memcached</strong></span> vs MySQL Query Cache? Where you
        check <span><strong class="command">memcached</strong></span>, and get data from MySQL and
        put it in <span><strong class="command">memcached</strong></span> or just make a query and
        results are put into MySQL Query Cache.
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-17">14.5.5.17: </a>
        Does the <code class="literal">-L</code> flag automatically sense how much
        memory is being used by other memcached?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-18">14.5.5.18: </a>
        Is the data inside of <code class="literal">memcached</code> secure?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-19">14.5.5.19: </a>
        Can we implement different types of <span><strong class="command">memcached</strong></span>
        as different nodes in the same server - so can there be
        deterministic and non deterministic in the same server?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-20">14.5.5.20: </a>
        How easy is it to introduce <code class="literal">memcached</code> to an
        existing enterprise application instead of inclusion at project
        design?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-21">14.5.5.21: </a>
        Can <span><strong class="command">memcached</strong></span> work with
        <code class="literal">ASPX</code>?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-22">14.5.5.22: </a>
        If I have an object larger then a MB, do I have to manually
        split it or can I configure <span><strong class="command">memcached</strong></span> to
        handle larger objects?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-23">14.5.5.23: </a>
        How does <span><strong class="command">memcached</strong></span> compare to nCache?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-24">14.5.5.24: </a>
        Doing a direct telnet to the memcached port, is that just for
        that one machine, or does it magically apply across all nodes?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-25">14.5.5.25: </a>
        Is memcached more effective for video and audio as opposed to
        textual read/writes
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-26">14.5.5.26: </a>
        We are caching XML by serialising using saveXML(), because PHP
        cannot serialise DOM objects; Some of the XML is variable and is
        modified per-request. Do you recommend caching then using XPath,
        or is it better to rebuild the DOM from separate node-groups?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-27">14.5.5.27: </a>
        Do the memcache UDFs work under 5.1?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-28">14.5.5.28: </a>
        Is it true <code class="literal">memcached</code> will be much more
        effective with db-read-intensive applications than with
        db-write-intensive applications?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-29">14.5.5.29: </a>
        How are auto-increment columns in the MySQL database coordinated
        across multiple instances of memcached?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-5-5-1-30">14.5.5.30: </a>
        If you log a complex class (with methods that do calculation
        etc) will the get from Memcache re-create the class on the way
        out?
      </p></li></ul></div><p><span class="bold"><strong>Questions and Answers</strong></span></p><p><a name="qandaitem-14-5-5-1-1"></a><span class="bold"><strong>14.5.5.1: </strong></span><span class="bold"><strong>
        How does an event such as a crash of one of the
        <span><strong class="command">memcached</strong></span> servers handled by the
        <span><strong class="command">memcached</strong></span> client?
      </strong></span></p><p>
        There is no automatic handling of this. If your client fails to
        get a response from a server then it should fall back to loading
        the data from the MySQL database.
      </p><p>
        The client APIs all provide the ability to add and remove
        <span><strong class="command">memcached</strong></span> instances on the fly. If within
        your application you notice that <span><strong class="command">memcached</strong></span>
        server is no longer responding, your can remove the server from
        the list of servers, and keys will automatically be
        redistributed to another <span><strong class="command">memcached</strong></span> server in
        the list. If retaining the cache content on all your servers is
        important, make sure you use an API that supports a consistent
        hashing algorithm. For more information, see
        <a href="ha-overview.html#ha-memcached-using-hashtypes" title="14.5.2.4. memcached Distribution Types">Section 14.5.2.4, “<span><strong class="command">memcached</strong></span> Distribution Types”</a>.
      </p><p><a name="qandaitem-14-5-5-1-2"></a><span class="bold"><strong>14.5.5.2: </strong></span><span class="bold"><strong>
        What's a recommended hardware config for a memcached server?
        Linux or Windows?
      </strong></span></p><p>
        <span><strong class="command">memcached</strong></span> is only available on Unix/Linux, so
        using a Windows machine is not an option. Outside of this,
        <span><strong class="command">memcached</strong></span> has a very low processing overhead.
        All that is required is spare physical RAM capacity. The point
        is not that you should necessarily deploy a dedicated
        <span><strong class="command">memcached</strong></span> server. If you have web,
        application, or database servers that have spare RAM capacity,
        then use them with <span><strong class="command">memcached</strong></span>.
      </p><p>
        If you want to build and deploy a dedicated
        <span><strong class="command">memcached</strong></span> servers, then you use a relatively
        low-power CPU, lots of RAM and one or more Gigabit Ethernet
        interfaces.
      </p><p><a name="qandaitem-14-5-5-1-3"></a><span class="bold"><strong>14.5.5.3: </strong></span><span class="bold"><strong>
        <span><strong class="command">memcached</strong></span> is fast - is there any overhead in
        not using persistent connections? If persistent is always
        recommended, what are the downsides (for example, locking up)?
      </strong></span></p><p>
        If you don't use persistent connections when communicating with
        <span><strong class="command">memcached</strong></span> then there will be a small increase
        in the latency of opening the connection each time. The effect
        is comparable to use nonpersistent connections with MySQL.
      </p><p>
        In general, the chance of locking or other issues with
        persistent connections is minimal, because there is very little
        locking within <span><strong class="command">memcached</strong></span>. If there is a
        problem then eventually your request will timeout and return no
        result so your application will need to load from MySQL again.
      </p><p><a name="qandaitem-14-5-5-1-4"></a><span class="bold"><strong>14.5.5.4: </strong></span><span class="bold"><strong>
        How expensive is it to establish a memcache connection? Should
        those connections be pooled?
      </strong></span></p><p>
        Opening the connection is relatively inexpensive, because there
        is no security, authentication or other handshake taking place
        before you can start sending requests and getting results. Most
        APIs support a persistent connection to a
        <span><strong class="command">memcached</strong></span> instance to reduce the latency.
        Connection pooling would depend on the API you are using, but if
        you are communicating directly over TCP/IP, then connection
        pooling would provide some small performance benefit.
      </p><p><a name="qandaitem-14-5-5-1-5"></a><span class="bold"><strong>14.5.5.5: </strong></span><span class="bold"><strong>
        How will the data will be handled when the
        <span><strong class="command">memcached</strong></span> server is down?
      </strong></span></p><p>
        The behavior is entirely application dependent. Most
        applications will fall back to loading the data from the
        database (just as if they were updating the
        <span><strong class="command">memcached</strong></span>) information. If you are using
        multiple <span><strong class="command">memcached</strong></span> servers, you may also want
        to remove a server from the list to prevent the missing server
        affecting performance. This is because the client will still
        attempt to communicate the <span><strong class="command">memcached</strong></span> that
        corresponds to the key you are trying to load.
      </p><p><a name="qandaitem-14-5-5-1-6"></a><span class="bold"><strong>14.5.5.6: </strong></span><span class="bold"><strong>
        Can memcached be run on a Windows environment?
      </strong></span></p><p>
        No. Currently <span><strong class="command">memcached</strong></span> is available only on
        the Unix/Linux platform. There is an unofficial port available,
        see <a href="http://www.codeplex.com/memcachedproviders" target="_top">http://www.codeplex.com/memcachedproviders</a>.
      </p><p><a name="qandaitem-14-5-5-1-7"></a><span class="bold"><strong>14.5.5.7: </strong></span><span class="bold"><strong>
        What is the max size of an object you can store in memcache and
        is that configurable?
      </strong></span></p><p>
        The default maximum object size is 1MB. If you want to increase
        this size, you have to re-compile <span><strong class="command">memcached</strong></span>.
        You can modify the value of the <code class="literal">POWER_BLOCK</code>
        within the <code class="filename">slabs.c</code> file within the source.
      </p><p><a name="qandaitem-14-5-5-1-8"></a><span class="bold"><strong>14.5.5.8: </strong></span><span class="bold"><strong>
        What are best practices for testing an implementation, to ensure
        that it is an improvement over the MySQL query cache, and to
        measure the impact of <span><strong class="command">memcached</strong></span> configuration
        changes? And would you recommend keeping the configuration very
        simple to start?
      </strong></span></p><p>
        The best way to test the performance is to start up a
        <span><strong class="command">memcached</strong></span> instance. First, modify your
        application so that it stores the data just before the data is
        about to be used or displayed into
        <span><strong class="command">memcached</strong></span>.Since the APIs handle the
        serialization of the data, it should just be a one line
        modification to your code. Then, modify the start of the process
        that would normally load that information from MySQL with the
        code that requests the data from <span><strong class="command">memcached</strong></span>.
        If the data cannot be loaded from <span><strong class="command">memcached</strong></span>,
        default to the MySQL process.
      </p><p>
        All of the changes required will probably amount to just a few
        lines of code. To get the best benefit, make sure you cache
        entire objects (for example, all the components of a web page,
        blog post, discussion thread, etc.), rather than using
        <span><strong class="command">memcached</strong></span> as a simple cache of individuals
        rows of MySQL tables. You should see performance benefits almost
        immediately.
      </p><p>
        Keeping the configuration very simple at the start, or even over
        the long term, is very easy with <span><strong class="command">memcached</strong></span>.
        Once you have the basic structure up and running, the only
        addition you may want to make is to add more servers into the
        list of servers used by your clients. You don't need to manage
        the <span><strong class="command">memcached</strong></span> servers, and there is no
        complex configuration, just add more servers to the list and let
        the client API and the <span><strong class="command">memcached</strong></span> servers make
        the decisions.
      </p><p><a name="qandaitem-14-5-5-1-9"></a><span class="bold"><strong>14.5.5.9: </strong></span><span class="bold"><strong>
        Can MySQL actually trigger/store the changed data to memcached?
      </strong></span></p><p>
        Yes. You can use the MySQL UDFs for <span><strong class="command">memcached</strong></span>
        and either write statements that directly set the values in the
        <span><strong class="command">memcached</strong></span> server, or use triggers or stored
        procedures to do it for you. For more information, see
        <a href="ha-overview.html#ha-memcached-interfaces-mysqludf" title="14.5.3.7. Using the MySQL memcached UDFs">Section 14.5.3.7, “Using the MySQL <span><strong class="command">memcached</strong></span> UDFs”</a>
      </p><p><a name="qandaitem-14-5-5-1-10"></a><span class="bold"><strong>14.5.5.10: </strong></span><span class="bold"><strong>
        So the responsibility lies with the application to populate and
        get records from the database as opposed to being a transparent
        cache layer for the db?
      </strong></span></p><p>
        Yes. You load the data from the database and write it into the
        cache provided by <span><strong class="command">memcached</strong></span>. Using
        <span><strong class="command">memcached</strong></span> as a simple database row cache,
        however, is probably inefficient. The best way to use
        <span><strong class="command">memcached</strong></span> is to load all of the information
        from the database relating to a particular object, and then
        cache the entire object. For example, in a blogging environment,
        you might load the blog, associated comments, categories and so
        on, and then cache all of the information relating to that blog
        post. The reading of the data from the database will require
        multiple SQL statements and probably multiple rows of data to
        complete, which is time consuming. Loading the entire blog post
        and the associated information from <span><strong class="command">memcached</strong></span>
        is just one operation and doesn't involve using the disk or
        parsing the SQL statement.
      </p><p><a name="qandaitem-14-5-5-1-11"></a><span class="bold"><strong>14.5.5.11: </strong></span><span class="bold"><strong>
        Is compression available?
      </strong></span></p><p>
        Yes. Most of the client APIs support some sort of compression,
        and some even allow you to specify the threshold at which a
        value is deemed appropriate for compression during storage.
      </p><p><a name="qandaitem-14-5-5-1-12"></a><span class="bold"><strong>14.5.5.12: </strong></span><span class="bold"><strong>
        File socket support for <span><strong class="command">memcached</strong></span> from the
        localhost use to the local memcached server?
      </strong></span></p><p>
        You can use the <code class="literal">-s</code> option to
        <span><strong class="command">memcached</strong></span> to specify the location of a file
        socket. This automatically disables network support.
      </p><p><a name="qandaitem-14-5-5-1-13"></a><span class="bold"><strong>14.5.5.13: </strong></span><span class="bold"><strong>
        Are there any, or are there any plans to introduce, a framework
        to hide the interaction of memcached from the application; that
        is, within hibernate?
      </strong></span></p><p>
        There are lots of projects working with
        <span><strong class="command">memcached</strong></span>. There is a Google Code
        implementation of Hibernate and <span><strong class="command">memcached</strong></span>
        working together. See
        <a href="http://code.google.com/p/hibernate-memcached/" target="_top">http://code.google.com/p/hibernate-memcached/</a>.
      </p><p><a name="qandaitem-14-5-5-1-14"></a><span class="bold"><strong>14.5.5.14: </strong></span><span class="bold"><strong>
        What are the advantages of using UDFs when the get/sets are
        manageable from within the client code rather than the db?
      </strong></span></p><p>
        Sometimes you want to be able to be able to update the
        information within <span><strong class="command">memcached</strong></span> based on a
        generic database activity, rather than relying on your client
        code. For example, you may want to update status or counter
        information in <span><strong class="command">memcached</strong></span> through the use of a
        trigger or stored procedure. For some situations and
        applications the existing use of a stored procedure for some
        operations means that updating the value in
        <span><strong class="command">memcached</strong></span> from the database is easier than
        separately loading and communicating that data to the client
        just so the client can talk to <span><strong class="command">memcached.</strong></span>
      </p><p>
        In other situations, when you are using a number of different
        clients and different APIs, you don't want to have to write (and
        maintain) the code required to update
        <span><strong class="command">memcached</strong></span> in all the environments. Instead,
        you do this from within the database and the client never gets
        involved.
      </p><p><a name="qandaitem-14-5-5-1-15"></a><span class="bold"><strong>14.5.5.15: </strong></span><span class="bold"><strong>
        Is <span><strong class="command">memcached</strong></span> typically a better solution for
        improving speed than MySQL Cluster and\or MySQL Proxy?
      </strong></span></p><p>
        Both MySQL Cluster and MySQL Proxy still require access to the
        underlying database to retrieve the information. This implies
        both a parsing overhead for the statement and, often, disk based
        access to retrieve the data you have selected.
      </p><p>
        The advantage of <span><strong class="command">memcached</strong></span> is that you can
        store entire objects or groups of information that may require
        multiple SQL statements to obtain. Restoring the result of 20
        SQL statements formatted into a structure that your application
        can use directly without requiring any additional processing is
        always going to be faster than building that structure by
        loading the rows from a database.
      </p><p><a name="qandaitem-14-5-5-1-16"></a><span class="bold"><strong>14.5.5.16: </strong></span><span class="bold"><strong>
        What speed trade offs is there between
        <span><strong class="command">memcached</strong></span> vs MySQL Query Cache? Where you
        check <span><strong class="command">memcached</strong></span>, and get data from MySQL and
        put it in <span><strong class="command">memcached</strong></span> or just make a query and
        results are put into MySQL Query Cache.
      </strong></span></p><p>
        In general, the time difference between getting data from the
        MySQL Query Cache and getting the exact same data from
        <span><strong class="command">memcached</strong></span> is very small.
      </p><p>
        However, the benefit of <span><strong class="command">memcached</strong></span> is that you
        can store any information, including the formatted and processed
        results of many queries into a single
        <span><strong class="command">memcached</strong></span> key. Even if all the queries that
        you executed could be retrieved from the Query Cache without
        having to go to disk, you would still be running multiple
        queries (with network and other overhead) compared to just one
        for the <span><strong class="command">memcached</strong></span> equivalent. If your
        application uses objects, or does any kind of processing on the
        information, with <span><strong class="command">memcached</strong></span> you can store the
        post-processed version, so the data you load is immediately
        available to be used. With data loaded from the Query Cache, you
        would still have to do that processing.
      </p><p>
        In addition to these considerations, keep in mind that keeping
        data in the MySQL Query Cache is difficult as you have no
        control over the queries that are stored. This means that a
        slightly unusual query can temporarily clear a frequently used
        (and normally cached) query, reducing the effectiveness of your
        Query Cache. With <span><strong class="command">memcached</strong></span> you can specify
        which objects are stored, when they are stored, and when they
        should be deleted giving you much more control over the
        information stored in the cache.
      </p><p><a name="qandaitem-14-5-5-1-17"></a><span class="bold"><strong>14.5.5.17: </strong></span><span class="bold"><strong>
        Does the <code class="literal">-L</code> flag automatically sense how much
        memory is being used by other memcached?
      </strong></span></p><p>
        No. There is no communication or sharing of information between
        <span><strong class="command">memcached</strong></span> instances.
      </p><p><a name="qandaitem-14-5-5-1-18"></a><span class="bold"><strong>14.5.5.18: </strong></span><span class="bold"><strong>
        Is the data inside of <code class="literal">memcached</code> secure?
      </strong></span></p><p>
        No, there is no security required to access or update the
        information within a <span><strong class="command">memcached</strong></span> instance,
        which means that anybody with access to the machine has the
        ability to read, view and potentially update the information. If
        you want to keep the data secure, you can encrypt and decrypt
        the information before storing it. If you want to restrict the
        users capable of connecting to the server, your only choice is
        to either disable network access, or use IPTables or similar to
        restrict access to the <span><strong class="command">memcached</strong></span> ports to a
        select set of hosts.
      </p><p><a name="qandaitem-14-5-5-1-19"></a><span class="bold"><strong>14.5.5.19: </strong></span><span class="bold"><strong>
        Can we implement different types of <span><strong class="command">memcached</strong></span>
        as different nodes in the same server - so can there be
        deterministic and non deterministic in the same server?
      </strong></span></p><p>
        Yes. You can run multiple instances of
        <span><strong class="command">memcached</strong></span> on a single server, and in your
        client configuration you choose the list of servers you want to
        use.
      </p><p><a name="qandaitem-14-5-5-1-20"></a><span class="bold"><strong>14.5.5.20: </strong></span><span class="bold"><strong>
        How easy is it to introduce <code class="literal">memcached</code> to an
        existing enterprise application instead of inclusion at project
        design?
      </strong></span></p><p>
        In general, it is very easy. In many languages and environments
        the changes to the application will be just a few lines, first
        to attempt to read from the cache when loading data and then
        fall back to the old method, and to update the cache with
        information once the data has been read.
      </p><p>
        <span><strong class="command">memcached</strong></span> is designed to be deployed very
        easily, and you shouldn't require significant architectural
        changes to your application to use <span><strong class="command">memcached</strong></span>.
      </p><p><a name="qandaitem-14-5-5-1-21"></a><span class="bold"><strong>14.5.5.21: </strong></span><span class="bold"><strong>
        Can <span><strong class="command">memcached</strong></span> work with
        <code class="literal">ASPX</code>?
      </strong></span></p><p>
        There are ports and interfaces for many languages and
        environments. ASPX relies on an underlying language such as C#
        or VisualBasic, and if you are using ASP.NET then there is a C#
        <span><strong class="command">memcached</strong></span> library. For more information, see
        <a href="https://sourceforge.net/projects/memcacheddotnet/" target="_top">.</a>
      </p><p><a name="qandaitem-14-5-5-1-22"></a><span class="bold"><strong>14.5.5.22: </strong></span><span class="bold"><strong>
        If I have an object larger then a MB, do I have to manually
        split it or can I configure <span><strong class="command">memcached</strong></span> to
        handle larger objects?
      </strong></span></p><p>
        You would have to manually split it.
        <span><strong class="command">memcached</strong></span> is very simple, you give it a key
        and some data, it tries to cache it in RAM. If you try to store
        more than the default maximum size, the value is just truncated
        for speed reasons.
      </p><p><a name="qandaitem-14-5-5-1-23"></a><span class="bold"><strong>14.5.5.23: </strong></span><span class="bold"><strong>
        How does <span><strong class="command">memcached</strong></span> compare to nCache?
      </strong></span></p><p>
        The main benefit of <span><strong class="command">memcached</strong></span> is that is very
        easy to deploy and works with a wide range of languages and
        environments, including .NET, Java, Perl, Python, PHP, even
        MySQL. <span><strong class="command">memcached</strong></span> is also very lightweight in
        terms of systems and requirements, and you can easily add as
        many or as few <span><strong class="command">memcached</strong></span> servers as you need
        without changing the individual configuration.
        <span><strong class="command">memcached</strong></span> does require additional
        modifications to the application to take advantage of
        functionality such as multiple <span><strong class="command">memcached</strong></span>
        servers.
      </p><p><a name="qandaitem-14-5-5-1-24"></a><span class="bold"><strong>14.5.5.24: </strong></span><span class="bold"><strong>
        Doing a direct telnet to the memcached port, is that just for
        that one machine, or does it magically apply across all nodes?
      </strong></span></p><p>
        Just one. There is no communication between different instances
        of <span><strong class="command">memcached</strong></span>, even if each instance is
        running on the same machine.
      </p><p><a name="qandaitem-14-5-5-1-25"></a><span class="bold"><strong>14.5.5.25: </strong></span><span class="bold"><strong>
        Is memcached more effective for video and audio as opposed to
        textual read/writes
      </strong></span></p><p>
        <span><strong class="command">memcached</strong></span> doesn't care what information you
        are storing. To <span><strong class="command">memcached</strong></span>, any value you
        store is just a stream of data. Remember, though, that the
        maximum size of an object you can store in
        <span><strong class="command">memcached</strong></span> without modifying the source code
        is 1MB, so it's usability with audio and video content is
        probably significantly reduced. Also remember that
        <span><strong class="command">memcached</strong></span> is a solution for caching
        information for reading. It shouldn't be used for writes, except
        when updating the information in the cache.
      </p><p><a name="qandaitem-14-5-5-1-26"></a><span class="bold"><strong>14.5.5.26: </strong></span><span class="bold"><strong>
        We are caching XML by serialising using saveXML(), because PHP
        cannot serialise DOM objects; Some of the XML is variable and is
        modified per-request. Do you recommend caching then using XPath,
        or is it better to rebuild the DOM from separate node-groups?
      </strong></span></p><p>
        You would need to test your application using the different
        methods to determine this information. You may find that the
        default serialization within PHP may allow you to store DOM
        objects directly into the cache.
      </p><p><a name="qandaitem-14-5-5-1-27"></a><span class="bold"><strong>14.5.5.27: </strong></span><span class="bold"><strong>
        Do the memcache UDFs work under 5.1?
      </strong></span></p><p>
        Yes.
      </p><p><a name="qandaitem-14-5-5-1-28"></a><span class="bold"><strong>14.5.5.28: </strong></span><span class="bold"><strong>
        Is it true <code class="literal">memcached</code> will be much more
        effective with db-read-intensive applications than with
        db-write-intensive applications?
      </strong></span></p><p>
        Yes. <span><strong class="command">memcached</strong></span> plays no role in database
        writes, it is a method of caching data already read from the
        database in RAM.
      </p><p><a name="qandaitem-14-5-5-1-29"></a><span class="bold"><strong>14.5.5.29: </strong></span><span class="bold"><strong>
        How are auto-increment columns in the MySQL database coordinated
        across multiple instances of memcached?
      </strong></span></p><p>
        They aren't. There is no relationship between MySQL and
        <span><strong class="command">memcached</strong></span> unless your application (or, if you
        are using the MySQL UDFs for <span><strong class="command">memcached</strong></span>, your
        database definition) creates one.
      </p><p>
        If you are storing information based on an auto-increment key
        into multiple instances of <span><strong class="command">memcached</strong></span> then the
        information will only be stored on one of the
        <span><strong class="command">memcached</strong></span> instances anyway. The client uses
        the key value to determine which <span><strong class="command">memcached</strong></span>
        instance to store the information, it doesn't store the same
        information across all the instances, as that would be a waste
        of cache memory.
      </p><p><a name="qandaitem-14-5-5-1-30"></a><span class="bold"><strong>14.5.5.30: </strong></span><span class="bold"><strong>
        If you log a complex class (with methods that do calculation
        etc) will the get from Memcache re-create the class on the way
        out?
      </strong></span></p><p>
        In general, yes. If the serialization method within the
        API/language that you are using supports it, then methods and
        other information will be stored and retrieved.
      </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="mysql-proxy"></a>14.6. MySQL Proxy</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#mysql-proxy-platforms">14.6.1. MySQL Proxy Supported Platforms</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-install">14.6.2. Installing MySQL Proxy</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-cmdline">14.6.3. MySQL Proxy Command-Line Options</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting">14.6.4. MySQL Proxy Scripting</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-using">14.6.5. Using MySQL Proxy</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-faq">14.6.6. MySQL Proxy FAQ</a></span></dt></dl></div><p>
    The MySQL Proxy is an application that communicates over the network
    using the MySQL Network Protocol and provides communication between
    one or more MySQL servers and one or more MySQL clients. In the most
    basic configuration, MySQL Proxy simply passes on queries from the
    client to the MySQL Server and returns the responses from the MySQL
    Server to the client.
  </p><p>
    Because MySQL Proxy uses the MySQL network protocol, any MySQL
    compatible client (include the command line client, any clients
    using the MySQL client libraries, and any connector that supports
    the MySQL network protocol) can connect to the proxy without
    modification.
  </p><p>
    In addition to the basic pass-through configuration, the MySQL Proxy
    is also capable of monitoring and altering the communication between
    the client and the server. This interception of the queries enables
    you to add profiling, and the interception of the exchanges is
    scriptable using the Lua scripting language.
  </p><p>
    By intercepting the queries from the client, the proxy can insert
    additional queries into the list of queries sent to the server, and
    remove the additional results when they are returned by the server.
    Using this functionality you can add informational statements to
    each query, for example to monitor their execution time or progress,
    and separately log the results, while still returning the results
    from the original query to the client.
  </p><p>
    The proxy allows you to perform additional monitoring, filtering or
    manipulation on queries without you having to make any modifications
    to the client and without the client even being aware that it is
    communicating with anything but a genuine MySQL server.
  </p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>
      MySQL Proxy is currently an Alpha release and should not be used
      within production environments.
    </p></div><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3><p>
      MySQL Proxy is compatible with MySQL 5.0.x or later. Testing has
      not been performed with Version 4.1. Please provide feedback on
      your experiences via the
      <a href="http://forums.mysql.com/list.php?146" target="_top">MySQL Proxy Forum</a>.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="mysql-proxy-platforms"></a>14.6.1. MySQL Proxy Supported Platforms</h3></div></div></div><p>
      MySQL Proxy is currently available as a pre-compiled binary for
      the following platforms:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          Linux (including RedHat, Fedora, Debian, SuSE) and
          derivatives.
        </p></li><li><p>
          Mac OS X
        </p></li><li><p>
          FreeBSD
        </p></li><li><p>
          IBM AIX
        </p></li><li><p>
          Sun Solaris
        </p></li><li><p>
          Microsoft Windows (including Microsoft Windows XP, and
          Microsoft Windows Server 2003)
        </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>You must have the .NET Framework 1.1 or higher installed. </p></div></li></ul></div><p>
      Other Unix/Linux platforms not listed should be compatible by
      using the source package and building MySQL Proxy locally.
    </p><p>
      System requirements for the MySQL Proxy application are the same
      as the main MySQL server. Currently MySQL Proxy is compatible only
      with MySQL 5.0.1 and later. MySQL Proxy is provided as a
      standalone, statically linked binary. You do not need to have
      MySQL or Lua installed.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="mysql-proxy-install"></a>14.6.2. Installing MySQL Proxy</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#mysql-proxy-install-binary">14.6.2.1. Installing MySQL Proxy from a binary distribution</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-install-source">14.6.2.2. Installing MySQL Proxy from a source distribution</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-install-cvs">14.6.2.3. Installing MySQL Proxy from the Bazaar repository</a></span></dt></dl></div><p>
      You have three choices for installing MySQL Proxy:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          Pre-compiled binaries are available for a number of different
          platforms. See <a href="ha-overview.html#mysql-proxy-install-binary" title="14.6.2.1. Installing MySQL Proxy from a binary distribution">Section 14.6.2.1, “Installing MySQL Proxy from a binary distribution”</a>.
        </p></li><li><p>
          You can install from the source code if you want to build on
          an environment not supported by the binary distributions. See
          <a href="ha-overview.html#mysql-proxy-install-source" title="14.6.2.2. Installing MySQL Proxy from a source distribution">Section 14.6.2.2, “Installing MySQL Proxy from a source distribution”</a>.
        </p></li><li><p>
          The latest version of the MySQL proxy source code is available
          through a development repository is the best way to stay up to
          date with the latest fixes and revisions. See
          <a href="ha-overview.html#mysql-proxy-install-cvs" title="14.6.2.3. Installing MySQL Proxy from the Bazaar repository">Section 14.6.2.3, “Installing MySQL Proxy from the Bazaar repository”</a>.
        </p></li></ul></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-install-binary"></a>14.6.2.1. Installing MySQL Proxy from a binary distribution</h4></div></div></div><p>
        If you download the binary packages then you need only to
        extract the package and then copy the
        <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a> file to your desired location.
        For example:
      </p><pre class="programlisting">shell&gt; tar zxf <em class="replaceable"><code>mysql-proxy-0.5.0.tar.gz</code></em>
shell&gt; cp ./mysql-proxy-0.5.0/sbin/mysql-proxy /usr/local/sbin</pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-install-source"></a>14.6.2.2. Installing MySQL Proxy from a source distribution</h4></div></div></div><p>
        If you have downloaded the source package then you will need to
        compile the MySQL Proxy before using it. To build you will need
        to have the following installed:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            libevent 1.x or higher (1.3b or later is preferred)
          </p></li><li><p>
            lua 5.1.x or higher
          </p></li><li><p>
            glib2 2.6.0 or higher
          </p></li><li><p>
            pkg-config
          </p></li><li><p>
            libtool 1.5 or higher
          </p></li><li><p>
            MySQL 5.0.x or higher developer files
          </p></li></ul></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
          On some operating systems you may need to manually build the
          required components to get the latest version. If you are
          having trouble compiling MySQL Proxy then consider using one
          of the binary distributions.
        </p></div><p>
        Once these components are installed, you need to configure and
        then build:
      </p><pre class="programlisting">shell&gt; tar zxf <em class="replaceable"><code>mysql-proxy-0.5.0.tar.gz</code></em>
shell&gt; cd mysql-proxy-0.5.0
shell&gt; ./configure
shell&gt; make</pre><p>
        If you want to test the build, then use the
        <code class="literal">check</code> target to <span><strong class="command">make</strong></span>:
      </p><pre class="programlisting">shell&gt; make check</pre><p>
        The tests try to connect to <code class="literal">localhost</code> using
        the <code class="literal">root</code> user. If you need to provide a
        password, set the <code class="literal">MYSQL_PASSWORD</code> environment
        variable:
      </p><pre class="programlisting">shell&gt; MYSQL_PASSWORD=root_pwd make check</pre><p>
        You can install using the <code class="literal">install</code> target:
      </p><pre class="programlisting">shell&gt; make install</pre><p>
        By default <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a> is installed into
        <code class="filename">/usr/local/sbin/mysql-proxy</code>. The Lua
        example scripts are copied into
        <code class="filename">/usr/local/share</code>.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-install-cvs"></a>14.6.2.3. Installing MySQL Proxy from the Bazaar repository</h4></div></div></div><p>
        The MySQL Proxy source is available through a public Bazaar
        repository and is the quickest way to get hold of the latest
        releases and fixes.
      </p><p>
        To build from the Bazaar repository, you need the following
        components already installed:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            Bazaar 1.10.0 or later
          </p></li><li><p>
            <code class="literal">libtool</code> 1.5 or higher
          </p></li><li><p>
            <code class="literal">autoconf</code> 2.56 or higher
          </p></li><li><p>
            <code class="literal">automake</code> 1.9 or higher
          </p></li><li><p>
            <code class="literal">libevent</code> 1.x or higher (1.3b or later is
            preferred)
          </p></li><li><p>
            <code class="literal">lua</code> 5.1.x or higher
          </p></li><li><p>
            <code class="literal">glib2</code> 2.4.0 or higher
          </p></li><li><p>
            <code class="literal">pkg-config</code>
          </p></li><li><p>
            <code class="literal">MySQL</code> 5.0.x or higher developer files
          </p></li></ul></div><p>
        The <code class="literal">mysql-proxy</code> source is hosted on
        Launchpad. To checkout a local copy of the Bazaar repository,
        use <span><strong class="command">bzr</strong></span>:
      </p><pre class="programlisting">shell&gt; bzr branch lp:mysql-proxy</pre><p>
        The above command will download a complete version of the Bazaar
        repository for <code class="literal">mysql-proxy</code>. The main source
        files are located within the <code class="filename">trunk</code>
        subdirectory. The configuration scripts need to be generated
        before you can configure and build
        <code class="literal">mysql-proxy</code>. The
        <code class="filename">autogen.sh</code> script will generate the
        configuration scripts for you:
      </p><pre class="programlisting">shell&gt; sh ./autogen.sh</pre><p>
        The script creates the standard <span><strong class="command">configure</strong></span>
        script, which you can then use to configure and build with
        <span><strong class="command">make</strong></span>:
      </p><pre class="programlisting">shell&gt; ./configure
shell&gt; make
shell&gt; make install</pre><p>
        If you want to create a standalone source distribution,
        identical to the source distribution available for download:
      </p><pre class="programlisting">shell&gt; make distcheck</pre><p>
        The above will create the file
        <code class="filename">mysql-proxy-<em class="replaceable"><code>0.5.0</code></em>.tar.gz</code>
        within the current directory.
      </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="mysql-proxy-cmdline"></a>14.6.3. MySQL Proxy Command-Line Options</h3></div></div></div><p>
      To start <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a> you can just run the
      command directly. However, for most situations you will want to
      specify at the very least the address/host name and port number of
      the backend MySQL server to which the MySQL Proxy should pass on
      queries.
    </p><p>
      You can get a list of the supported command-line options using the
      <code class="literal">--help-all</code> command-line option. The majority of
      these options set up the environment, either in terms of the
      address/port number that <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a> should
      listen on for connections, or the onward connection to a MySQL
      server. A full description of the options is shown below:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          <code class="literal">--help-all</code> — show all help options.
        </p></li><li><p>
          <code class="literal">--help-admin </code> — show options for the
          admin-module.
        </p></li><li><p>
          <code class="literal">--help-proxy</code> — Show options for the
          proxy-module.
        </p></li><li><p>
          <code class="literal">--admin-address=host:port</code> — specify
          the host name (or IP address) and port for the administration
          port. The default is <code class="literal">localhost:4041</code>.
        </p></li><li><p>
          <code class="literal">--proxy-address=host:port</code> — the
          listening host name (or IP address) and port of the proxy
          server. The default is <code class="literal">localhost:4040</code>.
        </p></li><li><p>
          <code class="literal">--proxy-read-only-backend-address=host:port</code>
          — the listening host name (or IP address) and port of
          the proxy server for read-only connections. The default is for
          this information not to be set.
        </p></li><li><p>
          <code class="literal">--proxy-backend-addresses=host:port</code> —
          the host name (or IP address) and port of the MySQL server to
          connect to. You can specify multiple backend servers by
          supplying multiple options. Clients are connected to each
          backend server in round-robin fashion. For example, if you
          specify two servers A and B, the first client connection will
          go to server A; the second client connection to server B and
          the third client connection to server A.
        </p></li><li><p>
          <code class="literal">--proxy-skip-profiling </code> — disables
          profiling of queries (tracking time statistics). The default
          is for tracking to be enabled.
        </p></li><li><p>
          <code class="literal">--proxy-fix-bug-25371 </code> — gets round
          an issue when connecting to a MySQL server later than 5.1.12
          when using a MySQL client library of any earlier version.
        </p></li><li><p>
          <code class="literal">--proxy-lua-script=file </code> — specify
          the Lua script file to be loaded. Note that the script file is
          not physically loaded and parsed until a connection is made.
          Also note that the specified Lua script is reloaded for each
          connection; if the content of the Lua script changes while
          <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a> is running then the updated
          content will automatically be used when a new connection is
          made.
        </p></li><li><p>
          <code class="literal">--daemon</code> — starts the proxy in daemon
          mode.
        </p></li><li><p>
          <code class="literal">--pid-file=file</code> — sets the name of
          the file to be used to store the process ID.
        </p></li><li><p>
          <code class="literal">--version</code> — show the version number.
        </p></li></ul></div><p>
      The most common usage is as a simple proxy service (that is,
      without addition scripting). For basic proxy operation you must
      specify at least one <code class="literal">proxy-backend-addresses</code>
      option to specify the MySQL server to connect to by default:
    </p><pre class="programlisting">shell&gt; mysql-proxy
--proxy-backend-addresses=MySQL.example.com:3306</pre><p>
      The default proxy port is <code class="literal">4040</code>, so you can
      connect to your MySQL server through the proxy by specifying the
      host name and port details:
    </p><pre class="programlisting">shell&gt; mysql --host=localhost --port=4040</pre><p>
      If your server requires authentication information then this will
      be passed through natively without alteration by
      <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a>, so you must also specify the
      authentication information if required:
    </p><pre class="programlisting">shell&gt; mysql --host=localhost --port=4040 \
   --user=username --password=password</pre><p>
      You can also connect to a read-only port (which filters out
      <a href="sql-syntax.html#update" title="12.2.11. UPDATE Syntax"><code class="literal">UPDATE</code></a> and
      <a href="sql-syntax.html#insert" title="12.2.5. INSERT Syntax"><code class="literal">INSERT</code></a> queries) by connecting to
      the read-only port. By default the host name is the default, and
      the port is <code class="literal">4042</code>, but you can alter the
      host/port information by using the
      <code class="literal">--proxy-read-only-address</code> command-line option.
    </p><p>
      For more detailed information on how to use these command line
      options, and <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a> in general in
      combination with Lua scripts, see
      <a href="ha-overview.html#mysql-proxy-using" title="14.6.5. Using MySQL Proxy">Section 14.6.5, “Using MySQL Proxy”</a>.
    </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="mysql-proxy-scripting"></a>14.6.4. MySQL Proxy Scripting</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting-injection">14.6.4.1. Proxy Scripting Sequence During Query Injection</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting-structures">14.6.4.2. Internal Structures</a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting-connect-server">14.6.4.3. Capturing a connection with <code class="function">connect_server()</code></a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting-read-handshake">14.6.4.4. Examining the handshake with <code class="function">read_handshake()</code></a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting-read-auth">14.6.4.5. Examining the authentication credentials with
        <code class="function">read_auth()</code></a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting-read-auth-result">14.6.4.6. Accessing authentication information with
        <code class="function">read_auth_result()</code></a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting-read-query">14.6.4.7. Manipulating Queries with <code class="function">read_query()</code></a></span></dt><dt><span class="section"><a href="ha-overview.html#mysql-proxy-scripting-read-query-result">14.6.4.8. Manipulating Results with <code class="function">read_query_result()</code></a></span></dt></dl></div><p>
      You can control how MySQL Proxy manipulates and works with the
      queries and results that are passed on to the MySQL server through
      the use of the embedded Lua scripting language. You can find out
      more about the Lua programming language from the
      <a href="http://www.lua.org" target="_top">Lua Website</a>.
    </p><p>
      The primary interaction between MySQL Proxy and the server is
      provided by defining one or more functions through an Lua script.
      A number of functions are supported, according to different events
      and operations in the communication sequence between a client and
      one or more backend MySQL servers:
    </p><div class="itemizedlist"><ul type="disc"><li><p>
          <code class="function">connect_server()</code> — this function is
          called each time a connection is made to MySQL Proxy from a
          client. You can use this function during load-balancing to
          intercept the original connection and decide which server the
          client should ultimately be attached to. If you do not define
          a special solution, then a simple round-robin style
          distribution is used by default.
        </p></li><li><p>
          <code class="function">read_handshake()</code> — this function is
          called when the initial handshake information is returned by
          the server. You can capture the handshake information returned
          and provide additional checks before the authorization
          exchange takes place.
        </p></li><li><p>
          <code class="function">read_auth()</code> — this function is
          called when the authorization packet (user name, password,
          default database) are submitted by the client to the server
          for authentication.
        </p></li><li><p>
          <code class="function">read_auth_result()</code> — this function
          is called when the server returns an authorization packet to
          the client indicating whether the authorization succeeded.
        </p></li><li><p>
          <code class="function">read_query()</code> — this function is
          called each time a query is sent by the client to the server.
          You can use this to edit and manipulate the original query,
          including adding new queries before and after the original
          statement. You can also use this function to return
          information directly to the client, bypassing the server,
          which can be useful to filter unwanted queries or queries that
          exceed known limits.
        </p></li><li><p>
          <code class="function">read_query_result()</code> — this function
          is called each time a result is returned from the server,
          providing you have manually injected queries into the query
          queue. If you have not explicitly inject queries within the
          <code class="function">read_query()</code> function then this function
          is not triggered. You can use this to edit the result set, or
          to remove or filter the result sets generated from additional
          queries you injected into the queue when using
          <code class="function">read_query()</code>.
        </p></li></ul></div><p>
      The table below describes the direction of flow of information at
      the point when the function is triggered.
    </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><thead><tr><th>Function</th><th>Supplied Information</th><th>Direction</th></tr></thead><tbody><tr><td><code class="function">connect_server()</code></td><td>None</td><td>Client to Server</td></tr><tr><td><code class="function">read_handshake()</code></td><td>Handshake packet</td><td>Server to Client</td></tr><tr><td><code class="function">read_auth()</code></td><td>Authorization packet</td><td>Client to Server</td></tr><tr><td><code class="function">read_auth_result()</code></td><td>Authorization response</td><td>Server to Client</td></tr><tr><td><code class="function">read_query()</code></td><td>Query</td><td>Client to Server</td></tr><tr><td><code class="function">read_query_result()</code></td><td>Query result</td><td>Server to Client</td></tr></tbody></table></div><p>
      By default, all functions return a result that indicates that the
      data should be passed on to the client or server (depending on the
      direction of the information being transferred). This return value
      can be overridden by explicitly returning a constant indicating
      that a particular response should be sent. For example, it is
      possible to construct result set information by hand within
      <code class="function">read_query()</code> and to return the resultset
      directly to the client without ever sending the original query to
      the server.
    </p><p>
      In addition to these functions, a number of built-in structures
      provide control over how MySQL Proxy forwards on queries and
      returns the results by providing a simplified interface to
      elements such as the list of queries and the groups of result sets
      that are returned.
    </p><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-scripting-injection"></a>14.6.4.1. Proxy Scripting Sequence During Query Injection</h4></div></div></div><p>
        The figure below gives an example of how the proxy might be used
        when injecting queries into the query queue. Because the proxy
        sits between the client and MySQL server, what the proxy sends
        to the server, and the information that the proxy ultimately
        returns to the client do not have to match or correlate. Once
        the client has connected to the proxy, the following sequence
        occurs for each individual query sent by the client.
      </p><div class="mediaobject"><img src="images/proxy-architecture.png" width="772" height="413" alt="MySQL Proxy architecture"></div><div class="orderedlist"><ol type="1"><li><p>
            The client submits one query to the proxy, the
            <code class="function">read_query()</code> function within the proxy
            is triggered. The function adds the query to the query
            queue.
          </p></li><li><p>
            Once manipulation by <code class="function">read_query()</code> has
            completed, the queries are submitted, sequentially, to the
            MySQL server.
          </p></li><li><p>
            The MySQL server returns the results from each query, one
            result set for each query submitted. The
            <code class="function">read_query_result()</code> function is
            triggered for each result set, and each invocation can
            decide which result set to return to the client
          </p></li></ol></div><p>
        For example, you can queue additional queries into the global
        query queue to be processed by the server. This can be used to
        add statistical information by adding queries before and after
        the original query, changing the original query:
      </p><pre class="programlisting">SELECT * FROM City;</pre><p>
        Into a sequence of queries:
      </p><pre class="programlisting">SELECT NOW();
SELECT * FROM City;
SELECT NOW();</pre><p>
        You can also modify the original statement, for example to add
        <a href="sql-syntax.html#explain" title="12.3.2. EXPLAIN Syntax"><code class="literal">EXPLAIN</code></a> to each statement
        executed to get information on how the statement was processed,
        again altering our original SQL statement into a number of
        statements:
      </p><pre class="programlisting">SELECT * FROM City;
EXPLAIN SELECT * FROM City;</pre><p>
        In both of these examples, the client would have received more
        result sets than expected. Regardless of how you manipulate the
        incoming query and the returned result, the number of queries
        returned by the proxy must match the number of original queries
        sent by the client.
      </p><p>
        You could adjust the client to handle the multiple result sets
        sent by the proxy, but in most cases you will want the existence
        of the proxy to remain transparent. To ensure that the number of
        queries and result sets match, you can use the MySQL Proxy
        <code class="function">read_query_result()</code> to extract the
        additional result set information and return only the result set
        the client originally requested back to the client. You can
        achieve this by giving each query that you add to the query
        queue a unique ID, and then filter out queries that do not match
        the original query ID when processing them with
        <code class="function">read_query_result()</code>.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-scripting-structures"></a>14.6.4.2. Internal Structures</h4></div></div></div><p>
        There are a number of internal structures within the scripting
        element of MySQL Proxy. The primary structure is
        <code class="literal">proxy</code> and this provides an interface to the
        many common structures used throughout the script, such as
        connection lists and configured backend servers. Other
        structures, such as the incoming packet from the client and
        result sets are only available within the context of one of the
        scriptable functions.
      </p><div class="informaltable"><a name="mysql-proxy-scripting-structures-proxy"></a><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Attribute</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">connection</code></td><td>A structure containing the active client connections. For a list of
                attributes, see
                <a href="ha-overview.html#mysql-proxy-scripting-structures-connection"><code class="literal">proxy.connection</code></a>.</td></tr><tr><td><code class="literal">servers</code></td><td>A structure containing the list of configured backend servers. For a
                list of attributes, see
                <a href="ha-overview.html#mysql-proxy-scripting-structures-backends"><code class="literal">proxy.backends</code></a>.</td></tr><tr><td><code class="literal">queries</code></td><td>A structure containing the queue of queries that will be sent to the
                server during a single client query. For a list of
                attributes, see
                <a href="ha-overview.html#mysql-proxy-scripting-structures-queries"><code class="literal">proxy.queries</code></a>.</td></tr><tr><td><code class="literal">PROXY_VERSION</code></td><td>The version number of MySQL Proxy, encoded in hex. You can use this to
                check that the version number supports a particular
                option from within the Lua script. Note that the value
                is encoded as a hex value, so to check the version is at
                least 0.5.1 you compare against
                <code class="literal">0x00501</code>.</td></tr></tbody></table></div><p><a name="mysql-proxy-scripting-structures-connection"></a>
        <span class="bold"><strong> <code class="literal">proxy.connection</code>
        </strong></span>
      </p><p>
        The <code class="literal">proxy.connection</code> object is read only, and
        provides information about the current connection.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Attribute</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">thread_id</code></td><td>The thread ID of the connection.</td></tr><tr><td><code class="literal">backend_ndx</code></td><td>The ID of the server used for this connection. This is an ID valid
                against the list of configured servers available through
                the <code class="literal">proxy.backends</code> object.</td></tr></tbody></table></div><p><a name="mysql-proxy-scripting-structures-backends"></a>
        <span class="bold"><strong> <code class="literal">proxy.backends</code>
        </strong></span>
      </p><p>
        The <code class="literal">proxy.backends</code> table is partially
        writable and contains an array of all the configured backend
        servers and the server metadata (IP address, status, etc.). You
        can determine the array index of the current connection using
        <code class="literal">proxy.connection["backend_ndx"]</code> which is the
        index into this table of the backend server being used by the
        active connection.
      </p><p>
        The attributes for each entry within the
        <code class="literal">proxy.backends</code> table are shown in this table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Attribute</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">address</code></td><td>The host name/port combination used for this connection</td></tr><tr><td><code class="literal">connected_clients</code></td><td>The number of clients currently connected.</td></tr><tr><td><code class="literal">state</code></td><td>The status of the backend server. See
                <a href="ha-overview.html#mysql-proxy-scripting-structures-backend-states">Section 14.6.4.2, “Internal Structures”</a>.</td></tr></tbody></table></div><p><a name="mysql-proxy-scripting-structures-queries"></a>
        <span class="bold"><strong> <code class="literal">proxy.queries</code>
        </strong></span>
      </p><p>
        The <code class="literal">proxy.queries</code> object is a queue
        representing the list of queries to be sent to the server. The
        queue is not populated automatically, but if you do not
        explicitly populate the queue then queries are passed on to the
        backend server verbatim. Also, if you do not populate the query
        queue by hand, then the <code class="function">read_query_result()</code>
        function is not triggered.
      </p><p>
        The following methods are supported for populating the
        <code class="literal">proxy.queries</code> object.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code class="function">append(id,packet)</code></td><td>Appends a query to the end of the query queue. The <code class="literal">id</code>
                is an integer identifier that you can use to recognize
                the query results when they are returned by the server.
                The packet should be a properly formatted query packet.</td></tr><tr><td><code class="function">prepend(id,packet)</code></td><td>Prepends a query to the query queue. The <code class="literal">id</code> is an
                identifier that you can use to recognize the query
                results when they are returned by the server. The packet
                should be a properly formatted query packet.</td></tr><tr><td><code class="function">reset()</code></td><td>Empties the query queue.</td></tr><tr><td><code class="function">len()</code></td><td>Returns the number of query packets in the queue.</td></tr></tbody></table></div><p>
        For example, you could append a query packet to the
        <code class="literal">proxy.queries</code> queue by using the
        <code class="function">append()</code>:
      </p><pre class="programlisting">proxy.queries:append(1,packet)</pre><p><a name="mysql-proxy-scripting-structures-response"></a>
        <span class="bold"><strong><code class="literal">proxy.response</code></strong></span>
      </p><p>
        The <code class="literal">proxy.response</code> structure is used when you
        want to return your own MySQL response, instead of forwarding a
        packet that you have received a backend server. The structure
        holds the response type information, an optional error message,
        and the result set (rows/columns) that you want to return.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Attribute</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">type</code></td><td>The type of the response. The type must be either
                <code class="literal">MYSQLD_PACKET_OK</code> or
                <code class="literal">MYSQLD_PACKET_ERR</code>. If the
                <code class="literal">MYSQLD_PACKET_ERR</code>, then you should
                set the value of the
                <code class="literal">mysql.response.errmsg</code> with a suitable
                error message.</td></tr><tr><td><code class="literal">errmsg</code></td><td>A string containing the error message that will be returned to the
                client.</td></tr><tr><td><code class="literal">resultset</code></td><td>A structure containing the result set information (columns and rows),
                identical to what would be returned when returning a
                results from a <a href="sql-syntax.html#select" title="12.2.8. SELECT Syntax"><code class="literal">SELECT</code></a>
                query.</td></tr></tbody></table></div><p>
        When using <code class="literal">proxy.response</code> you either set
        <code class="literal">proxy.response.type</code> to
        <code class="literal">proxy.MYSQLD_PACKET_OK</code> and then build
        <code class="literal">resultset</code> to contain the results that you
        want to return, or set <code class="literal">proxy.response.type</code> to
        <code class="literal">proxy.MYSQLD_PACKET_ERR</code> and set the
        <code class="literal">proxy.response.errmsg</code> to a string with the
        error message. To send the completed resultset or error message,
        you should return the <code class="literal">proxy.PROXY_SEND_RESULT</code>
        to trigger the return of the packet information.
      </p><p>
        An example of this can be seen in the
        <code class="filename">tutorial-resultset.lua</code> script within the
        MySQL Proxy package:
      </p><pre class="programlisting">if string.lower(command) == "show" and string.lower(option) == "querycounter" then
        ---
        -- proxy.PROXY_SEND_RESULT requires
        --
        -- proxy.response.type to be either
        -- * proxy.MYSQLD_PACKET_OK or
        -- * proxy.MYSQLD_PACKET_ERR
        --
        -- for proxy.MYSQLD_PACKET_OK you need a resultset
        -- * fields
        -- * rows
        --
        -- for proxy.MYSQLD_PACKET_ERR
        -- * errmsg
        proxy.response.type = proxy.MYSQLD_PACKET_OK
        proxy.response.resultset = {
                fields = {
                        { type = proxy.MYSQL_TYPE_LONG, name = "global_query_counter", },
                        { type = proxy.MYSQL_TYPE_LONG, name = "query_counter", },
                },
                rows = {
                        { proxy.global.query_counter, query_counter }
                }
        }

        -- we have our result, send it back
        return proxy.PROXY_SEND_RESULT
elseif string.lower(command) == "show" and string.lower(option) == "myerror" then
        proxy.response.type = proxy.MYSQLD_PACKET_ERR
        proxy.response.errmsg = "my first error"

        return proxy.PROXY_SEND_RESULT
</pre><p><a name="mysql-proxy-scripting-structures-resultset"></a>
        <span class="bold"><strong><code class="literal">proxy.response.resultset</code></strong></span>
      </p><p>
        The <code class="literal">proxy.response.resultset</code> structure should
        be populated with the rows and columns of data that you want to
        return. The structure contains the information about the entire
        result set, with the individual elements of the data shown in
        the table below.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Attribute</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">fields</code></td><td>The definition of the columns being returned. This should be a
                dictionary structure with the <code class="literal">type</code>
                specifying the MySQL data type, and the
                <code class="literal">name</code> specifying the column name.
                Columns should be listed in the order of the column data
                that will be returned.</td></tr><tr><td><code class="literal">flags</code></td><td>A number of flags related to the resultset. Valid flags include
                <code class="literal">auto_commit</code> (whether an automatic
                commit was triggered),
                <code class="literal">no_good_index_used</code> (the query
                executed without using an appropriate index), and
                <code class="literal">no_index_used</code> (the query executed
                without using any index).</td></tr><tr><td><code class="literal">rows</code></td><td>The actual row data. The information should be returned as an array of
                arrays. Each inner array should contain the column data,
                with the outer array making up the entire result set.</td></tr><tr><td><a href="server-administration.html#sysvar_warning_count"><code class="literal">warning_count</code></a></td><td>The number of warnings for this result set.</td></tr><tr><td><code class="literal">affected_rows</code></td><td>The number of rows affected by the original statement.</td></tr><tr><td><a href="server-administration.html#sysvar_insert_id"><code class="literal">insert_id</code></a></td><td>The last insert ID for an auto-incremented column in a table.</td></tr><tr><td><code class="literal">query_status</code></td><td>The status of the query operation. You can use the
                <code class="literal">MYSQLD_PACKET_OK</code> or
                <code class="literal">MYSQLD_PACKET_ERR</code> constants to
                populate this parameter.</td></tr></tbody></table></div><p>
        For an example of the population of this table, see
        <a href="ha-overview.html#mysql-proxy-scripting-structures-response">Section 14.6.4.2, “Internal Structures”</a>.
      </p><p><a name="mysql-proxy-scripting-structures-return-states"></a>
        <span class="bold"><strong>Proxy Return State Constants</strong></span>
      </p><p>
        The following constants are used internally by the proxy to
        specify the response to send to the client or server. All
        constants are exposed as values within the main
        <code class="literal">proxy</code> table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Constant</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">PROXY_SEND_QUERY</code></td><td>Causes the proxy to send the current contents of the queries queue to
                the server.</td></tr><tr><td><code class="literal">PROXY_SEND_RESULT</code></td><td>Causes the proxy to send a result set back to the client.</td></tr><tr><td><code class="literal">PROXY_IGNORE_RESULT</code></td><td>Causes the proxy to drop the result set (nothing is returned to the
                client).</td></tr></tbody></table></div><p>
        As constants, these entities are available without qualification
        in the Lua scripts. For example, at the end of the
        <code class="function">read_query_result()</code> you might return
        <code class="literal">PROXY_IGNORE_RESULT:</code>
      </p><pre class="programlisting">return proxy.PROXY_IGNORE_RESULT</pre><p><a name="mysql-proxy-scripting-structures-packet-states"></a>
        <span class="bold"><strong>Packet State Constants</strong></span>
      </p><p>
        The following states describe the status of a network packet.
        These items are entries within the main <code class="literal">proxy</code>
        table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Constant</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">MYSQLD_PACKET_OK</code></td><td>The packet is OK.</td></tr><tr><td><code class="literal">MYSQLD_PACKET_ERR</code></td><td>The packet contains error information.</td></tr><tr><td><code class="literal">MYSQLD_PACKET_RAW</code></td><td>The packet contains raw data.</td></tr></tbody></table></div><p><a name="mysql-proxy-scripting-structures-backend-states"></a>
        <span class="bold"><strong>Backend State/Type Constants</strong></span>
      </p><p>
        The following constants are used either to define the status of
        the backend server (the MySQL server to which the proxy is
        connected) or the type of backend server. These items are
        entries within the main <code class="literal">proxy</code> table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Constant</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">BACKEND_STATE_UNKNOWN</code></td><td>The current status is unknown.</td></tr><tr><td><code class="literal">BACKEND_STATE_UP</code></td><td>The backend is known to be up (available).</td></tr><tr><td><code class="literal">BACKEND_STATE_DOWN</code></td><td>The backend is known to be down (unavailable).</td></tr><tr><td><code class="literal">BACKEND_TYPE_UNKNOWN</code></td><td>Backend type is unknown.</td></tr><tr><td><code class="literal">BACKEND_TYPE_RW</code></td><td>Backend is available for read/write.</td></tr><tr><td><code class="literal">BACKEND_TYPE_RO</code></td><td>Backend is available only for read-only use.</td></tr></tbody></table></div><p><a name="mysql-proxy-scripting-structures-command-constants"></a>
        <span class="bold"><strong>Server Command Constants</strong></span>
      </p><p>
        The following values are used in the packets exchanged between
        the client and server to identify the information in the rest of
        the packet. These items are entries within the main
        <code class="literal">proxy</code> table. The packet type is defined as
        the first character in the sent packet. For example, when
        intercepting packets from the client to edit or monitor a query
        you would check that the first byte of the packet was of type
        <code class="literal">proxy.COM_QUERY</code>.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Constant</th><th>Description</th></tr></thead><tbody><tr><td><code class="literal">COM_SLEEP</code></td><td>Sleep</td></tr><tr><td><code class="literal">COM_QUIT</code></td><td>Quit</td></tr><tr><td><code class="literal">COM_INIT_DB</code></td><td>Initialize database</td></tr><tr><td><code class="literal">COM_QUERY</code></td><td>Query</td></tr><tr><td><code class="literal">COM_FIELD_LIST</code></td><td>Field List</td></tr><tr><td><code class="literal">COM_CREATE_DB</code></td><td>Create database</td></tr><tr><td><code class="literal">COM_DROP_DB</code></td><td>Drop database</td></tr><tr><td><code class="literal">COM_REFRESH</code></td><td>Refresh</td></tr><tr><td><code class="literal">COM_SHUTDOWN</code></td><td>Shutdown</td></tr><tr><td><code class="literal">COM_STATISTICS</code></td><td>Statistics</td></tr><tr><td><code class="literal">COM_PROCESS_INFO</code></td><td>Process List</td></tr><tr><td><code class="literal">COM_CONNECT</code></td><td>Connect</td></tr><tr><td><code class="literal">COM_PROCESS_KILL</code></td><td>Kill</td></tr><tr><td><code class="literal">COM_DEBUG</code></td><td>Debug</td></tr><tr><td><code class="literal">COM_PING</code></td><td>Ping</td></tr><tr><td><code class="literal">COM_TIME</code></td><td>Time</td></tr><tr><td><code class="literal">COM_DELAYED_INSERT</code></td><td>Delayed insert</td></tr><tr><td><code class="literal">COM_CHANGE_USER</code></td><td>Change user</td></tr><tr><td><code class="literal">COM_BINLOG_DUMP</code></td><td>Binlog dump</td></tr><tr><td><code class="literal">COM_TABLE_DUMP</code></td><td>Table dump</td></tr><tr><td><code class="literal">COM_CONNECT_OUT</code></td><td>Connect out</td></tr><tr><td><code class="literal">COM_REGISTER_SLAVE</code></td><td>Register slave</td></tr><tr><td><code class="literal">COM_STMT_PREPARE</code></td><td>Prepare server-side statement</td></tr><tr><td><code class="literal">COM_STMT_EXECUTE</code></td><td>Execute server-side statement</td></tr><tr><td><code class="literal">COM_STMT_SEND_LONG_DATA</code></td><td>Long data</td></tr><tr><td><code class="literal">COM_STMT_CLOSE</code></td><td>Close server-side statement</td></tr><tr><td><code class="literal">COM_STMT_RESET</code></td><td>Reset statement</td></tr><tr><td><code class="literal">COM_SET_OPTION</code></td><td>Set option</td></tr><tr><td><code class="literal">COM_STMT_FETCH</code></td><td>Fetch statement</td></tr><tr><td><code class="literal">COM_DAEMON</code></td><td>Daemon (MySQL 5.1 only)</td></tr><tr><td><code class="literal">COM_ERROR</code></td><td>Error</td></tr></tbody></table></div><p><a name="mysql-proxy-scripting-structures-type-constants"></a>
        <span class="bold"><strong>MySQL Type Constants</strong></span>
      </p><p>
        These constants are used to identify the field types in the
        query result data returned to clients from the result of a
        query. These items are entries within the main
        <code class="literal">proxy</code> table.
      </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><thead><tr><th>Constant</th><th>Field Type</th></tr></thead><tbody><tr><td><code class="literal">MYSQL_TYPE_DECIMAL</code></td><td>Decimal</td></tr><tr><td><code class="literal">MYSQL_TYPE_NEWDECIMAL</code></td><td>Decimal (MySQL 5.0 or later)</td></tr><tr><td><code class="literal">MYSQL_TYPE_TINY</code></td><td>Tiny</td></tr><tr><td><code class="literal">MYSQL_TYPE_SHORT</code></td><td>Short</td></tr><tr><td><code class="literal">MYSQL_TYPE_LONG</code></td><td>Long</td></tr><tr><td><code class="literal">MYSQL_TYPE_FLOAT</code></td><td>Float</td></tr><tr><td><code class="literal">MYSQL_TYPE_DOUBLE</code></td><td>Double</td></tr><tr><td><code class="literal">MYSQL_TYPE_NULL</code></td><td>Null</td></tr><tr><td><code class="literal">MYSQL_TYPE_TIMESTAMP</code></td><td>Timestamp</td></tr><tr><td><code class="literal">MYSQL_TYPE_LONGLONG</code></td><td>Long long</td></tr><tr><td><code class="literal">MYSQL_TYPE_INT24</code></td><td>Integer</td></tr><tr><td><code class="literal">MYSQL_TYPE_DATE</code></td><td>Date</td></tr><tr><td><code class="literal">MYSQL_TYPE_TIME</code></td><td>Time</td></tr><tr><td><code class="literal">MYSQL_TYPE_DATETIME</code></td><td>Datetime</td></tr><tr><td><code class="literal">MYSQL_TYPE_YEAR</code></td><td>Year</td></tr><tr><td><code class="literal">MYSQL_TYPE_NEWDATE</code></td><td>Date (MySQL 5.0 or later)</td></tr><tr><td><code class="literal">MYSQL_TYPE_ENUM</code></td><td>Enumeration</td></tr><tr><td><code class="literal">MYSQL_TYPE_SET</code></td><td>Set</td></tr><tr><td><code class="literal">MYSQL_TYPE_TINY_BLOB</code></td><td>Tiny Blob</td></tr><tr><td><code class="literal">MYSQL_TYPE_MEDIUM_BLOB</code></td><td>Medium Blob</td></tr><tr><td><code class="literal">MYSQL_TYPE_LONG_BLOB</code></td><td>Long Blob</td></tr><tr><td><code class="literal">MYSQL_TYPE_BLOB</code></td><td>Blob</td></tr><tr><td><code class="literal">MYSQL_TYPE_VAR_STRING</code></td><td>Varstring</td></tr><tr><td><code class="literal">MYSQL_TYPE_STRING</code></td><td>String</td></tr><tr><td><code class="literal">MYSQL_TYPE_TINY</code></td><td>Tiny (compatible with <code class="literal">MYSQL_TYPE_CHAR)</code></td></tr><tr><td><code class="literal">MYSQL_TYPE_ENUM</code></td><td>Enumeration (compatible with <code class="literal">MYSQL_TYPE_INTERVAL</code>)</td></tr><tr><td><code class="literal">MYSQL_TYPE_GEOMETRY</code></td><td>Geometry</td></tr><tr><td><code class="literal">MYSQL_TYPE_BIT</code></td><td>Bit</td></tr></tbody></table></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-scripting-connect-server"></a>14.6.4.3. Capturing a connection with <code class="function">connect_server()</code></h4></div></div></div><p>
        When the proxy accepts a connection from a MySQL client, the
        <code class="function">connect_server()</code> function is called.
      </p><p>
        There are no arguments to the function, but you can use and if
        necessary manipulate the information in the
        <code class="literal">proxy.connection</code> table, which is unique to
        each client session.
      </p><p>
        For example, if you have multiple backend servers then you can
        set the server to be used by that connection by setting the
        value of <code class="literal">proxy.connection.backend_ndx</code> to a
        valid server number. The code below will choose between two
        servers based on whether the current time in minutes is odd or
        even:
      </p><pre class="programlisting">function connect_server()
        print("--&gt; a client really wants to talk to a server")
        if (tonumber(os.date("%M")) % 2 == 0) then
                proxy.connection.backend_ndx = 2
                print("Choosing backend 2")
        else
                proxy.connection.backend_ndx = 1
                print("Choosing backend 1")
        end
        print("Using " .. proxy.backends[proxy.connection.backend_ndx].address)
end</pre><p>
        In this example the IP address/port combination is also
        displayed by accessing the information from the internal
        <code class="literal">proxy.backends</code> table.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-scripting-read-handshake"></a>14.6.4.4. Examining the handshake with <code class="function">read_handshake()</code></h4></div></div></div><p>
        Handshake information is sent by the server to the client after
        the initial connection (through
        <code class="function">connect_server()</code>) has been made. The
        handshake information contains details about the MySQL version,
        the ID of the thread that will handle the connection
        information, and the IP address of the client and server. This
        information is exposed through the <code class="literal">proxy.connection</code> structure.
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <code class="literal">proxy.connection.server.mysqld_version</code> — the version of the
            MySQL server.
          </p></li><li><p>
            <code class="literal">proxy.connection.server.thread_id</code> — the thread ID.
          </p></li><li><p>
            <code class="literal">proxy.connection.server.scramble_buffer</code> — the password scramble
            buffer.
          </p></li><li><p>
            <code class="literal">proxy.connection.server.dst.name</code> — the IP address of the
            server.
          </p></li><li><p>
            <code class="literal">proxy.connection.client.dst.name</code> — the IP address of the
            client.
          </p></li></ul></div><p>
        For example, you can print out the handshake data and refuse
        clients by IP address with the following function:
      </p><pre class="programlisting">function read_handshake( auth )
        print("&lt;-- let's send him some information about us")
        print("    mysqld-version: " .. proxy.connection.server.mysqld_version)
        print("    thread-id     : " .. proxy.connection.server.thread_id)
        print("    scramble-buf  : " .. string.format("%q",proxy.connection.server.scramble_buffer))
        print("    server-addr   : " .. proxy.connection.server.dst.name)
        print("    client-addr   : " .. proxy.connection.client.dst.name)

        if not auth.client_addr:match("^127.0.0.1:") then
                proxy.response.type = proxy.MYSQLD_PACKET_ERR
                proxy.response.errmsg = "only local connects are allowed"

                print("we don't like this client");

                return proxy.PROXY_SEND_RESULT
        end
end</pre><p>
        Note that you have to return an error packet to the client by
        using <code class="literal">proxy.PROXY_SEND_RESULT</code>.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-scripting-read-auth"></a>14.6.4.5. Examining the authentication credentials with
        <code class="function">read_auth()</code></h4></div></div></div><p>
        The <code class="function">read_auth()</code> function is triggered when
        an authentication handshake is initiated by the client. In the
        execution sequence, <code class="function">read_auth()</code> occurs
        immediately after <code class="function">read_handshake()</code>, so the
        server selection has already been made, but the connection and
        authorization information has not yet been provided to the
        backend server.
      </p><p>
        The function accepts a single argument, an Lua table containing
        the authorization information for the handshake process. The
        entries in the table are:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <code class="literal">username</code> — the user login for
            connecting to the server.
          </p></li><li><p>
            <code class="literal">password</code> — the password, encrypted,
            to be used when connecting.
          </p></li><li><p>
            <code class="literal">default_db</code> — the default database
            to be used once the connection has been made.
          </p></li></ul></div><p>
        For example, you can print the user name and password supplied
        during authorization using:
      </p><pre class="programlisting">function read_auth( auth )
        print("    username      : " .. auth.username)
        print("    password      : " .. string.format("%q", auth.password))
end</pre><p>
        You can interrupt the authentication process within this
        function and return an error packet back to the client by
        constructing a new packet and returning
        <code class="literal">proxy.PROXY_SEND_RESULT</code>:
      </p><pre class="programlisting">proxy.response.type = proxy.MYSQLD_PACKET_ERR
proxy.response.errmsg = "Logins are not allowed"
return proxy.PROXY_SEND_RESULT
</pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-scripting-read-auth-result"></a>14.6.4.6. Accessing authentication information with
        <code class="function">read_auth_result()</code></h4></div></div></div><p>
        The return packet from the server during authentication is
        captured by <code class="function">read_auth_result()</code>. The only
        argument to this function is the authentication packet returned
        by the server. As the packet is a raw MySQL network protocol
        packet, you must access the first byte to identify the packet
        type and contents. The <code class="literal">MYSQLD_PACKET_ERR</code> and
        <code class="literal">MYSQLD_PACKET_OK</code> constants can be used to
        identify whether the authentication was successful:
      </p><pre class="programlisting">function read_auth_result( auth )
        local state = auth.packet:byte()

        if state == proxy.MYSQLD_PACKET_OK then
                print("&lt;-- auth ok");
        elseif state == proxy.MYSQLD_PACKET_ERR then
                print("&lt;-- auth failed");
        else
                print("&lt;-- auth ... don't know: " .. string.format("%q", auth.packet));
        end
end</pre></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-scripting-read-query"></a>14.6.4.7. Manipulating Queries with <code class="function">read_query()</code></h4></div></div></div><p>
        The <code class="function">read_query()</code> function is called once
        for each query submitted by the client and accepts a single
        argument, the query packet that was provided. To access the
        content of the packet you must parse the packet contents
        manually.
      </p><p>
        For example, you can intercept a query packet and print out the
        contents using the following function definition:
      </p><pre class="programlisting">function read_query( packet )
        if packet:byte() == proxy.COM_QUERY then
                print("we got a normal query: " .. packet:sub(2))
        end
end</pre><p>
        This example checks the first byte of the packet to determine
        the type. If the type is <code class="literal">COM_QUERY</code> (see
        <a href="ha-overview.html#mysql-proxy-scripting-structures-command-constants">Section 14.6.4.2, “Internal Structures”</a>),
        then we extract the query from the packet and print it out. The
        structure of the packet type supplied is important. In the case
        of a <code class="literal">COM_QUERY</code> packet, the remaining contents
        of the packet are the text of the query string. In this example,
        no changes have been made to the query or the list of queries
        that will ultimately be sent to the MySQL server.
      </p><p>
        To modify a query, or add new queries, you must populate the
        query queue (<code class="literal">proxy.queries</code>) and then execute
        the queries that you have placed into the queue. If you do not
        modify the original query or the queue, then the query received
        from the client is sent to the MySQL server verbatim.
      </p><p>
        When adding queries to the queue, you should follow these
        guidelines:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            The packets inserted into the queue must be valid query
            packets. For each packet, you must set the initial byte to
            the packet type. If you are appending a query, you can
            append the query statement to the rest of the packet.
          </p></li><li><p>
            Once you add a query to the queue, the queue is used as the
            source for queries sent to the server. If you add a query to
            the queue to add more information, you must also add the
            original query to the queue or it will not be executed.
          </p></li><li><p>
            Once the queue has been populated, you must set the return
            value from <code class="function">read_query()</code> to indicate
            whether the query queue should be sent to the server.
          </p></li><li><p>
            When you add queries to the queue, you should add an ID. The
            ID you specify is returned with the result set so that you
            identify each query and corresponding result set. The ID has
            no other purpose than as an identifier for correlating the
            query and resultset. When operating in a passive mode,
            during profiling for example, you want to identify the
            original query and the corresponding resultset so that the
            results expect by the client can be returned correctly.
          </p></li><li><p>
            Unless your client is designed to cope with more result sets
            than queries, you should ensure that the number of queries
            from the client match the number of results sets returned to
            the client. Using the unique ID and removing result sets you
            inserted will help.
          </p></li></ul></div><p>
        Normally, the <code class="function">read_query()</code> and
        <code class="function">read_query_result()</code> function are used in
        conjunction with each other to inject additional queries and
        remove the additional result sets. However,
        <code class="function">read_query_result()</code> is only called if you
        populate the query queue within
        <code class="function">read_query()</code>.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-scripting-read-query-result"></a>14.6.4.8. Manipulating Results with <code class="function">read_query_result()</code></h4></div></div></div><p>
        The <code class="function">read_query_result()</code> is called for each
        result set returned by the server only if you have manually
        injected queries into the query queue. If you have not
        manipulated the query queue then this function is not called.
        The function supports a single argument, the result packet,
        which provides a number of properties:
      </p><div class="itemizedlist"><ul type="disc"><li><p>
            <code class="literal">id</code> — the ID of the result set,
            which corresponds to the ID that was set when the query
            packet was submitted to the server when using
            <code class="function">append(id)</code> on the query queue.
          </p></li><li><p>
            <code class="literal">query</code> — the text of the original
            query.
          </p></li><li><p>
            <code class="literal">query_time</code> — the number of
            microseconds required to receive the first row of a result
            set.
          </p></li><li><p>
            <code class="literal">response_time</code> — the number of
            microseconds required to receive the last row of the result
            set.
          </p></li><li><p>
            <code class="literal">resultset</code> — the content of the
            result set data.
          </p></li></ul></div><p>
        By accessing the result information from the MySQL server you
        can extract the results that match the queries that you
        injected, return different result sets (for example, from a
        modified query), and even create your own result sets.
      </p><p>
        The Lua script below, for example, will output the query,
        followed by the query time and response time (that is, the time
        to execute the query and the time to return the data for the
        query) for each query sent to the server:
      </p><pre class="programlisting">function read_query( packet )
        if packet:byte() == proxy.COM_QUERY then
                print("we got a normal query: " .. packet:sub(2))

                proxy.queries:append(1, packet )

                return proxy.PROXY_SEND_QUERY
        end
end

function read_query_result(inj)
        print("query-time: " .. (inj.query_time / 1000) .. "ms")
        print("response-time: " .. (inj.response_time / 1000) .. "ms")
end</pre><p>
        You can access the rows of returned results from the resultset
        by accessing the rows property of the resultset property of the
        result that is exposed through
        <code class="function">read_query_result()</code>. For example, you can
        iterate over the results showing the first column from each row
        using this Lua fragment:
      </p><pre class="programlisting">for row in inj.resultset.rows do
        print("injected query returned: " .. row[1])
end</pre><p>
        Just like <code class="function">read_query()</code>,
        <code class="function">read_query_result()</code> can return different
        values for each result according to the result returned. If you
        have injected additional queries into the query queue, for
        example, then you will want to remove the results returned from
        those additional queries and only return the results from the
        query originally submitted by the client.
      </p><p>
        The example below injects additional <code class="literal">SELECT
        NOW()</code> statements into the query queue, giving them a
        different ID to the ID of the original query. Within
        <code class="function">read_query_result()</code>, if the ID for the
        injected queries is identified, we display the result row, and
        return the <code class="literal">proxy.PROXY_IGNORE_RESULT</code> from the
        function so that the result is not returned to the client. If
        the result is from any other query, we print out the query time
        information for the query and return the default, which passes
        on the result set unchanged. We could also have explicitly
        returned <code class="literal">proxy.PROXY_IGNORE_RESULT</code> to the
        MySQL client.
      </p><pre class="programlisting">function read_query( packet )
        if packet:byte() == proxy.COM_QUERY then
                proxy.queries:append(2, string.char(proxy.COM_QUERY) .. "SELECT NOW()" )
                proxy.queries:append(1, packet )
                proxy.queries:append(2, string.char(proxy.COM_QUERY) .. "SELECT NOW()" )

                return proxy.PROXY_SEND_QUERY
        end
end


function read_query_result(inj)
        if inj.id == 2 then
                for row in inj.resultset.rows do
                        print("injected query returned: " .. row[1])
                end
                return proxy.PROXY_IGNORE_RESULT
        else
                print("query-time: " .. (inj.query_time / 1000) .. "ms")
                print("response-time: " .. (inj.response_time / 1000) .. "ms")
        end
end</pre><p>
        For further examples, see <a href="ha-overview.html#mysql-proxy-using" title="14.6.5. Using MySQL Proxy">Section 14.6.5, “Using MySQL Proxy”</a>.
      </p></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="mysql-proxy-using"></a>14.6.5. Using MySQL Proxy</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ha-overview.html#mysql-proxy-using-admin">14.6.5.1. Using the Administration Interface</a></span></dt></dl></div><p>
      There are a number of different ways to use MySQL Proxy. At the
      most basic level, you can allow MySQL Proxy to pass on queries
      from clients to a single server. To use MySQL proxy in this mode,
      you just have to specify the backend server that the proxy should
      connect to on the command line:
    </p><pre class="programlisting">shell&gt; mysql-proxy --proxy-backend-addresses=sakila:3306</pre><p>
      If you specify multiple backend MySQL servers then the proxy will
      connect each client to each server in a round-robin fashion. For
      example, imagine you have two MySQL servers, A and B. The first
      client to connect will be connected to server A, the second to
      server B, the third to server C. For example:
    </p><pre class="programlisting">shell&gt; mysql-proxy \
     --proxy-backend-addresses=narcissus:3306 \
     --proxy-backend-addresses=nostromo:3306</pre><p>
      When you have specified multiple servers in this way, the proxy
      will automatically identify when a MySQL server has become
      unavailable and mark it accordingly. New connections will
      automatically be attached to a server that is available, and a
      warning will be reported to the standard output from
      <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a>:
    </p><pre class="programlisting">network-mysqld.c.367: connect(nostromo:3306) failed: Connection refused
network-mysqld-proxy.c.2405: connecting to backend (nostromo:3306) failed, marking it as down for ...
</pre><p>
      Lua scripts enable a finer level of control, both over the
      connections and their distribution and how queries and result sets
      are processed. When using an Lua script, you must specify the name
      of the script on the command line using the
      <code class="option">--proxy-lua-script</code> option:
    </p><pre class="programlisting">shell&gt; mysql-proxy --proxy-lua-script=mc.lua --proxy-backend-addresses=sakila:3306</pre><p>
      When you specify a script, the script is not executed until a
      connection is made. This means that faults with the script will
      not be raised until the script is executed. Script faults will not
      affect the distribution of queries to backend MySQL servers.
    </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>
        Because the script is not read until the connection is made, you
        can modify the contents of the Lua script file while the proxy
        is still running and the script will automatically be used for
        the next connection. This ensures that MySQL Proxy remains
        available because it does not have to be restarted for the
        changes to take effect.
      </p></div><div class="section" lang="en"><div class="titlepage"><div><div><h4 class="title"><a name="mysql-proxy-using-admin"></a>14.6.5.1. Using the Administration Interface</h4></div></div></div><p>
        The <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a> administration interface can
        be accessed using any MySQL client using the standard protocols.
        You can use the administration interface to gain information
        about the proxy server as a whole - standard connections to the
        proxy are isolated to operate as if you were connected directly
        to the backend MySQL server. Currently, the interface supports a
        limited set of functionality designed to provide connection and
        configuration information.
      </p><p>
        Because connectivity is provided over the standard MySQL
        protocol, you must access this information using SQL syntax. By
        default, the administration port is configured as 4041. You can
        change this port number using the
        <code class="literal">--admin-address</code> command-line option.
      </p><p>
        To get a list of the currently active connections to the proxy:
      </p><pre class="programlisting">mysql&gt; select * from proxy_connections;
+------+--------+-------+------+
| id   | type   | state | db   |
+------+--------+-------+------+
|    0 | server | 0     |      |
|    1 | proxy  | 0     |      |
|    2 | server | 10    |      |
+------+--------+-------+------+
3 rows in set (0.00 sec)</pre><p>
        To get the current configuration:
      </p><pre class="programlisting">mysql&gt; select * from proxy_config;
+----------------------------+----------------------+
| option                     | value                |
+----------------------------+----------------------+
| admin.address              | :4041                |
| proxy.address              | :4040                |
| proxy.lua_script           | mc.lua               |
| proxy.backend_addresses[0] | mysql:3306           |
| proxy.fix_bug_25371        | 0                    |
| proxy.profiling            | 1                    |
+----------------------------+----------------------+
6 rows in set (0.01 sec)</pre></div></div><div class="section" lang="en"><div class="titlepage"><div><div><h3 class="title"><a name="mysql-proxy-faq"></a>14.6.6. MySQL Proxy FAQ</h3></div></div></div><p><span class="bold"><strong>Questions</strong></span></p><div class="itemizedlist"><ul type="disc"><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-1">14.6.6.1: </a>
        In load balancing, how can I separate reads from writes?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-2">14.6.6.2: </a>
        Is the system context switch expensive, how much overhead does
        the lua script add?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-3">14.6.6.3: </a>
        How do I use a socket with MySQL Proxy? Proxy change logs
        mention that support for UNIX sockets has been added.
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-4">14.6.6.4: </a>
        Can I use MySQL Proxy with all versions of MySQL?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-5">14.6.6.5: </a>
        If MySQL Proxy has to live on same machine as MySQL, are there
        any tuning considerations to ensure both perform optimally?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-6">14.6.6.6: </a>
        Do proxy applications run on a separate server? If not, what is
        the overhead incurred by Proxy on the DB server side?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-7">14.6.6.7: </a>
        Can MySQL Proxy handle SSL connections?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-8">14.6.6.8: </a>
        What is the limit for <code class="literal">max-connections</code> on the
        server?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-9">14.6.6.9: </a>
        As the script is re-read by proxy, does it cache this or is it
        looking at the file system with each request?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-10">14.6.6.10: </a>
        With load balancing, what happen to transactions ? Are all
        queries sent to the same server ?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-11">14.6.6.11: </a>
        Can I run MySQL Proxy as a daemon?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-12">14.6.6.12: </a>
        What about caching the authorization info so clients connecting
        are given back-end connections that were established with
        identical authorization information, thus saving a few more
        round trips?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-13">14.6.6.13: </a>
        Could MySQL Proxy be used to capture passwords?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-14">14.6.6.14: </a>
        Can MySQL Proxy be used on slaves and intercept binlog messages?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-15">14.6.6.15: </a>
        MySQL Proxy can handle about 5000 connections, what is the limit
        on a MySQL server?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-16">14.6.6.16: </a>
        How does MySQL Proxy compare to DBSlayer ?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-17">14.6.6.17: </a>
        I currently use SQL Relay for efficient connection pooling with
        a number of apache processes connecting to a MySQL server. Can
        MySQL proxy currently accomplish this. My goal is to minimize
        connection latency while keeping temporary tables available.
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-18">14.6.6.18: </a>
        The global namespace variable example with quotas does not
        persist after a reboot, is that correct?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-19">14.6.6.19: </a>
        I tried using MySQL Proxy without any Lua script to try a
        round-robin type load balancing. In this case, if the first
        database in the list is down, MySQL Proxy would not connect the
        client to the second database in the list.
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-20">14.6.6.20: </a>
        Would the Java-only connection pooling solution work for
        multiple web servers? With this, I'd assume you can pool across
        many web servers at once?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-21">14.6.6.21: </a>
        Is the MySQL Proxy an API ?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-22">14.6.6.22: </a>
        If you have multiple databases on the same box, can you use
        proxy to connect to databases on default port 3306?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-23">14.6.6.23: </a>
        Will Proxy be deprecated for use with connection pooling once
        MySQL 6.x comes out? Or will 6.x integrate proxy more deeply?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-24">14.6.6.24: </a>
        We've looked at using MySQL Proxy but we're concerned about the
        alpha status - when do you think the proxy would be considered
        production ready?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-25">14.6.6.25: </a>
        Will the proxy road map involve moving popular features from lua
        to C? For example Read/Write splitting
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-26">14.6.6.26: </a>
        Are these reserved function names (for example, error_result)
        that get automatically called?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-27">14.6.6.27: </a>
        Can you explain the status of your work with
        <span><strong class="command">memcached</strong></span> and MySQL Proxy?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-28">14.6.6.28: </a>
        Is there any big web site using MySQL Proxy ? For what purpose
        and what transaction rate have they achieved.
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-29">14.6.6.29: </a>
        So the authentication when connection pooling has to be done at
        every connection? What's the authentication latency?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-30">14.6.6.30: </a>
        Is it possible to use the MySQL proxy w/ updating a Lucene index
        (or Solr) by making TCP calls to that server to update?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-31">14.6.6.31: </a>
        Isn't MySQL Proxy similar to what is provided by Java connection
        pools?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-32">14.6.6.32: </a>
        Are there tools for isolating problems? How can someone figure
        out if a problem is in the client, in the db or in the proxy?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-33">14.6.6.33: </a>
        Can you dynamically reconfigure the pool of MySQL servers that
        MySQL Proxy will load balance to?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-34">14.6.6.34: </a>
        Given that there is a <code class="literal">connect_server</code>
        function, can a Lua script link up with multiple servers?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-35">14.6.6.35: </a>
        Adding a proxy must add latency to the connection, how big is
        that latency?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-36">14.6.6.36: </a>
        In the quick poll, I see "Load Balancer: read-write splitting"
        as an option, so would it be correct to say that there are no
        scripts written for Proxy yet to do this?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-37">14.6.6.37: </a>
        Is it "safe" to use <code class="literal">LuaSocket</code> with proxy
        scripts?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-38">14.6.6.38: </a>
        How different is MySQL Proxy from DBCP (Database connection
        pooling) for Apache in terms of connection pooling?
      </p></li><li><p><a href="ha-overview.html#qandaitem-14-6-6-1-39">14.6.6.39: </a>
        Do you have make one large script and call at proxy startup, can
        I change scripts without stopping and restarting (interrupting)
        the proxy?
      </p></li></ul></div><p><span class="bold"><strong>Questions and Answers</strong></span></p><p><a name="qandaitem-14-6-6-1-1"></a><span class="bold"><strong>14.6.6.1: </strong></span><span class="bold"><strong>
        In load balancing, how can I separate reads from writes?
      </strong></span></p><p>
        There is no automatic separation of queries that perform reads
        or writes to the different backend servers. However, you can
        specify to <a href="ha-overview.html#mysql-proxy" title="14.6. MySQL Proxy"><span><strong class="command">mysql-proxy</strong></span></a> that one or more of
        the 'backend' MyuSQL servers are read-only.
      </p><pre class="programlisting">$ mysql-proxy \
--proxy-backend-addresses=10.0.1.2:3306 \
--proxy-read-only-backend-addresses=10.0.1.3:3306 &amp;</pre><p>
        In the next releases we will add connection pooling and
        read/write splitting to make this more useful. See also
        <a href="http://dev.mysql.com/doc/refman/5.1/en/load-balancer.html" target="_top">MySQL Load Balancer</a>.
      </p><p><a name="qandaitem-14-6-6-1-2"></a><span class="bold"><strong>14.6.6.2: </strong></span><span class="bold"><strong>
        Is the system context switch expensive, how much overhead does
        the lua script add?
      </strong></span></p><p>
        Lua is fast and the overhead should be small enough for most
        applications. The raw packet-overhead is around 400
        microseconds.
      </p><p><a name="qandaitem-14-6-6-1-3"></a><span class="bold"><strong>14.6.6.3: </strong></span><span class="bold"><strong>
        How do I use a socket with MySQL Proxy? Proxy change logs
        mention that support for UNIX sockets has been added.
      </strong></span></p><p>
        Just specify the path to the socket:
      </p><pre class="programlisting">--proxy-backend-addresses=/path/to/socket</pre><p>
        However it appears that
        <code class="literal">--proxy-address=/path/to/socket</code> does not work
        on the front end. It would be nice if someone added this
        feature.
      </p><p><a name="qandaitem-14-6-6-1-4"></a><span class="bold"><strong>14.6.6.4: </strong></span><span class="bold"><strong>
        Can I use MySQL Proxy with all versions of MySQL?
      </strong></span></p><p>
        MySQL Proxy is designed to work with MySQL 5.0 or higher, and
        supports the MySQL network protocol for 5.0 and higher.
      </p><p><a name="qandaitem-14-6-6-1-5"></a><span class="bold"><strong>14.6.6.5: </strong></span><span class="bold"><strong>
        If MySQL Proxy has to live on same machine as MySQL, are there
        any tuning considerations to ensure both perform optimally?
      </strong></span></p><p>
        MySQL Proxy can live on any box: application, db or its own box.
        MySQL Proxy uses comparatively little CPU or RAM, so additional
        requirements or overhead is negligible.
      </p><p><a name="qandaitem-14-6-6-1-6"></a><span class="bold"><strong>14.6.6.6: </strong></span><span class="bold"><strong>
        Do proxy applications run on a separate server? If not, what is
        the overhead incurred by Proxy on the DB server side?
      </strong></span></p><p>
        You can run the proxy on the application server, on its own box
        or on the DB-server depending on the use-case
      </p><p><a name="qandaitem-14-6-6-1-7"></a><span class="bold"><strong>14.6.6.7: </strong></span><span class="bold"><strong>
        Can MySQL Proxy handle SSL connections?
      </strong></span></p><p>
        No, being the man-in-the-middle, Proxy can't handle encrypted
        sessions because it cannot share the SSL information.
      </p><p><a name="qandaitem-14-6-6-1-8"></a><span class="bold"><strong>14.6.6.8: </strong></span><span class="bold"><strong>
        What is the limit for <code class="literal">max-connections</code> on the
        server?
      </strong></span></p><p>
        Around 1024 connections the MySQL Server may run out of threads
        it can spawn. Leaving it at around 100 is advised.
      </p><p><a name="qandaitem-14-6-6-1-9"></a><span class="bold"><strong>14.6.6.9: </strong></span><span class="bold"><strong>
        As the script is re-read by proxy, does it cache this or is it
        looking at the file system with each request?
      </strong></span></p><p>
        It looks for the script at client-connect and reads it if it has
        changed, otherwise it uses the cached version.
      </p><p><a name="qandaitem-14-6-6-1-10"></a><span class="bold"><strong>14.6.6.10: </strong></span><span class="bold"><strong>
        With load balancing, what happen to transactions ? Are all
        queries sent to the same server ?
      </strong></span></p><p>
        Without any special customization the whole connection is sent
        to the same server. That keeps the whole connection state
        intact.
      </p><p><a name="qandaitem-14-6-6-1-11"></a><span class="bold"><strong>14.6.6.11: </strong></span><span class="bold"><strong>
        Can I run MySQL Proxy as a daemon?
      </strong></span></p><p>
        Starting from version 0.6.0, the Proxy is launched as a daemon
        by default. If you want to avoid this, use the
        <code class="literal">-D</code> or <code class="literal">--no-daemon</code> option.
        To keep track of the process ID, the daemon can be started with
        the additional option <code class="literal">--pid-file=file</code>, to
        save the PID to a known file name. On version 0.5.x, the Proxy
        can't be started natively as a daemon
      </p><p><a name="qandaitem-14-6-6-1-12"></a><span class="bold"><strong>14.6.6.12: </strong></span><span class="bold"><strong>
        What about caching the authorization info so clients connecting
        are given back-end connections that were established with
        identical authorization information, thus saving a few more
        round trips?
      </strong></span></p><p>
        There is an option that provides this functionality <code class="literal">
        --proxy-pool-no-change-user</code>.
      </p><p><a name="qandaitem-14-6-6-1-13"></a><span class="bold"><strong>14.6.6.13: </strong></span><span class="bold"><strong>
        Could MySQL Proxy be used to capture passwords?
      </strong></span></p><p>
        The MySQL network protocol does not allow passwords to be sent
        in clear-text, all you could capture is the encrypted version.
      </p><p><a name="qandaitem-14-6-6-1-14"></a><span class="bold"><strong>14.6.6.14: </strong></span><span class="bold"><strong>
        Can MySQL Proxy be used on slaves and intercept binlog messages?
      </strong></span></p><p>
        We are working on that. See
        <a href="http://jan.kneschke.de/2008/5/30/mysql-proxy-rbr-to-sbr-decoding" target="_top">http://jan.kneschke.de/2008/5/30/mysql-proxy-rbr-to-sbr-decoding</a>
        for an example.
      </p><p><a name="qandaitem-14-6-6-1-15"></a><span class="bold"><strong>14.6.6.15: </strong></span><span class="bold"><strong>
        MySQL Proxy can handle about 5000 connections, what is the limit
        on a MySQL server?
      </strong></span></p><p>
        Se your <code class="literal">max-connections</code> settings. By default
        the setting is 150, the proxy can handle a lot more.
      </p><p><a name="qandaitem-14-6-6-1-16"></a><span class="bold"><strong>14.6.6.16: </strong></span><span class="bold"><strong>
        How does MySQL Proxy compare to DBSlayer ?
      </strong></span></p><p>
        DBSlayer is a REST-&gt;MySQL tool, MySQL Proxy is transparent to
        your application. No change to the application is needed.
      </p><p><a name="qandaitem-14-6-6-1-17"></a><span class="bold"><strong>14.6.6.17: </strong></span><span class="bold"><strong>
        I currently use SQL Relay for efficient connection pooling with
        a number of apache processes connecting to a MySQL server. Can
        MySQL proxy currently accomplish this. My goal is to minimize
        connection latency while keeping temporary tables available.
      </strong></span></p><p>
        Yes.
      </p><p><a name="qandaitem-14-6-6-1-18"></a><span class="bold"><strong>14.6.6.18: </strong></span><span class="bold"><strong>
        The global namespace variable example with quotas does not
        persist after a reboot, is that correct?
      </strong></span></p><p>
        Yes. if you restart the proxy, you lose the results, unless you
        save them in a file.
      </p><p><a name="qandaitem-14-6-6-1-19"></a><span class="bold"><strong>14.6.6.19: </strong></span><span class="bold"><strong>
        I tried using MySQL Proxy without any Lua script to try a
        round-robin type load balancing. In this case, if the first
        database in the list is down, MySQL Proxy would not connect the
        client to the second database in the list.
      </strong></span></p><p>
        This issue is fixed in version 0.7.0.
      </p><p><a name="qandaitem-14-6-6-1-20"></a><span class="bold"><strong>14.6.6.20: </strong></span><span class="bold"><strong>
        Would the Java-only connection pooling solution work for
        multiple web servers? With this, I'd assume you can pool across
        many web servers at once?
      </strong></span></p><p>
        Yes. But you can also start one proxy on each application server
        to get a similar behaviour as you have it already.
      </p><p><a name="qandaitem-14-6-6-1-21"></a><span class="bold"><strong>14.6.6.21: </strong></span><span class="bold"><strong>
        Is the MySQL Proxy an API ?
      </strong></span></p><p>
        No, MySQL Proxy is an application that forwards packets from a
        client to a server using the MySQL network protocol. The MySQL
        proxy provides a API allowing you to change its behaviour.
      </p><p><a name="qandaitem-14-6-6-1-22"></a><span class="bold"><strong>14.6.6.22: </strong></span><span class="bold"><strong>
        If you have multiple databases on the same box, can you use
        proxy to connect to databases on default port 3306?
      </strong></span></p><p>
        Yes, MySQL Proxy can listen on any port. Providing none of the
        MySQL servers are listening on the same port.
      </p><p><a name="qandaitem-14-6-6-1-23"></a><span class="bold"><strong>14.6.6.23: </strong></span><span class="bold"><strong>
        Will Proxy be deprecated for use with connection pooling once
        MySQL 6.x comes out? Or will 6.x integrate proxy more deeply?
      </strong></span></p><p>
        The logic about the pooling is controlled by the lua scripts,
        you can enable and disable it if you like. There are no plans to
        embed the current MySQL Proxy functionality into the MySQL
        Server.
      </p><p><a name="qandaitem-14-6-6-1-24"></a><span class="bold"><strong>14.6.6.24: </strong></span><span class="bold"><strong>
        We've looked at using MySQL Proxy but we're concerned about the
        alpha status - when do you think the proxy would be considered
        production ready?
      </strong></span></p><p>
        We are on the road to the next feature release: 0.7.0. It will
        improve the performance quite a bit. After that we may be able
        to enter the beta phase.
      </p><p><a name="qandaitem-14-6-6-1-25"></a><span class="bold"><strong>14.6.6.25: </strong></span><span class="bold"><strong>
        Will the proxy road map involve moving popular features from lua
        to C? For example Read/Write splitting
      </strong></span></p><p>
        We will keep the high-level parts in the Lua layer to be able to
        adjust to special situations without a rebuild. Read/Write
        splitting sometimes needs external knowledge that may only be
        available by the DBA.
      </p><p><a name="qandaitem-14-6-6-1-26"></a><span class="bold"><strong>14.6.6.26: </strong></span><span class="bold"><strong>
        Are these reserved function names (for example, error_result)
        that get automatically called?
      </strong></span></p><p>
        Only functions and values starting with
        <code class="literal">proxy.*</code> are provided by the proxy. All others
        are provided by you.
      </p><p><a name="qandaitem-14-6-6-1-27"></a><span class="bold"><strong>14.6.6.27: </strong></span><span class="bold"><strong>
        Can you explain the status of your work with
        <span><strong class="command">memcached</strong></span> and MySQL Proxy?
      </strong></span></p><p>
        There are some ideas to integrate proxy and
        <span><strong class="command">memcache</strong></span> a bit, but no code yet.
      </p><p><a name="qandaitem-14-6-6-1-28"></a><span class="bold"><strong>14.6.6.28: </strong></span><span class="bold"><strong>
        Is there any big web site using MySQL Proxy ? For what purpose
        and what transaction rate have they achieved.
      </strong></span></p><p>
        Yes, <a href="http://gaiaonline.com/" target="_top">gaiaonline</a>.
        They have tested MySQL Proxy and seen it handle 2400 queries per
        second through the proxy.
      </p><p><a name="qandaitem-14-6-6-1-29"></a><span class="bold"><strong>14.6.6.29: </strong></span><span class="bold"><strong>
        So the authentication when connection pooling has to be done at
        every connection? What's the authentication latency?
      </strong></span></p><p>
        You can skip the round-trip and use the connection as it was
        added to the pool. As long as the application cleans up the
        temporary tables it used. The overhead is (as always) around 400
        microseconds.
      </p><p><a name="qandaitem-14-6-6-1-30"></a><span class="bold"><strong>14.6.6.30: </strong></span><span class="bold"><strong>
        Is it possible to use the MySQL proxy w/ updating a Lucene index
        (or Solr) by making TCP calls to that server to update?
      </strong></span></p><p>
        Yes, but it isn't advised for now.
      </p><p><a name="qandaitem-14-6-6-1-31"></a><span class="bold"><strong>14.6.6.31: </strong></span><span class="bold"><strong>
        Isn't MySQL Proxy similar to what is provided by Java connection
        pools?
      </strong></span></p><p>
        Yes and no. Java connection pools are specific to Java
        applications, MySQL Proxy works with any client API that talks
        the MySQL network protocol. Also, connection pools do not
        provide any functionality for intelligently examining the
        network packets and modifying the contents.
      </p><p><a name="qandaitem-14-6-6-1-32"></a><span class="bold"><strong>14.6.6.32: </strong></span><span class="bold"><strong>
        Are there tools for isolating problems? How can someone figure
        out if a problem is in the client, in the db or in the proxy?
      </strong></span></p><p>
        You can set a debug script in the proxy, which is an
        exceptionally good tool for this purpose. You can see very
        clearly which component is causing the problem, if you set the
        right breakpoints.
      </p><p><a name="qandaitem-14-6-6-1-33"></a><span class="bold"><strong>14.6.6.33: </strong></span><span class="bold"><strong>
        Can you dynamically reconfigure the pool of MySQL servers that
        MySQL Proxy will load balance to?
      </strong></span></p><p>
        Not yet, it is on the list. We are working on a administration
        interface for that purpose.
      </p><p><a name="qandaitem-14-6-6-1-34"></a><span class="bold"><strong>14.6.6.34: </strong></span><span class="bold"><strong>
        Given that there is a <code class="literal">connect_server</code>
        function, can a Lua script link up with multiple servers?
      </strong></span></p><p>
        The proxy provides some tutorials in the source-package, one is
        <code class="filename">examples/tutorial-keepalive.lua</code>.
      </p><p><a name="qandaitem-14-6-6-1-35"></a><span class="bold"><strong>14.6.6.35: </strong></span><span class="bold"><strong>
        Adding a proxy must add latency to the connection, how big is
        that latency?
      </strong></span></p><p>
        In the range of 400microseconds
      </p><p><a name="qandaitem-14-6-6-1-36"></a><span class="bold"><strong>14.6.6.36: </strong></span><span class="bold"><strong>
        In the quick poll, I see "Load Balancer: read-write splitting"
        as an option, so would it be correct to say that there are no
        scripts written for Proxy yet to do this?
      </strong></span></p><p>
        There is a proof of concept script for that included. But its
        far from perfect and may not work for you yet.
      </p><p><a name="qandaitem-14-6-6-1-37"></a><span class="bold"><strong>14.6.6.37: </strong></span><span class="bold"><strong>
        Is it "safe" to use <code class="literal">LuaSocket</code> with proxy
        scripts?
      </strong></span></p><p>
        You can, but it is not advised as it may block.
      </p><p><a name="qandaitem-14-6-6-1-38"></a><span class="bold"><strong>14.6.6.38: </strong></span><span class="bold"><strong>
        How different is MySQL Proxy from DBCP (Database connection
        pooling) for Apache in terms of connection pooling?
      </strong></span></p><p>
        Connection Pooling is just one use-case of the MySQL Proxy. You
        can use it for a lot more and it works in cases where you can't
        use DBCP (like if you don't have Java).
      </p><p><a name="qandaitem-14-6-6-1-39"></a><span class="bold"><strong>14.6.6.39: </strong></span><span class="bold"><strong>
        Do you have make one large script and call at proxy startup, can
        I change scripts without stopping and restarting (interrupting)
        the proxy?
      </strong></span></p><p>
        You can just change the script and the proxy will reload it when
        a client connects.
      </p></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="storage-engines.html">Prev</a> </td><td width="20%" align="center"> </td><td width="40%" align="right"> <a accesskey="n" href="mem-introduction.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Chapter 13. Storage Engines </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> Chapter 15. MySQL Enterprise Monitor</td></tr></table></div></body></html>
